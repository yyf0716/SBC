2017-12-24 04:46:30,320 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = master100/192.168.1.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.1
STARTUP_MSG:   classpath = /home/tools/hadoop-2.5.1/etc/hadoop:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jsch-0.1.42.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-el-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/xz-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/asm-3.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/junit-4.11.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/hadoop-auth-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/hadoop-annotations-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jettison-1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/activation-1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/hadoop-nfs-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/hadoop-common-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/hadoop-common-2.5.1-tests.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-2.5.1-tests.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jline-0.9.94.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-client-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-api-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-common-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-common-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.1-tests.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-10-20T05:53Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2017-12-24 04:46:30,333 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-12-24 04:46:30,348 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2017-12-24 04:46:31,012 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-12-24 04:46:31,261 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-12-24 04:46:31,261 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2017-12-24 04:46:31,265 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://aaaaa
2017-12-24 04:46:31,265 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use aaaaa to access this namenode/service.
2017-12-24 04:46:32,480 INFO org.apache.hadoop.hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
2017-12-24 04:46:32,480 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://master100:50070
2017-12-24 04:46:32,737 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-12-24 04:46:32,753 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2017-12-24 04:46:32,866 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-12-24 04:46:32,905 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-12-24 04:46:32,905 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-12-24 04:46:32,905 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-12-24 04:46:33,311 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-12-24 04:46:33,350 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-12-24 04:46:33,563 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2017-12-24 04:46:33,563 INFO org.mortbay.log: jetty-6.1.26
2017-12-24 04:46:35,026 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: 'signature.secret' configuration not set, using a random value as secret
2017-12-24 04:46:35,287 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@master100:50070
2017-12-24 04:46:35,341 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-12-24 04:46:35,434 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2017-12-24 04:46:35,514 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2017-12-24 04:46:35,514 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2017-12-24 04:46:35,518 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-12-24 04:46:35,520 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2017 十二月 24 04:46:35
2017-12-24 04:46:35,523 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2017-12-24 04:46:35,524 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-12-24 04:46:35,529 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2017-12-24 04:46:35,529 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2017-12-24 04:46:35,597 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2017-12-24 04:46:35,598 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2017-12-24 04:46:35,598 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2017-12-24 04:46:35,598 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2017-12-24 04:46:35,598 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2017-12-24 04:46:35,598 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2017-12-24 04:46:35,598 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2017-12-24 04:46:35,598 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2017-12-24 04:46:35,598 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2017-12-24 04:46:35,612 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2017-12-24 04:46:35,612 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2017-12-24 04:46:35,612 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2017-12-24 04:46:35,613 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Determined nameservice ID: aaaaa
2017-12-24 04:46:35,613 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: true
2017-12-24 04:46:35,616 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2017-12-24 04:46:36,081 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2017-12-24 04:46:36,081 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-12-24 04:46:36,081 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2017-12-24 04:46:36,081 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2017-12-24 04:46:36,088 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2017-12-24 04:46:36,110 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2017-12-24 04:46:36,111 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-12-24 04:46:36,111 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2017-12-24 04:46:36,111 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2017-12-24 04:46:36,115 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-12-24 04:46:36,115 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2017-12-24 04:46:36,115 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2017-12-24 04:46:36,127 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2017-12-24 04:46:36,128 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-12-24 04:46:36,135 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2017-12-24 04:46:36,135 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-12-24 04:46:36,139 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 966.7 MB = 297.0 KB
2017-12-24 04:46:36,139 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2017-12-24 04:46:36,153 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2017-12-24 04:46:36,153 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2017-12-24 04:46:36,153 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2017-12-24 04:46:36,200 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop2/dfs/name/in_use.lock acquired by nodename 4775@master100
2017-12-24 04:46:41,563 WARN org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory: The property 'ssl.client.truststore.location' has not been set, no TrustStore will be loaded
2017-12-24 04:46:44,363 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2017-12-24 04:46:44,729 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2017-12-24 04:46:44,876 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2017-12-24 04:46:44,877 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /opt/hadoop2/dfs/name/current/fsimage_0000000000000000000
2017-12-24 04:46:44,902 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2017-12-24 04:46:44,905 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2017-12-24 04:46:44,905 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 8752 msecs
2017-12-24 04:46:45,947 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to master100:8020
2017-12-24 04:46:45,954 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-12-24 04:46:46,008 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2017-12-24 04:46:46,431 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2017-12-24 04:46:46,589 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2017-12-24 04:46:46,591 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2017-12-24 04:46:46,591 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 11 secs
2017-12-24 04:46:46,591 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2017-12-24 04:46:46,592 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2017-12-24 04:46:46,965 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-12-24 04:46:47,043 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2017-12-24 04:46:47,273 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: master100/192.168.1.100:8020
2017-12-24 04:46:47,273 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2017-12-24 04:46:47,298 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node at slave101/192.168.1.101:8020 every 120 seconds.
2017-12-24 04:46:47,329 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN at http://slave101:50070
Serving checkpoints at http://master100:50070
2017-12-24 04:48:47,703 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-24 04:48:48,975 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:48:49,977 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:48:50,979 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:48:51,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:48:52,983 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:48:53,985 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:48:55,004 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:48:56,007 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:48:57,047 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:48:58,054 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:48:58,086 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.ConnectException: Call From master100/192.168.1.100 to slave101:8020 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-24 04:49:58,115 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-24 04:49:59,129 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:50:00,132 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:50:01,134 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:50:02,169 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:50:03,172 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:50:04,174 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:50:05,176 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:50:06,178 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:50:07,180 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:50:08,210 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:50:08,212 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.ConnectException: Call From master100/192.168.1.100 to slave101:8020 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-24 04:51:08,256 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-24 04:51:09,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:51:10,262 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:51:11,264 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:51:12,266 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:51:13,268 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:51:14,272 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:51:15,274 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:51:16,277 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:51:17,279 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:51:18,282 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:51:18,296 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.ConnectException: Call From master100/192.168.1.100 to slave101:8020 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-24 04:51:27,736 WARN org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory: The property 'ssl.client.truststore.location' has not been set, no TrustStore will be loaded
2017-12-24 04:52:18,375 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-24 04:52:19,381 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:52:20,419 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:52:21,421 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:52:22,426 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:52:23,429 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:52:24,458 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:52:25,460 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:52:26,462 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:52:27,466 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:52:28,469 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:52:28,471 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.ConnectException: Call From master100/192.168.1.100 to slave101:8020 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-24 04:53:28,502 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-24 04:53:29,507 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:53:30,508 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:53:31,511 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:53:32,514 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:53:33,518 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:53:34,521 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:53:35,524 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:53:36,526 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:53:37,528 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:53:38,530 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:53:38,534 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.ConnectException: Call From master100/192.168.1.100 to slave101:8020 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-24 04:54:38,565 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-24 04:54:39,567 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:54:40,569 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:54:41,572 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:54:42,574 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:54:43,575 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:54:44,578 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:54:45,581 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:54:46,583 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:54:47,585 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:54:48,587 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:54:48,590 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.ConnectException: Call From master100/192.168.1.100 to slave101:8020 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-24 04:55:48,651 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-24 04:55:49,654 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:55:50,657 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:55:51,659 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:55:52,662 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:55:53,692 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:55:54,697 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:55:55,699 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:55:56,702 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:55:57,730 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:55:58,732 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:55:58,737 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.ConnectException: Call From master100/192.168.1.100 to slave101:8020 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-24 04:56:58,757 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-24 04:56:59,764 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:57:00,766 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:57:01,768 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:57:02,770 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:57:03,772 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:57:04,774 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:57:05,776 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:57:06,811 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:57:07,814 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:57:08,815 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:57:08,819 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.ConnectException: Call From master100/192.168.1.100 to slave101:8020 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-24 04:58:08,854 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-24 04:58:09,859 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:58:10,861 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:58:11,863 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:58:12,865 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:58:13,867 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:58:14,871 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:58:15,873 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:58:16,876 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:58:17,902 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:58:18,904 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:58:18,909 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.ConnectException: Call From master100/192.168.1.100 to slave101:8020 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-24 04:59:18,944 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-24 04:59:19,949 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:59:20,951 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:59:21,955 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:59:22,986 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:59:23,988 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:59:24,990 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:59:25,992 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:59:26,996 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:59:27,998 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:59:29,001 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 04:59:29,004 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.ConnectException: Call From master100/192.168.1.100 to slave101:8020 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-24 05:00:29,076 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-24 05:00:30,080 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:00:31,113 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:00:32,142 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:00:33,144 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:00:34,146 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:00:35,149 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:00:36,151 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:00:37,154 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:00:38,156 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:00:39,158 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:00:39,161 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.ConnectException: Call From master100/192.168.1.100 to slave101:8020 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-24 05:01:39,222 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-24 05:01:40,229 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:01:41,231 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:01:42,233 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:01:43,235 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:01:44,237 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:01:45,241 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:01:46,244 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:01:47,246 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:01:48,248 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:01:49,256 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:01:49,260 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.ConnectException: Call From master100/192.168.1.100 to slave101:8020 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-24 05:02:49,278 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-24 05:02:50,280 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:02:51,354 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:02:52,357 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:02:53,359 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:02:54,360 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:02:55,362 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:02:56,363 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:02:57,365 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:02:58,367 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:02:59,369 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:02:59,370 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.ConnectException: Call From master100/192.168.1.100 to slave101:8020 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-24 05:03:00,402 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:03:01,407 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:03:02,409 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:03:03,412 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:03:04,414 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:03:05,415 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:03:06,417 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:03:07,419 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:03:08,421 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:03:09,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:03:59,415 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-24 05:04:00,419 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:04:01,448 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:04:02,450 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:04:03,452 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:04:04,454 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:04:05,459 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:04:06,461 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:04:07,464 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:04:08,466 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:04:09,468 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:04:09,472 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.ConnectException: Call From master100/192.168.1.100 to slave101:8020 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-24 05:04:10,479 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:04:11,482 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:04:12,485 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:04:13,487 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:04:14,489 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:04:15,493 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:04:16,496 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:04:17,499 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:04:18,503 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:04:19,505 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:05:09,497 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-24 05:05:10,501 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:05:11,504 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:05:12,506 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:05:13,508 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:05:14,511 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:05:15,513 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:05:16,516 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:05:17,518 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:05:18,524 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:05:19,527 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:05:19,534 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.ConnectException: Call From master100/192.168.1.100 to slave101:8020 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor13.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-24 05:05:20,541 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:05:21,545 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:05:22,547 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:05:23,549 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:05:24,551 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:05:25,588 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:05:26,594 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:05:27,596 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:05:28,598 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:05:29,600 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:06:19,570 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-24 05:06:20,574 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:06:21,576 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:06:22,578 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:06:23,580 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:06:24,582 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:06:25,585 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:06:26,588 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:06:27,593 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:06:28,596 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:06:29,598 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:06:29,600 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.ConnectException: Call From master100/192.168.1.100 to slave101:8020 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor13.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-24 05:06:30,615 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:06:31,622 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:06:32,624 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:06:33,627 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:06:34,630 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:06:35,632 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:06:36,634 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:06:37,661 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:06:38,666 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:06:39,668 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:07:29,638 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-24 05:07:30,641 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:07:31,643 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:07:32,645 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:07:33,648 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:07:34,649 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:07:35,654 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:07:36,657 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:07:37,659 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:07:38,661 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:07:39,663 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:07:39,667 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.ConnectException: Call From master100/192.168.1.100 to slave101:8020 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.GeneratedConstructorAccessor13.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-24 05:07:40,693 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:07:41,695 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:07:42,698 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:07:43,701 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:07:44,703 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:07:45,706 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:07:46,709 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:07:47,744 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:07:48,746 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:07:49,748 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:08:22,885 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2017-12-24 05:08:22,890 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at master100/192.168.1.100
************************************************************/
2017-12-24 05:09:01,769 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = master100/192.168.1.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.1
STARTUP_MSG:   classpath = /home/tools/hadoop-2.5.1/etc/hadoop:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jsch-0.1.42.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-el-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/xz-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/asm-3.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/junit-4.11.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/hadoop-auth-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/hadoop-annotations-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jettison-1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/activation-1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/hadoop-nfs-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/hadoop-common-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/hadoop-common-2.5.1-tests.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-2.5.1-tests.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jline-0.9.94.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-client-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-api-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-common-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-common-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.1-tests.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-10-20T05:53Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2017-12-24 05:09:01,786 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-12-24 05:09:01,800 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2017-12-24 05:09:02,527 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-12-24 05:09:02,778 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-12-24 05:09:02,778 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2017-12-24 05:09:02,782 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://aaaaa
2017-12-24 05:09:02,782 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use aaaaa to access this namenode/service.
2017-12-24 05:09:04,213 INFO org.apache.hadoop.hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
2017-12-24 05:09:04,213 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://master100:50070
2017-12-24 05:09:04,494 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-12-24 05:09:04,524 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2017-12-24 05:09:04,591 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-12-24 05:09:04,617 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-12-24 05:09:04,617 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-12-24 05:09:04,617 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-12-24 05:09:05,049 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-12-24 05:09:05,074 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-12-24 05:09:05,375 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2017-12-24 05:09:05,376 INFO org.mortbay.log: jetty-6.1.26
2017-12-24 05:09:07,610 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: 'signature.secret' configuration not set, using a random value as secret
2017-12-24 05:09:08,418 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@master100:50070
2017-12-24 05:09:08,526 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-12-24 05:09:08,709 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2017-12-24 05:09:08,846 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2017-12-24 05:09:08,846 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2017-12-24 05:09:08,853 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-12-24 05:09:08,857 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2017 十二月 24 05:09:08
2017-12-24 05:09:08,863 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2017-12-24 05:09:08,863 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-12-24 05:09:08,870 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2017-12-24 05:09:08,870 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2017-12-24 05:09:08,989 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2017-12-24 05:09:08,990 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2017-12-24 05:09:08,990 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2017-12-24 05:09:08,990 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2017-12-24 05:09:08,990 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2017-12-24 05:09:08,990 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2017-12-24 05:09:08,990 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2017-12-24 05:09:08,990 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2017-12-24 05:09:08,991 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2017-12-24 05:09:09,006 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2017-12-24 05:09:09,006 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2017-12-24 05:09:09,007 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2017-12-24 05:09:09,008 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Determined nameservice ID: aaaaa
2017-12-24 05:09:09,008 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: true
2017-12-24 05:09:09,014 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2017-12-24 05:09:10,818 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2017-12-24 05:09:10,818 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-12-24 05:09:10,822 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2017-12-24 05:09:10,822 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2017-12-24 05:09:10,864 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2017-12-24 05:09:11,001 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2017-12-24 05:09:11,001 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-12-24 05:09:11,005 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2017-12-24 05:09:11,006 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2017-12-24 05:09:11,019 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-12-24 05:09:11,019 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2017-12-24 05:09:11,019 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2017-12-24 05:09:11,035 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2017-12-24 05:09:11,038 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-12-24 05:09:11,063 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2017-12-24 05:09:11,063 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-12-24 05:09:11,068 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 966.7 MB = 297.0 KB
2017-12-24 05:09:11,068 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2017-12-24 05:09:11,204 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2017-12-24 05:09:11,204 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2017-12-24 05:09:11,204 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2017-12-24 05:09:11,326 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop2/dfs/name/in_use.lock acquired by nodename 5755@master100
2017-12-24 05:09:17,360 WARN org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory: The property 'ssl.client.truststore.location' has not been set, no TrustStore will be loaded
2017-12-24 05:09:23,632 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:23,634 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:23,634 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:24,636 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:24,637 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:24,638 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:25,706 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:25,767 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:25,767 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:25,911 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-24 05:09:26,769 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:26,856 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:26,901 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:26,911 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-24 05:09:27,771 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:27,858 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:27,903 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:27,913 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-24 05:09:28,773 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:28,860 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:28,906 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:28,914 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-24 05:09:29,775 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:29,862 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:29,907 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:29,915 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10007 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-24 05:09:30,778 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:30,864 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:30,909 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:30,916 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11008 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-24 05:09:31,780 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:31,865 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:31,911 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:31,918 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12010 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-24 05:09:32,782 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:32,867 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:32,919 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 13011 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: Call From master100/192.168.1.100 to slave101:8485 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, 192.168.1.102:8485: Call From master100/192.168.1.100 to slave102:8485 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused]
2017-12-24 05:09:32,980 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:32,997 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: Call From master100/192.168.1.100 to slave101:8485 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
192.168.1.103:8485: Call From master100/192.168.1.100 to slave103:8485 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
192.168.1.102:8485: Call From master100/192.168.1.100 to slave102:8485 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:636)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:279)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:955)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:700)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:529)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:751)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:735)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1473)
2017-12-24 05:09:33,003 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2017-12-24 05:09:33,104 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2017-12-24 05:09:33,235 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2017-12-24 05:09:33,235 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /opt/hadoop2/dfs/name/current/fsimage_0000000000000000000
2017-12-24 05:09:33,254 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2017-12-24 05:09:33,254 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2017-12-24 05:09:33,255 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 22051 msecs
2017-12-24 05:09:33,865 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to master100:8020
2017-12-24 05:09:33,882 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-12-24 05:09:33,940 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2017-12-24 05:09:34,055 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2017-12-24 05:09:34,082 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2017-12-24 05:09:34,082 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2017-12-24 05:09:34,082 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 25 secs
2017-12-24 05:09:34,083 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2017-12-24 05:09:34,083 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2017-12-24 05:09:34,282 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-12-24 05:09:34,306 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2017-12-24 05:09:34,309 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: master100/192.168.1.100:8020
2017-12-24 05:09:34,309 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2017-12-24 05:09:34,328 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node at slave101/192.168.1.101:8020 every 120 seconds.
2017-12-24 05:09:34,347 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN at http://slave101:50070
Serving checkpoints at http://master100:50070
2017-12-24 05:09:35,354 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:35,355 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:35,373 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:36,358 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:36,359 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:36,376 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:37,361 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:37,362 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:37,402 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:38,364 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:38,365 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:38,959 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:39,367 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:39,368 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:39,964 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:40,351 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-24 05:09:40,371 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:40,399 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:40,967 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:41,353 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-24 05:09:41,395 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:41,402 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:42,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:42,354 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-24 05:09:42,397 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:42,404 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:43,024 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:43,355 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-24 05:09:43,400 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:43,407 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:44,058 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:44,356 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-24 05:09:44,404 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:44,410 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:45,061 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-24 05:09:45,065 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: Call From master100/192.168.1.100 to slave101:8485 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
192.168.1.103:8485: Call From master100/192.168.1.100 to slave103:8485 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
192.168.1.102:8485: Call From master100/192.168.1.100 to slave102:8485 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-24 05:09:50,055 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(192.168.1.102, datanodeUuid=39baae53-80c7-4807-a492-8cd1ad4291cf, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-291bf135-e81a-466b-8cca-005142eed37a;nsid=18366549;c=0) storage 39baae53-80c7-4807-a492-8cd1ad4291cf
2017-12-24 05:09:50,103 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/192.168.1.102:50010
2017-12-24 05:09:51,589 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(192.168.1.103, datanodeUuid=f82ecc71-3014-4c25-9c75-013de0470b2c, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-291bf135-e81a-466b-8cca-005142eed37a;nsid=18366549;c=0) storage f82ecc71-3014-4c25-9c75-013de0470b2c
2017-12-24 05:09:51,591 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/192.168.1.103:50010
2017-12-24 05:09:51,630 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-7cdd7c35-81c1-401d-ac3b-cde27a144a3d for DN 192.168.1.102:50010
2017-12-24 05:09:52,261 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-b50a7f4e-71dd-4065-a0c8-0dde4734ec7d for DN 192.168.1.103:50010
2017-12-24 05:09:52,329 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from DatanodeStorage[DS-7cdd7c35-81c1-401d-ac3b-cde27a144a3d,DISK,NORMAL] after starting up or becoming active. Its block contents are no longer considered stale
2017-12-24 05:09:52,329 INFO BlockStateChange: BLOCK* processReport: from storage DS-7cdd7c35-81c1-401d-ac3b-cde27a144a3d node DatanodeRegistration(192.168.1.102, datanodeUuid=39baae53-80c7-4807-a492-8cd1ad4291cf, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-291bf135-e81a-466b-8cca-005142eed37a;nsid=18366549;c=0), blocks: 0, hasStaleStorages: false, processing time: 13 msecs
2017-12-24 05:09:53,147 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from DatanodeStorage[DS-b50a7f4e-71dd-4065-a0c8-0dde4734ec7d,DISK,NORMAL] after starting up or becoming active. Its block contents are no longer considered stale
2017-12-24 05:09:53,147 INFO BlockStateChange: BLOCK* processReport: from storage DS-b50a7f4e-71dd-4065-a0c8-0dde4734ec7d node DatanodeRegistration(192.168.1.103, datanodeUuid=f82ecc71-3014-4c25-9c75-013de0470b2c, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-291bf135-e81a-466b-8cca-005142eed37a;nsid=18366549;c=0), blocks: 0, hasStaleStorages: false, processing time: 0 msecs
2017-12-24 05:09:56,485 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(192.168.1.101, datanodeUuid=c1a65381-b373-45ea-8031-47c9f6c4e577, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-291bf135-e81a-466b-8cca-005142eed37a;nsid=18366549;c=0) storage c1a65381-b373-45ea-8031-47c9f6c4e577
2017-12-24 05:09:56,485 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/192.168.1.101:50010
2017-12-24 05:09:57,323 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-fa575c26-9138-4923-adfe-224bf6e42868 for DN 192.168.1.101:50010
2017-12-24 05:09:57,645 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from DatanodeStorage[DS-fa575c26-9138-4923-adfe-224bf6e42868,DISK,NORMAL] after starting up or becoming active. Its block contents are no longer considered stale
2017-12-24 05:09:57,645 INFO BlockStateChange: BLOCK* processReport: from storage DS-fa575c26-9138-4923-adfe-224bf6e42868 node DatanodeRegistration(192.168.1.101, datanodeUuid=c1a65381-b373-45ea-8031-47c9f6c4e577, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-291bf135-e81a-466b-8cca-005142eed37a;nsid=18366549;c=0), blocks: 0, hasStaleStorages: false, processing time: 0 msecs
2017-12-24 05:09:58,343 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Stopping services started for standby state
2017-12-24 05:09:58,344 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:337)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-24 05:09:58,355 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2017-12-24 05:09:58,373 WARN org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory: The property 'ssl.client.truststore.location' has not been set, no TrustStore will be loaded
2017-12-24 05:09:58,435 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Starting recovery process for unclosed journal segments...
2017-12-24 05:09:59,893 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Successfully started new epoch 1
2017-12-24 05:09:59,894 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt/hadoop2/dfs/name/current
2017-12-24 05:09:59,894 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Catching up to latest edits from old active before taking over writer role in edits logs
2017-12-24 05:09:59,933 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: Marking all datandoes as stale
2017-12-24 05:09:59,937 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Reprocessing replication and invalidation queues
2017-12-24 05:09:59,937 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2017-12-24 05:09:59,938 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Will take over writing edit logs at txnid 1
2017-12-24 05:09:59,991 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
2017-12-24 05:10:03,725 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
2017-12-24 05:10:03,726 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2017-12-24 05:10:03,726 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2017-12-24 05:10:03,726 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2017-12-24 05:10:03,729 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2017-12-24 05:10:03,729 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 3782 msec
2017-12-24 05:10:03,735 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-12-24 05:10:03,736 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning because of pending operations
2017-12-24 05:10:03,783 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 47 millisecond(s).
2017-12-24 05:10:33,737 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-24 05:10:33,738 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-24 05:11:03,739 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-24 05:11:03,740 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-24 05:11:33,740 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-24 05:11:33,741 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-24 05:11:52,790 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-24 05:11:52,790 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-24 05:11:52,790 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1
2017-12-24 05:11:52,791 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 79 267 
2017-12-24 05:11:52,837 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 124 268 
2017-12-24 05:11:52,886 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000001 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000001-0000000000000000002
2017-12-24 05:11:52,915 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 3
2017-12-24 05:12:03,740 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-24 05:12:03,741 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-24 05:12:33,741 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-24 05:12:33,742 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2017-12-24 05:13:03,741 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-24 05:13:03,742 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-24 05:13:33,742 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-24 05:13:33,743 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-24 05:13:54,380 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-24 05:13:54,380 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-24 05:13:54,380 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 3
2017-12-24 05:13:54,381 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 7 63 
2017-12-24 05:13:54,401 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 26 64 
2017-12-24 05:13:54,416 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000003 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000003-0000000000000000004
2017-12-24 05:13:54,416 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 5
2017-12-24 05:13:57,245 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: there are no corrupt file blocks.
2017-12-24 05:14:03,743 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-24 05:14:03,743 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-24 05:14:33,743 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-24 05:14:33,744 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-24 05:15:03,744 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-24 05:15:03,745 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-24 05:15:09,982 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 137 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 15 51 
2017-12-24 05:15:33,745 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-24 05:15:33,746 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-24 05:15:54,744 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /usr/file/jdk-7u80-linux-x64.rpm._COPYING_. BP-388453887-192.168.1.100-1514119536645 blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-fa575c26-9138-4923-adfe-224bf6e42868:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-7cdd7c35-81c1-401d-ac3b-cde27a144a3d:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-b50a7f4e-71dd-4065-a0c8-0dde4734ec7d:NORMAL|RBW]]}
2017-12-24 05:15:55,731 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-24 05:15:55,731 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-24 05:15:55,731 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 5
2017-12-24 05:15:55,740 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 8 Total time for transactions(ms): 143 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms): 118 58 
2017-12-24 05:15:55,754 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000005 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000005-0000000000000000012
2017-12-24 05:15:55,754 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 13
2017-12-24 05:16:03,746 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-24 05:16:03,747 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-24 05:16:24,746 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 192.168.1.102:50010 is added to blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-fa575c26-9138-4923-adfe-224bf6e42868:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-7cdd7c35-81c1-401d-ac3b-cde27a144a3d:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-b50a7f4e-71dd-4065-a0c8-0dde4734ec7d:NORMAL|RBW]]} size 0
2017-12-24 05:16:24,887 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 192.168.1.103:50010 is added to blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-fa575c26-9138-4923-adfe-224bf6e42868:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-7cdd7c35-81c1-401d-ac3b-cde27a144a3d:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-b50a7f4e-71dd-4065-a0c8-0dde4734ec7d:NORMAL|RBW]]} size 0
2017-12-24 05:16:24,946 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 192.168.1.101:50010 is added to blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-fa575c26-9138-4923-adfe-224bf6e42868:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-7cdd7c35-81c1-401d-ac3b-cde27a144a3d:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-b50a7f4e-71dd-4065-a0c8-0dde4734ec7d:NORMAL|RBW]]} size 0
2017-12-24 05:16:24,996 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocateBlock: /usr/file/jdk-7u80-linux-x64.rpm._COPYING_. BP-388453887-192.168.1.100-1514119536645 blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-7cdd7c35-81c1-401d-ac3b-cde27a144a3d:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-fa575c26-9138-4923-adfe-224bf6e42868:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-b50a7f4e-71dd-4065-a0c8-0dde4734ec7d:NORMAL|RBW]]}
2017-12-24 05:16:31,621 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 192.168.1.103:50010 is added to blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-7cdd7c35-81c1-401d-ac3b-cde27a144a3d:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-fa575c26-9138-4923-adfe-224bf6e42868:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-b50a7f4e-71dd-4065-a0c8-0dde4734ec7d:NORMAL|RBW]]} size 0
2017-12-24 05:16:31,624 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 192.168.1.101:50010 is added to blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-7cdd7c35-81c1-401d-ac3b-cde27a144a3d:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-fa575c26-9138-4923-adfe-224bf6e42868:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-b50a7f4e-71dd-4065-a0c8-0dde4734ec7d:NORMAL|RBW]]} size 0
2017-12-24 05:16:31,629 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 192.168.1.102:50010 is added to blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-7cdd7c35-81c1-401d-ac3b-cde27a144a3d:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-fa575c26-9138-4923-adfe-224bf6e42868:NORMAL|RBW], ReplicaUnderConstruction[[DISK]DS-b50a7f4e-71dd-4065-a0c8-0dde4734ec7d:NORMAL|RBW]]} size 0
2017-12-24 05:16:31,658 INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /usr/file/jdk-7u80-linux-x64.rpm._COPYING_ is closed by DFSClient_NONMAPREDUCE_-1472019453_1
2017-12-24 05:16:33,746 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-24 05:16:33,747 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-24 05:17:03,747 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-24 05:17:03,748 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-24 05:17:33,748 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-24 05:17:33,749 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-24 05:17:56,370 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-24 05:17:56,370 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-24 05:17:56,370 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 13
2017-12-24 05:17:56,371 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 7 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 4 SyncTimes(ms): 377 352 
2017-12-24 05:17:56,449 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 7 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 5 SyncTimes(ms): 454 353 
2017-12-24 05:17:56,460 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000013 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000013-0000000000000000019
2017-12-24 05:17:56,461 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 20
2017-12-24 05:18:03,749 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-24 05:18:03,751 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2017-12-24 05:18:27,664 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2017-12-24 05:18:27,668 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at master100/192.168.1.100
************************************************************/
2017-12-29 15:57:06,625 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = master100/192.168.1.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.1
STARTUP_MSG:   classpath = /home/tools/hadoop-2.5.1/etc/hadoop:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jsch-0.1.42.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-el-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/xz-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/asm-3.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/junit-4.11.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/hadoop-auth-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/hadoop-annotations-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jettison-1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/activation-1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/hadoop-nfs-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/hadoop-common-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/hadoop-common-2.5.1-tests.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-2.5.1-tests.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jline-0.9.94.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-client-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-api-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-common-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-common-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.1-tests.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-10-20T05:53Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2017-12-29 15:57:06,915 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-12-29 15:57:06,958 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2017-12-29 15:57:08,469 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-12-29 15:57:09,989 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-12-29 15:57:09,989 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2017-12-29 15:57:09,997 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://aaaaa
2017-12-29 15:57:10,003 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use aaaaa to access this namenode/service.
2017-12-29 15:57:12,588 INFO org.apache.hadoop.hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
2017-12-29 15:57:12,588 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://master100:50070
2017-12-29 15:57:13,675 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-12-29 15:57:13,685 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2017-12-29 15:57:13,719 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-12-29 15:57:13,736 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-12-29 15:57:13,737 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-12-29 15:57:13,737 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-12-29 15:57:14,747 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-12-29 15:57:14,904 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-12-29 15:57:16,617 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2017-12-29 15:57:16,617 INFO org.mortbay.log: jetty-6.1.26
2017-12-29 15:57:20,503 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: 'signature.secret' configuration not set, using a random value as secret
2017-12-29 15:57:21,918 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@master100:50070
2017-12-29 15:57:22,948 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-12-29 15:57:23,854 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2017-12-29 15:57:24,879 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2017-12-29 15:57:24,880 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2017-12-29 15:57:24,898 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-12-29 15:57:24,914 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2017 十二月 29 15:57:24
2017-12-29 15:57:24,929 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2017-12-29 15:57:24,929 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-12-29 15:57:25,123 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2017-12-29 15:57:25,123 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2017-12-29 15:57:25,516 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2017-12-29 15:57:25,517 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2017-12-29 15:57:25,517 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2017-12-29 15:57:25,517 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2017-12-29 15:57:25,517 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2017-12-29 15:57:25,518 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2017-12-29 15:57:25,518 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2017-12-29 15:57:25,518 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2017-12-29 15:57:25,518 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2017-12-29 15:57:25,544 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2017-12-29 15:57:25,544 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2017-12-29 15:57:25,544 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2017-12-29 15:57:25,545 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Determined nameservice ID: aaaaa
2017-12-29 15:57:25,545 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: true
2017-12-29 15:57:25,552 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2017-12-29 15:57:34,082 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2017-12-29 15:57:34,082 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-12-29 15:57:34,083 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2017-12-29 15:57:34,083 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2017-12-29 15:57:34,095 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2017-12-29 15:57:34,183 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2017-12-29 15:57:34,183 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-12-29 15:57:34,184 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2017-12-29 15:57:34,184 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2017-12-29 15:57:34,190 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-12-29 15:57:34,191 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2017-12-29 15:57:34,191 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2017-12-29 15:57:34,194 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2017-12-29 15:57:34,201 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-12-29 15:57:34,219 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2017-12-29 15:57:34,220 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-12-29 15:57:34,220 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 966.7 MB = 297.0 KB
2017-12-29 15:57:34,220 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2017-12-29 15:57:34,248 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2017-12-29 15:57:34,248 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2017-12-29 15:57:34,249 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2017-12-29 15:57:35,083 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop2/dfs/name/in_use.lock acquired by nodename 2400@master100
2017-12-29 15:57:39,942 WARN org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory: The property 'ssl.client.truststore.location' has not been set, no TrustStore will be loaded
2017-12-29 15:57:50,109 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 15:57:51,111 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 15:57:51,676 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:57:51,686 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:57:51,688 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:57:52,112 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 15:57:52,679 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:57:52,691 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:57:52,692 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:57:53,113 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 15:57:53,681 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:57:53,694 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:57:53,695 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:57:54,114 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10007 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 15:57:54,685 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:57:54,698 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:57:54,699 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:57:55,115 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11008 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 15:57:55,694 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:57:55,700 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:57:55,700 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:57:56,116 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12009 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 15:57:56,703 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:57:57,117 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 13010 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 15:57:57,697 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:57:57,704 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:57:57,706 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:57:58,118 WARN org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 14011 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 15:57:58,703 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:57:58,708 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:57:58,709 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:57:59,122 WARN org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 15016 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 15:57:59,705 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:57:59,710 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:57:59,711 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:00,124 WARN org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 16017 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 15:58:00,713 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:00,713 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:01,124 WARN org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 17018 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 15:58:01,707 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:01,726 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:02,126 WARN org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 18020 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 15:58:02,711 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:02,714 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:636)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:279)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:955)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:700)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:529)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:751)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:735)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1473)
2017-12-29 15:58:02,718 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2017-12-29 15:58:03,400 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2017-12-29 15:58:03,745 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2017-12-29 15:58:03,746 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /opt/hadoop2/dfs/name/current/fsimage_0000000000000000000
2017-12-29 15:58:03,762 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=true, haEnabled=true, isRollingUpgrade=false)
2017-12-29 15:58:03,763 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2017-12-29 15:58:03,763 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 29514 msecs
2017-12-29 15:58:13,654 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to master100:8020
2017-12-29 15:58:13,667 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-12-29 15:58:13,703 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2017-12-29 15:58:13,931 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2017-12-29 15:58:14,061 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2017-12-29 15:58:14,061 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2017-12-29 15:58:14,061 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 50 secs
2017-12-29 15:58:14,061 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2017-12-29 15:58:14,062 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2017-12-29 15:58:14,219 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-12-29 15:58:14,224 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2017-12-29 15:58:14,229 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: master100/192.168.1.100:8020
2017-12-29 15:58:14,230 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2017-12-29 15:58:14,238 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node at slave101/192.168.1.101:8020 every 120 seconds.
2017-12-29 15:58:14,252 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN at http://slave101:50070
Serving checkpoints at http://master100:50070
2017-12-29 15:58:15,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:15,261 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:15,261 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:16,263 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:16,263 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:16,265 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:17,267 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:17,268 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:17,269 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:18,295 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:18,296 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:18,296 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:19,299 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:19,339 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:20,257 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 15:58:20,299 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:20,300 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:21,259 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 15:58:21,301 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:21,342 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:21,362 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:22,260 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 15:58:22,344 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:22,364 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:23,261 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 15:58:23,306 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:23,366 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:24,262 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10007 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 15:58:24,309 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:24,347 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:24,368 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:25,265 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11009 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 15:58:25,310 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:25,349 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:26,266 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12010 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 15:58:26,312 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:26,351 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:58:26,355 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-29 15:59:27,385 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:59:27,388 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:59:27,389 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:59:28,392 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:59:28,392 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:59:29,390 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:59:29,394 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:59:29,394 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:59:30,392 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:59:30,396 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:59:30,396 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:59:31,394 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:59:31,398 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:59:31,399 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:59:32,382 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 15:59:32,403 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:59:32,403 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:59:33,383 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 15:59:33,401 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:59:33,409 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:59:34,384 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 15:59:34,404 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:59:34,411 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:59:34,412 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:59:35,385 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 15:59:35,407 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:59:35,416 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:59:35,416 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:59:36,386 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 15:59:36,411 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:59:36,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:59:36,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:59:37,389 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11008 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 15:59:37,415 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:59:37,430 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:59:38,391 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12010 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 15:59:38,426 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 15:59:38,432 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-29 16:00:38,436 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-29 16:00:39,614 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:40,616 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:41,618 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:42,622 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:43,624 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:44,626 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:45,630 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:46,641 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:48,646 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:49,649 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:49,650 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-29 16:00:50,654 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:50,656 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:50,658 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:51,676 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:51,676 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:52,660 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:52,684 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:52,685 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:53,662 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:53,687 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:53,688 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:54,690 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:54,691 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:55,659 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:00:55,665 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:55,694 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:56,660 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:00:56,667 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:56,695 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:56,696 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:57,661 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:00:57,669 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:57,697 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:57,698 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:58,664 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:00:58,671 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:58,700 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:58,702 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:59,665 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10008 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:00:59,674 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:59,704 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:00:59,705 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:01:00,667 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11010 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 16:01:00,676 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:01:00,708 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:01:01,669 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12011 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 16:01:02,670 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 13013 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 16:01:02,678 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:01:02,721 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-29 16:02:02,723 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-29 16:02:03,728 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:04,730 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:05,746 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:06,748 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:08,750 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:10,753 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:11,755 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:12,757 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:13,760 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:14,762 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:14,765 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-29 16:02:15,772 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:15,774 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:15,776 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:16,776 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:16,778 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:17,774 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:17,780 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:17,779 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:18,823 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:18,825 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:18,826 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:19,825 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:19,827 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:19,828 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:20,776 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:02:20,828 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:20,830 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:20,831 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:21,777 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:02:21,830 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:21,831 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:22,780 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:02:22,832 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:22,833 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:22,834 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:23,797 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9022 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:02:23,837 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:23,839 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:23,840 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:24,799 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10024 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:02:24,842 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:24,843 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:25,800 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11025 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:02:25,841 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:25,844 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:25,846 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:02:25,855 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-29 16:03:25,857 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-29 16:03:26,860 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:28,864 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:29,866 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:30,868 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:31,870 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:32,873 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:33,875 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:34,879 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:35,881 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:36,883 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:36,884 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-29 16:03:37,888 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:37,915 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:37,915 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:38,930 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:38,931 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:38,931 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:39,932 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:39,933 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:40,931 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:40,936 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:40,937 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:41,933 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:41,939 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:41,940 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:42,893 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:03:42,935 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:42,941 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:42,942 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:43,894 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:03:43,944 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:43,945 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:44,896 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:03:44,938 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:44,946 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:44,947 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:45,897 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:03:45,941 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:45,948 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:45,948 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:46,898 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10007 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:03:46,962 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:46,963 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:46,964 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:47,904 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11013 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 16:03:47,967 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:48,905 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12014 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 16:03:48,969 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:03:48,973 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-29 16:04:48,976 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-29 16:04:49,980 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:04:50,982 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:04:51,984 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:04:52,986 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:04:53,989 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:04:54,991 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:04:55,994 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:04:57,996 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:04:58,999 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:05:00,001 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:05:00,002 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-29 16:05:01,006 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:05:01,007 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:05:01,008 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:05:02,010 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:05:02,011 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:05:03,009 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:05:03,019 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:05:03,019 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:05:04,013 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:05:04,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:05:04,022 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:05:05,015 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:05:05,024 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:05:05,024 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:05:06,007 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:05:06,017 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:05:06,026 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:05:07,008 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:05:07,019 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:05:07,029 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:05:07,030 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:05:08,009 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:05:08,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:05:08,031 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:05:08,032 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:05:09,011 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:05:09,023 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:05:09,033 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:05:09,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:05:10,012 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:05:10,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:05:10,040 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:05:10,041 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:05:11,015 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11008 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:05:12,016 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12010 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 16:05:12,030 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:05:12,043 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:05:12,045 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-29 16:06:12,046 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-29 16:06:13,051 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:15,076 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:16,084 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:17,089 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:19,093 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:21,096 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:22,105 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:23,116 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:25,119 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:27,122 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:27,125 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-29 16:06:28,130 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:28,131 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:28,132 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:29,134 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:29,135 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:30,135 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:30,137 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:30,137 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:31,140 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:31,140 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:31,141 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:32,142 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:32,142 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:32,144 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:33,135 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:06:33,145 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:33,145 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:33,147 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:34,136 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:06:34,147 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:34,148 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:34,149 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:35,137 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:06:35,150 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:35,151 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:35,152 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:36,138 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:06:36,152 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:36,154 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:36,155 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:37,140 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10007 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:06:37,156 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:37,157 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:37,158 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:38,140 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11008 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 16:06:38,163 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:06:38,166 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-29 16:07:38,169 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-29 16:07:39,173 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:07:40,177 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:07:41,180 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:07:42,182 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:07:44,185 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:07:45,188 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:07:47,198 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:07:49,202 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:07:50,205 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:07:51,208 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:07:51,210 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-29 16:07:52,214 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:07:52,218 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:07:52,219 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:07:53,217 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:07:53,220 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:07:53,221 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:07:54,222 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:07:54,223 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:07:55,234 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:07:55,235 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:07:55,235 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:07:56,238 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:07:56,239 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:07:56,242 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:07:57,220 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:07:57,245 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:07:57,246 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:07:58,221 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:07:58,243 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:07:58,248 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:07:58,249 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:07:59,222 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:07:59,245 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:07:59,251 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:07:59,252 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:08:00,223 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:08:00,247 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:08:00,254 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:08:00,254 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:08:01,224 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:08:01,251 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:08:01,257 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:08:01,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:08:02,225 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11006 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 16:08:02,255 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:08:03,226 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12008 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 16:08:03,257 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:08:03,260 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-29 16:09:03,263 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-29 16:09:04,269 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:05,271 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:06,273 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:07,275 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:08,277 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:09,283 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:10,294 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:11,296 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:12,298 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:13,301 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:13,303 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-29 16:09:14,307 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:14,309 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:14,309 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:15,326 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:15,328 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:15,330 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:16,329 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:16,330 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:16,332 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:17,331 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:17,333 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:18,336 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:18,337 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:18,337 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:19,310 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:09:19,338 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:19,339 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:19,340 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:20,311 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:09:20,341 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:20,342 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:20,343 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:21,312 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:09:21,346 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:21,346 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:22,313 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:09:22,344 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:22,348 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:22,348 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:23,314 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:09:23,351 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:23,352 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:24,315 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11007 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 16:09:24,347 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:25,317 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12008 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 16:09:25,349 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:26,318 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 13009 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 16:09:27,320 WARN org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 14012 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 16:09:27,353 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:09:27,355 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-29 16:10:27,362 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-29 16:10:28,365 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:29,368 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:30,370 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:31,373 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:32,375 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:34,381 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:35,383 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:37,386 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:38,391 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:39,393 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:39,395 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-29 16:10:40,401 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:40,402 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:40,404 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:41,403 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:41,403 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:41,405 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:42,405 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:42,407 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:42,407 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:43,416 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:43,417 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:43,418 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:44,420 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:44,421 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:44,422 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:45,404 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:10:45,425 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:45,426 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:46,405 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:10:46,426 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:46,427 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:46,428 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:47,406 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:10:47,428 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:47,429 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:47,429 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:48,407 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:10:48,432 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:48,433 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:48,436 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:49,409 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:10:49,439 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:49,440 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:50,411 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11008 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 16:10:50,435 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:50,443 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:10:50,445 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-29 16:11:50,449 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-29 16:11:52,455 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:11:54,459 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:11:56,462 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:11:57,464 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:11:58,468 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:11:59,470 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:00,473 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:02,476 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:03,478 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:04,483 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:04,485 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-29 16:12:05,490 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:05,492 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:05,492 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:06,494 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:06,494 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:06,495 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:07,496 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:07,498 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:08,498 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:08,499 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:08,500 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:09,500 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:09,501 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:09,502 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:10,491 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:12:10,530 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:10,532 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:11,492 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:12:11,503 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:11,532 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:11,533 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:12,493 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:12:12,506 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:12,537 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:12,538 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:13,496 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9007 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:12:13,540 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:13,541 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:14,497 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10009 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:12:14,509 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:14,544 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:14,545 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:15,499 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11010 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 16:12:15,513 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:16,501 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12012 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 16:12:16,517 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:17,503 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 13014 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 16:12:17,520 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:12:17,522 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-29 16:13:17,525 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-29 16:13:18,529 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:19,531 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:20,534 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:21,536 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:22,547 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:23,549 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:24,552 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:25,576 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:27,581 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:28,586 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:28,590 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-29 16:13:29,598 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:29,599 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:29,602 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:30,601 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:30,602 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:30,604 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:31,604 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:31,605 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:31,605 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:32,608 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:32,609 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:32,611 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:33,613 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:34,605 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:13:34,611 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:34,613 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:34,615 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:35,606 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:13:35,613 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:35,616 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:35,617 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:36,608 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:13:36,615 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:36,619 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:36,619 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:37,609 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:13:37,617 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:37,621 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:37,622 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:38,610 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10008 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:13:38,619 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:38,622 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:38,623 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:39,613 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11010 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 16:13:39,621 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:39,624 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:13:39,625 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-29 16:14:39,627 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-29 16:14:40,631 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:41,634 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:42,636 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:43,638 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:44,640 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:45,648 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:46,650 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:47,658 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:48,660 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:50,664 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:50,666 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-29 16:14:51,672 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:51,676 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:51,676 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:52,674 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:52,678 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:52,679 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:53,676 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:53,680 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:53,681 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:54,678 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:54,682 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:54,683 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:55,680 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:55,684 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:55,685 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:56,678 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:14:56,687 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:56,688 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:57,679 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:14:57,684 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:57,691 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:57,692 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:58,680 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:14:58,686 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:58,693 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:58,694 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:59,683 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:14:59,689 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:59,695 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:14:59,696 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:15:00,684 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10007 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:15:00,698 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:15:00,701 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:15:01,686 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11009 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 16:15:01,691 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:15:02,687 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12010 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 16:15:02,693 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:15:02,696 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-29 16:16:02,699 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-29 16:16:03,702 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:04,705 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:05,708 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:06,710 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:07,712 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:08,742 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:10,747 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:11,749 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:12,751 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:14,758 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:14,760 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-29 16:16:15,768 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:15,769 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:15,773 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:16,771 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:16,772 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:16,774 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:17,777 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:17,778 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:17,777 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:18,781 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:18,782 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:19,782 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:19,783 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:19,784 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:20,775 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:16:20,785 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:20,786 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:20,786 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:21,776 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:16:21,789 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:21,790 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:21,790 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:22,777 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:16:22,792 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:22,793 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:22,794 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:23,781 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9008 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:16:23,796 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:23,797 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:23,797 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:24,782 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10009 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 16:16:24,799 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:24,800 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:24,801 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:25,784 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11011 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 16:16:25,802 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:16:25,806 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-29 16:17:25,808 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-29 16:17:26,811 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:17:46,833 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); maxRetries=45
2017-12-29 16:17:53,838 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:17:56,840 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:17:59,841 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:18:03,846 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:18:06,844 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 16:18:12,824 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2017-12-29 16:18:12,832 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at master100/192.168.1.100
************************************************************/
2017-12-29 19:30:59,589 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = master100/192.168.1.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.1
STARTUP_MSG:   classpath = /home/tools/hadoop-2.5.1/etc/hadoop:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jsch-0.1.42.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-el-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/xz-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/asm-3.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/junit-4.11.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/hadoop-auth-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/hadoop-annotations-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jettison-1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/activation-1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/hadoop-nfs-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/hadoop-common-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/hadoop-common-2.5.1-tests.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-2.5.1-tests.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jline-0.9.94.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-client-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-api-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-common-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-common-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.1-tests.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-10-20T05:53Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2017-12-29 19:30:59,769 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-12-29 19:30:59,925 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2017-12-29 19:31:01,669 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-12-29 19:31:04,368 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-12-29 19:31:04,368 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2017-12-29 19:31:04,378 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://aaaaa
2017-12-29 19:31:04,379 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use aaaaa to access this namenode/service.
2017-12-29 19:31:07,189 INFO org.apache.hadoop.hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
2017-12-29 19:31:07,189 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://master100:50070
2017-12-29 19:31:08,141 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-12-29 19:31:08,150 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2017-12-29 19:31:08,185 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-12-29 19:31:08,203 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-12-29 19:31:08,204 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-12-29 19:31:08,204 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-12-29 19:31:09,058 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-12-29 19:31:09,241 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-12-29 19:31:13,083 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2017-12-29 19:31:13,083 INFO org.mortbay.log: jetty-6.1.26
2017-12-29 19:31:16,702 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: 'signature.secret' configuration not set, using a random value as secret
2017-12-29 19:31:17,798 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@master100:50070
2017-12-29 19:31:19,026 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-12-29 19:31:20,486 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2017-12-29 19:31:21,556 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2017-12-29 19:31:21,557 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2017-12-29 19:31:21,565 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-12-29 19:31:21,569 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2017 十二月 29 19:31:21
2017-12-29 19:31:21,577 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2017-12-29 19:31:21,577 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-12-29 19:31:21,805 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2017-12-29 19:31:21,806 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2017-12-29 19:31:21,889 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2017-12-29 19:31:21,890 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2017-12-29 19:31:21,890 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2017-12-29 19:31:21,890 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2017-12-29 19:31:21,890 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2017-12-29 19:31:21,890 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2017-12-29 19:31:21,890 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2017-12-29 19:31:21,890 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2017-12-29 19:31:21,890 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2017-12-29 19:31:21,898 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2017-12-29 19:31:21,898 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2017-12-29 19:31:21,898 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2017-12-29 19:31:21,898 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Determined nameservice ID: aaaaa
2017-12-29 19:31:21,899 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: true
2017-12-29 19:31:21,901 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2017-12-29 19:31:27,966 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2017-12-29 19:31:27,966 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-12-29 19:31:27,966 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2017-12-29 19:31:27,967 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2017-12-29 19:31:27,979 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2017-12-29 19:31:28,058 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2017-12-29 19:31:28,058 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-12-29 19:31:28,058 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2017-12-29 19:31:28,058 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2017-12-29 19:31:28,065 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-12-29 19:31:28,065 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2017-12-29 19:31:28,065 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2017-12-29 19:31:28,076 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2017-12-29 19:31:28,083 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-12-29 19:31:28,099 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2017-12-29 19:31:28,100 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-12-29 19:31:28,104 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 966.7 MB = 297.0 KB
2017-12-29 19:31:28,104 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2017-12-29 19:31:28,133 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2017-12-29 19:31:28,134 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2017-12-29 19:31:28,134 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2017-12-29 19:31:28,796 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop2/dfs/name/in_use.lock acquired by nodename 2378@master100
2017-12-29 19:31:34,088 WARN org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory: The property 'ssl.client.truststore.location' has not been set, no TrustStore will be loaded
2017-12-29 19:31:45,473 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:31:46,105 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:31:46,106 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:31:46,108 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:31:46,475 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:31:47,109 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:31:47,109 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:31:47,110 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:31:47,476 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:31:48,111 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:31:48,112 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:31:48,112 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:31:48,478 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:31:49,114 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:31:49,114 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:31:49,115 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:31:49,479 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10008 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:31:50,117 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:31:50,118 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:31:50,119 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:31:50,480 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11009 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:31:51,121 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:31:51,122 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:31:51,123 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:31:51,510 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12039 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:31:52,125 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:31:52,511 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 13040 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:31:53,123 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:31:53,126 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:31:53,127 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:31:53,512 WARN org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 14041 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:31:54,128 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:31:54,129 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:31:54,514 WARN org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 15042 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:31:55,126 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:31:55,130 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:31:55,130 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:31:55,516 WARN org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 16045 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 19:31:56,128 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:31:56,132 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:31:56,518 WARN org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 17046 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 19:31:57,131 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:31:57,134 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:636)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:279)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:955)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:700)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:529)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:751)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:735)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1473)
2017-12-29 19:31:57,137 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2017-12-29 19:31:57,472 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2017-12-29 19:31:57,798 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2017-12-29 19:31:57,798 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /opt/hadoop2/dfs/name/current/fsimage_0000000000000000000
2017-12-29 19:31:57,808 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=true, haEnabled=true, isRollingUpgrade=false)
2017-12-29 19:31:57,808 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2017-12-29 19:31:57,808 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 29668 msecs
2017-12-29 19:32:09,429 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to master100:8020
2017-12-29 19:32:09,440 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-12-29 19:32:09,470 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2017-12-29 19:32:09,685 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2017-12-29 19:32:09,775 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2017-12-29 19:32:09,776 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2017-12-29 19:32:09,776 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 49 secs
2017-12-29 19:32:09,776 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2017-12-29 19:32:09,776 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2017-12-29 19:32:09,907 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-12-29 19:32:09,929 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: master100/192.168.1.100:8020
2017-12-29 19:32:09,929 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2017-12-29 19:32:09,930 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2017-12-29 19:32:09,937 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node at slave101/192.168.1.101:8020 every 120 seconds.
2017-12-29 19:32:09,953 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN at http://slave101:50070
Serving checkpoints at http://master100:50070
2017-12-29 19:32:10,959 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:32:10,960 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:32:10,960 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:32:11,963 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:32:12,964 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:32:12,965 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:32:12,965 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:32:13,967 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:32:13,967 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:32:13,968 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:32:14,969 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:32:14,970 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:32:14,970 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:32:16,100 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:32:15,956 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:32:16,101 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:32:16,101 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:32:17,101 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7146 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:32:17,102 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:32:17,103 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:32:17,103 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:32:18,102 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8147 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:32:18,103 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:32:18,104 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:32:18,105 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:32:19,104 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9148 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:32:19,105 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:32:19,106 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:32:19,106 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:32:20,105 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10149 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:32:20,108 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:32:20,108 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:32:20,108 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:32:21,105 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11150 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 19:32:21,136 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:32:21,137 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:32:21,140 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-29 19:33:22,149 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:33:22,152 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:33:22,153 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:33:23,152 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:33:23,153 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:33:23,162 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:33:24,166 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:33:24,187 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:33:25,156 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:33:25,168 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:33:25,189 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:33:26,158 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:33:26,192 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:33:27,147 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:33:27,160 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:33:27,172 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:33:27,194 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:33:28,148 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:33:28,162 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:33:28,174 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:33:28,196 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:33:29,149 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:33:29,164 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:33:29,176 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:33:29,199 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:33:30,150 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:33:30,166 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:33:30,177 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:33:30,201 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:33:31,151 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:33:31,169 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:33:31,179 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:33:31,203 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:33:32,152 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11006 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 19:33:32,171 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:33:32,181 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:33:32,183 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-29 19:33:59,991 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(192.168.1.101, datanodeUuid=c1a65381-b373-45ea-8031-47c9f6c4e577, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-291bf135-e81a-466b-8cca-005142eed37a;nsid=18366549;c=0) storage c1a65381-b373-45ea-8031-47c9f6c4e577
2017-12-29 19:34:00,001 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/192.168.1.101:50010
2017-12-29 19:34:00,572 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-fa575c26-9138-4923-adfe-224bf6e42868 for DN 192.168.1.101:50010
2017-12-29 19:34:00,656 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from DatanodeStorage[DS-fa575c26-9138-4923-adfe-224bf6e42868,DISK,NORMAL] after starting up or becoming active. Its block contents are no longer considered stale
2017-12-29 19:34:00,657 INFO BlockStateChange: BLOCK* processReport: from storage DS-fa575c26-9138-4923-adfe-224bf6e42868 node DatanodeRegistration(192.168.1.101, datanodeUuid=c1a65381-b373-45ea-8031-47c9f6c4e577, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-291bf135-e81a-466b-8cca-005142eed37a;nsid=18366549;c=0), blocks: 2, hasStaleStorages: false, processing time: 7 msecs
2017-12-29 19:34:02,313 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(192.168.1.102, datanodeUuid=39baae53-80c7-4807-a492-8cd1ad4291cf, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-291bf135-e81a-466b-8cca-005142eed37a;nsid=18366549;c=0) storage 39baae53-80c7-4807-a492-8cd1ad4291cf
2017-12-29 19:34:02,314 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/192.168.1.102:50010
2017-12-29 19:34:02,378 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(192.168.1.103, datanodeUuid=f82ecc71-3014-4c25-9c75-013de0470b2c, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-291bf135-e81a-466b-8cca-005142eed37a;nsid=18366549;c=0) storage f82ecc71-3014-4c25-9c75-013de0470b2c
2017-12-29 19:34:02,379 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/192.168.1.103:50010
2017-12-29 19:34:02,803 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-7cdd7c35-81c1-401d-ac3b-cde27a144a3d for DN 192.168.1.102:50010
2017-12-29 19:34:02,855 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-b50a7f4e-71dd-4065-a0c8-0dde4734ec7d for DN 192.168.1.103:50010
2017-12-29 19:34:02,868 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from DatanodeStorage[DS-7cdd7c35-81c1-401d-ac3b-cde27a144a3d,DISK,NORMAL] after starting up or becoming active. Its block contents are no longer considered stale
2017-12-29 19:34:02,869 INFO BlockStateChange: BLOCK* processReport: from storage DS-7cdd7c35-81c1-401d-ac3b-cde27a144a3d node DatanodeRegistration(192.168.1.102, datanodeUuid=39baae53-80c7-4807-a492-8cd1ad4291cf, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-291bf135-e81a-466b-8cca-005142eed37a;nsid=18366549;c=0), blocks: 2, hasStaleStorages: false, processing time: 0 msecs
2017-12-29 19:34:02,914 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from DatanodeStorage[DS-b50a7f4e-71dd-4065-a0c8-0dde4734ec7d,DISK,NORMAL] after starting up or becoming active. Its block contents are no longer considered stale
2017-12-29 19:34:02,915 INFO BlockStateChange: BLOCK* processReport: from storage DS-b50a7f4e-71dd-4065-a0c8-0dde4734ec7d node DatanodeRegistration(192.168.1.103, datanodeUuid=f82ecc71-3014-4c25-9c75-013de0470b2c, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-291bf135-e81a-466b-8cca-005142eed37a;nsid=18366549;c=0), blocks: 2, hasStaleStorages: false, processing time: 1 msecs
2017-12-29 19:34:32,184 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-29 19:34:33,320 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:34,322 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:35,325 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:36,329 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:37,331 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:38,333 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:39,335 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:40,338 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:42,342 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:43,344 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:43,346 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-29 19:34:44,349 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:44,350 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:44,351 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:45,354 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:45,355 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:45,355 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:46,357 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:46,358 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:47,360 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:47,361 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:47,362 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:48,363 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:48,365 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:48,365 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:49,351 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:34:49,365 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:49,367 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:49,367 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:50,353 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:34:50,367 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:50,370 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:50,370 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:51,356 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:34:51,369 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:51,372 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:51,372 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:52,357 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9007 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:34:52,371 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:52,374 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:52,374 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:53,361 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10008 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:34:53,374 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:53,376 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:53,376 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:54,359 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11009 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 19:34:54,376 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:34:54,379 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-29 19:35:05,773 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020, call org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 192.168.1.101:56826 Call#9 Retry#0: org.apache.hadoop.ipc.StandbyException: Operation category JOURNAL is not supported in state standby
2017-12-29 19:35:54,396 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-29 19:35:56,400 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:35:57,402 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:35:58,404 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:00,407 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:01,409 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:02,411 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:03,414 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:04,416 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:05,419 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:06,421 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:06,423 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-29 19:36:07,428 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:07,430 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:07,431 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:08,433 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:08,434 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:08,435 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:09,438 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:09,438 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:10,437 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:10,440 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:10,440 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:11,439 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:11,442 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:11,442 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:12,431 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:36:12,441 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:12,445 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:12,445 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:13,433 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:36:13,443 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:13,450 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:13,450 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:14,435 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:36:14,445 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:14,452 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:14,452 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:15,436 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:36:15,447 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:15,454 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:15,454 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:15,835 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 8020, call org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 192.168.1.101:56850 Call#13 Retry#0: org.apache.hadoop.ipc.StandbyException: Operation category JOURNAL is not supported in state standby
2017-12-29 19:36:16,437 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10007 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:36:16,449 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:16,456 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:16,457 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:17,438 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11008 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 19:36:17,451 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:36:17,454 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-29 19:36:53,495 INFO BlockStateChange: BLOCK* processReport: from storage DS-fa575c26-9138-4923-adfe-224bf6e42868 node DatanodeRegistration(192.168.1.101, datanodeUuid=c1a65381-b373-45ea-8031-47c9f6c4e577, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-291bf135-e81a-466b-8cca-005142eed37a;nsid=18366549;c=0), blocks: 2, hasStaleStorages: false, processing time: 0 msecs
2017-12-29 19:37:17,486 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-29 19:37:18,490 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:19,492 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:20,494 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:21,505 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:22,507 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:24,509 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:25,512 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:25,905 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020, call org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 192.168.1.101:56875 Call#17 Retry#0: org.apache.hadoop.ipc.StandbyException: Operation category JOURNAL is not supported in state standby
2017-12-29 19:37:27,514 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:29,516 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:30,518 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:30,520 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor13.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-29 19:37:31,525 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:31,525 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:31,526 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:32,528 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:32,529 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:32,530 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:33,532 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:33,533 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:33,534 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:34,534 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:34,536 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:35,536 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:35,538 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:35,538 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:36,525 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:37:36,539 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:36,542 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:36,542 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:37,526 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:37:37,541 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:37,544 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:37,544 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:38,527 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:37:38,543 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:38,546 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:38,547 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:39,528 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:37:39,545 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:39,549 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:39,549 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:40,529 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:37:40,547 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:40,551 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:40,552 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:41,530 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11006 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 19:37:41,564 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:37:41,566 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-29 19:38:37,976 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020, call org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 192.168.1.101:56899 Call#21 Retry#0: org.apache.hadoop.ipc.StandbyException: Operation category JOURNAL is not supported in state standby
2017-12-29 19:38:41,582 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-29 19:38:42,585 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:38:43,587 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:38:44,588 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:38:45,594 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:38:46,595 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:38:47,597 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:38:48,602 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:38:49,603 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:38:50,605 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:38:51,608 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:38:51,609 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor13.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-29 19:38:52,613 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:38:52,614 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:38:52,614 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:38:53,616 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:38:53,616 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:38:53,617 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:38:54,622 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:38:55,619 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:38:55,619 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:38:56,621 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:38:56,622 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:38:56,624 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:38:57,616 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:38:57,623 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:38:57,623 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:38:57,625 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:38:58,617 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:38:58,624 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:38:58,625 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:38:58,626 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:38:59,619 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:38:59,626 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:38:59,627 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:38:59,627 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:39:00,620 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:39:00,628 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:39:00,629 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:39:00,629 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:39:01,621 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:39:01,630 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:39:01,631 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:39:01,632 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:39:02,622 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11007 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:39:02,634 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:39:02,634 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:39:03,623 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12008 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 19:39:03,633 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:39:03,636 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-29 19:39:48,116 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Get corrupt file blocks returned error: Operation category READ is not supported in state standby
2017-12-29 19:39:49,049 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 8020, call org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 192.168.1.101:56923 Call#25 Retry#0: org.apache.hadoop.ipc.StandbyException: Operation category JOURNAL is not supported in state standby
2017-12-29 19:40:03,639 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-29 19:40:04,642 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:05,645 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:06,647 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:07,649 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:08,651 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:10,656 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:11,659 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:12,664 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:14,667 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:15,670 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:15,673 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor13.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-29 19:40:16,680 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:16,683 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:16,684 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:17,687 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:17,688 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:17,689 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:18,691 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:18,693 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:18,693 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:19,693 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:19,695 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:19,696 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:20,695 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:20,701 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:20,702 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:21,685 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:40:21,698 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:21,704 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:21,705 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:22,687 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:40:22,700 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:22,707 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:22,708 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:23,688 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:40:23,702 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:23,709 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:23,710 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:24,689 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:40:24,705 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:24,712 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:24,713 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:25,690 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:40:25,709 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:25,714 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:25,715 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:40:25,726 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-29 19:41:01,109 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020, call org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 192.168.1.101:56947 Call#29 Retry#0: org.apache.hadoop.ipc.StandbyException: Operation category JOURNAL is not supported in state standby
2017-12-29 19:41:21,922 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Get corrupt file blocks returned error: Operation category READ is not supported in state standby
2017-12-29 19:41:25,747 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-29 19:41:25,791 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category JOURNAL is not supported in state standby
	at org.apache.hadoop.hdfs.server.namenode.ha.StandbyState.checkOperation(StandbyState.java:87)
	at org.apache.hadoop.hdfs.server.namenode.NameNode$NameNodeHAContext.checkOperation(NameNode.java:1688)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkOperation(FSNamesystem.java:1258)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5765)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:886)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:11214)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at org.apache.hadoop.ipc.Client.call(Client.java:1411)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-29 19:41:25,868 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@75c50969 expecting start txid #1
2017-12-29 19:41:25,869 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=1&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a, http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=1&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-29 19:41:25,872 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=1&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a, http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=1&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 1
2017-12-29 19:41:25,872 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=1&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 1
2017-12-29 19:41:25,999 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=1&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a, http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=1&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-29 19:41:25,999 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@5aed08e6 expecting start txid #3
2017-12-29 19:41:25,999 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=3&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a, http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=3&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-29 19:41:25,999 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=3&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a, http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=3&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 1
2017-12-29 19:41:26,000 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=3&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 1
2017-12-29 19:41:26,005 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=3&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a, http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=3&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-29 19:41:26,005 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@7fe362ac expecting start txid #5
2017-12-29 19:41:26,005 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=5&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a, http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=5&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-29 19:41:26,005 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=5&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a, http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=5&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 1
2017-12-29 19:41:26,005 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=5&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 1
2017-12-29 19:41:26,138 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 192.168.1.101:50010 is added to blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-fa575c26-9138-4923-adfe-224bf6e42868:NORMAL|FINALIZED]]} size 0
2017-12-29 19:41:26,146 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 192.168.1.102:50010 is added to blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-fa575c26-9138-4923-adfe-224bf6e42868:NORMAL|FINALIZED], ReplicaUnderConstruction[[DISK]DS-7cdd7c35-81c1-401d-ac3b-cde27a144a3d:NORMAL|FINALIZED]]} size 0
2017-12-29 19:41:26,146 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 192.168.1.103:50010 is added to blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-fa575c26-9138-4923-adfe-224bf6e42868:NORMAL|FINALIZED], ReplicaUnderConstruction[[DISK]DS-7cdd7c35-81c1-401d-ac3b-cde27a144a3d:NORMAL|FINALIZED], ReplicaUnderConstruction[[DISK]DS-b50a7f4e-71dd-4065-a0c8-0dde4734ec7d:NORMAL|FINALIZED]]} size 0
2017-12-29 19:41:26,146 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=5&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a, http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=5&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 514 edits # 8 loaded in 0 seconds
2017-12-29 19:41:26,146 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@29634bcc expecting start txid #13
2017-12-29 19:41:26,147 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=13&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a, http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=13&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-29 19:41:26,147 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=13&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a, http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=13&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 1
2017-12-29 19:41:26,147 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=13&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 1
2017-12-29 19:41:26,151 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 192.168.1.101:50010 is added to blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-fa575c26-9138-4923-adfe-224bf6e42868:NORMAL|FINALIZED]]} size 0
2017-12-29 19:41:26,152 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 192.168.1.102:50010 is added to blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-fa575c26-9138-4923-adfe-224bf6e42868:NORMAL|FINALIZED], ReplicaUnderConstruction[[DISK]DS-7cdd7c35-81c1-401d-ac3b-cde27a144a3d:NORMAL|FINALIZED]]} size 0
2017-12-29 19:41:26,152 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 192.168.1.103:50010 is added to blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[[DISK]DS-fa575c26-9138-4923-adfe-224bf6e42868:NORMAL|FINALIZED], ReplicaUnderConstruction[[DISK]DS-7cdd7c35-81c1-401d-ac3b-cde27a144a3d:NORMAL|FINALIZED], ReplicaUnderConstruction[[DISK]DS-b50a7f4e-71dd-4065-a0c8-0dde4734ec7d:NORMAL|FINALIZED]]} size 0
2017-12-29 19:41:26,156 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=13&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a, http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=13&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 480 edits # 7 loaded in 0 seconds
2017-12-29 19:41:26,157 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Loaded 19 edits starting from txid 0 
2017-12-29 19:41:26,803 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:41:28,806 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:41:29,808 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:41:30,810 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:41:31,812 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:41:32,813 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:41:33,815 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:41:34,817 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:41:35,819 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:41:36,821 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:41:58,481 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Get corrupt file blocks returned error: Operation category READ is not supported in state standby
2017-12-29 19:42:27,165 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:42:28,167 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:42:29,169 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:42:30,171 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:42:31,173 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:42:32,175 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:42:33,180 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:42:34,182 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:42:35,184 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:42:36,186 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:43:06,373 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020, call org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 192.168.1.101:56976 Call#36 Retry#0: org.apache.hadoop.ipc.StandbyException: Operation category JOURNAL is not supported in state standby
2017-12-29 19:43:26,185 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-29 19:43:26,198 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category JOURNAL is not supported in state standby
	at org.apache.hadoop.hdfs.server.namenode.ha.StandbyState.checkOperation(StandbyState.java:87)
	at org.apache.hadoop.hdfs.server.namenode.NameNode$NameNodeHAContext.checkOperation(NameNode.java:1688)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkOperation(FSNamesystem.java:1258)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5765)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:886)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:11214)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at org.apache.hadoop.ipc.Client.call(Client.java:1411)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-29 19:43:27,209 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:43:28,211 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:43:29,213 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:43:30,215 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:43:32,218 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:43:34,221 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:43:35,224 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:43:36,226 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:43:38,229 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:43:39,233 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:44:06,409 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020, call org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 192.168.1.101:56990 Call#40 Retry#0: org.apache.hadoop.ipc.StandbyException: Operation category JOURNAL is not supported in state standby
2017-12-29 19:44:26,219 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-29 19:44:26,232 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category JOURNAL is not supported in state standby
	at org.apache.hadoop.hdfs.server.namenode.ha.StandbyState.checkOperation(StandbyState.java:87)
	at org.apache.hadoop.hdfs.server.namenode.NameNode$NameNodeHAContext.checkOperation(NameNode.java:1688)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkOperation(FSNamesystem.java:1258)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5765)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:886)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:11214)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at org.apache.hadoop.ipc.Client.call(Client.java:1411)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-29 19:44:27,246 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:44:28,247 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:44:29,249 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:44:30,251 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:44:31,254 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:44:32,257 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:44:33,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:44:34,262 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:44:35,264 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:44:36,266 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:45:06,452 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020, call org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 192.168.1.101:57004 Call#44 Retry#0: org.apache.hadoop.ipc.StandbyException: Operation category JOURNAL is not supported in state standby
2017-12-29 19:45:25,804 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Get corrupt file blocks returned error: Operation category READ is not supported in state standby
2017-12-29 19:45:26,253 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-29 19:45:26,279 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category JOURNAL is not supported in state standby
	at org.apache.hadoop.hdfs.server.namenode.ha.StandbyState.checkOperation(StandbyState.java:87)
	at org.apache.hadoop.hdfs.server.namenode.NameNode$NameNodeHAContext.checkOperation(NameNode.java:1688)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkOperation(FSNamesystem.java:1258)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5765)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:886)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:11214)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at org.apache.hadoop.ipc.Client.call(Client.java:1411)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-29 19:45:27,285 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:45:28,287 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:45:29,289 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:45:30,292 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:45:31,294 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:45:32,296 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:45:33,298 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:45:34,300 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:45:35,302 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:45:36,304 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:46:06,496 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020, call org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 192.168.1.101:57018 Call#48 Retry#0: org.apache.hadoop.ipc.StandbyException: Operation category JOURNAL is not supported in state standby
2017-12-29 19:46:26,294 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-29 19:46:26,307 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category JOURNAL is not supported in state standby
	at org.apache.hadoop.hdfs.server.namenode.ha.StandbyState.checkOperation(StandbyState.java:87)
	at org.apache.hadoop.hdfs.server.namenode.NameNode$NameNodeHAContext.checkOperation(NameNode.java:1688)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkOperation(FSNamesystem.java:1258)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5765)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:886)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:11214)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at org.apache.hadoop.ipc.Client.call(Client.java:1411)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-29 19:46:27,325 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:46:28,328 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:46:29,330 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:46:31,334 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:46:32,336 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:46:33,338 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:46:34,340 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:46:35,272 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2017-12-29 19:46:35,281 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at master100/192.168.1.100
************************************************************/
2017-12-29 19:51:02,664 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = master100/192.168.1.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.1
STARTUP_MSG:   classpath = /home/tools/hadoop-2.5.1/etc/hadoop:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jsch-0.1.42.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-el-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/xz-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/asm-3.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/junit-4.11.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/hadoop-auth-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/hadoop-annotations-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jettison-1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/activation-1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/hadoop-nfs-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/hadoop-common-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/hadoop-common-2.5.1-tests.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-2.5.1-tests.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jline-0.9.94.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-client-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-api-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-common-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-common-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.1-tests.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-10-20T05:53Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2017-12-29 19:51:02,695 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-12-29 19:51:02,713 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2017-12-29 19:51:03,750 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-12-29 19:51:04,082 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-12-29 19:51:04,083 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2017-12-29 19:51:04,089 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://aaaaa
2017-12-29 19:51:04,091 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use aaaaa to access this namenode/service.
2017-12-29 19:51:06,215 INFO org.apache.hadoop.hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
2017-12-29 19:51:06,216 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://master100:50070
2017-12-29 19:51:06,697 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-12-29 19:51:06,740 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2017-12-29 19:51:06,880 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-12-29 19:51:06,992 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-12-29 19:51:06,992 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-12-29 19:51:06,998 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-12-29 19:51:07,588 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-12-29 19:51:07,600 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-12-29 19:51:07,882 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2017-12-29 19:51:07,882 INFO org.mortbay.log: jetty-6.1.26
2017-12-29 19:51:10,275 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: 'signature.secret' configuration not set, using a random value as secret
2017-12-29 19:51:11,307 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@master100:50070
2017-12-29 19:51:11,622 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-12-29 19:51:12,433 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2017-12-29 19:51:13,061 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2017-12-29 19:51:13,061 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2017-12-29 19:51:13,078 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-12-29 19:51:13,092 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2017 十二月 29 19:51:13
2017-12-29 19:51:13,111 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2017-12-29 19:51:13,112 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-12-29 19:51:13,191 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2017-12-29 19:51:13,191 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2017-12-29 19:51:13,824 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2017-12-29 19:51:13,829 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2017-12-29 19:51:13,830 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2017-12-29 19:51:13,830 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2017-12-29 19:51:13,830 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2017-12-29 19:51:13,830 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2017-12-29 19:51:13,830 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2017-12-29 19:51:13,830 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2017-12-29 19:51:13,830 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2017-12-29 19:51:13,918 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2017-12-29 19:51:13,919 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2017-12-29 19:51:13,919 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2017-12-29 19:51:13,920 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Determined nameservice ID: aaaaa
2017-12-29 19:51:13,920 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: true
2017-12-29 19:51:13,944 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2017-12-29 19:51:17,726 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2017-12-29 19:51:17,726 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-12-29 19:51:17,729 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2017-12-29 19:51:17,729 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2017-12-29 19:51:17,844 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2017-12-29 19:51:18,072 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2017-12-29 19:51:18,072 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-12-29 19:51:18,073 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2017-12-29 19:51:18,073 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2017-12-29 19:51:18,101 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-12-29 19:51:18,101 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2017-12-29 19:51:18,101 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2017-12-29 19:51:18,122 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2017-12-29 19:51:18,129 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-12-29 19:51:18,196 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2017-12-29 19:51:18,196 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-12-29 19:51:18,203 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 966.7 MB = 297.0 KB
2017-12-29 19:51:18,204 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2017-12-29 19:51:18,297 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2017-12-29 19:51:18,297 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2017-12-29 19:51:18,304 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2017-12-29 19:51:18,555 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop2/dfs/name/in_use.lock acquired by nodename 3973@master100
2017-12-29 19:51:24,238 WARN org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory: The property 'ssl.client.truststore.location' has not been set, no TrustStore will be loaded
2017-12-29 19:51:28,484 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:28,489 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:28,489 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:29,503 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:29,504 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:30,490 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:30,506 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:30,507 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:31,493 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:31,509 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:31,509 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:32,269 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:51:32,494 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:32,510 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:32,511 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:33,272 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:51:33,496 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:33,513 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:33,514 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:34,274 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8007 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:51:34,499 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:34,517 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:34,531 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:35,281 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9015 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:51:35,501 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:35,533 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:35,534 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:36,285 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10019 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:51:36,518 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:36,536 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:36,537 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:37,287 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11020 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-29 19:51:37,525 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:37,539 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:37,540 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:38,288 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12021 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: Call From master100/192.168.1.100 to slave101:8485 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, 192.168.1.102:8485: Call From master100/192.168.1.100 to slave102:8485 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused]
2017-12-29 19:51:38,527 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:38,534 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: Call From master100/192.168.1.100 to slave101:8485 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
192.168.1.102:8485: Call From master100/192.168.1.100 to slave102:8485 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:636)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:279)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:955)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:700)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:529)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:751)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:735)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1473)
2017-12-29 19:51:38,570 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2017-12-29 19:51:39,132 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
2017-12-29 19:51:39,615 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2017-12-29 19:51:39,616 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /opt/hadoop2/dfs/name/current/fsimage_0000000000000000000
2017-12-29 19:51:39,676 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=true, haEnabled=true, isRollingUpgrade=false)
2017-12-29 19:51:39,677 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2017-12-29 19:51:39,681 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 21374 msecs
2017-12-29 19:51:43,613 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to master100:8020
2017-12-29 19:51:43,668 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-12-29 19:51:43,832 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2017-12-29 19:51:44,210 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2017-12-29 19:51:44,345 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2017-12-29 19:51:44,347 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2017-12-29 19:51:44,347 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 31 secs
2017-12-29 19:51:44,347 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
2017-12-29 19:51:44,347 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2017-12-29 19:51:44,908 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-12-29 19:51:44,921 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2017-12-29 19:51:44,985 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: master100/192.168.1.100:8020
2017-12-29 19:51:44,985 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2017-12-29 19:51:45,018 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node at slave101/192.168.1.101:8020 every 120 seconds.
2017-12-29 19:51:45,090 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN at http://slave101:50070
Serving checkpoints at http://master100:50070
2017-12-29 19:51:46,118 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:46,238 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@27e95e3 expecting start txid #1
2017-12-29 19:51:46,247 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=1&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a, http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=1&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-29 19:51:46,290 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=1&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a, http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=1&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 1
2017-12-29 19:51:46,291 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=1&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 1
2017-12-29 19:51:47,120 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:48,124 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:49,127 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:50,013 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader: replaying edit log: 1/2 transactions completed. (50%)
2017-12-29 19:51:50,014 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=1&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a, http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=1&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 3 seconds
2017-12-29 19:51:50,018 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@44a26b5c expecting start txid #3
2017-12-29 19:51:50,018 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=3&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a, http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=3&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-29 19:51:50,018 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=3&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a, http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=3&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 1
2017-12-29 19:51:50,019 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=3&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 1
2017-12-29 19:51:50,033 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=3&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a, http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=3&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-29 19:51:50,034 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3368838 expecting start txid #5
2017-12-29 19:51:50,034 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=5&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a, http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=5&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-29 19:51:50,034 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=5&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a, http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=5&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 1
2017-12-29 19:51:50,035 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=5&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 1
2017-12-29 19:51:50,129 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:50,336 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=5&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a, http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=5&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 514 edits # 8 loaded in 0 seconds
2017-12-29 19:51:50,336 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@7129162d expecting start txid #13
2017-12-29 19:51:50,337 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=13&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a, http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=13&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-29 19:51:50,337 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=13&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a, http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=13&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 1
2017-12-29 19:51:50,337 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=13&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 1
2017-12-29 19:51:50,389 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=13&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a, http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=13&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 480 edits # 7 loaded in 0 seconds
2017-12-29 19:51:50,391 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Loaded 19 edits starting from txid 0 
2017-12-29 19:51:51,130 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:52,133 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:53,136 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:54,139 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:55,585 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:51:55,665 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(192.168.1.102, datanodeUuid=39baae53-80c7-4807-a492-8cd1ad4291cf, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-291bf135-e81a-466b-8cca-005142eed37a;nsid=18366549;c=0) storage 39baae53-80c7-4807-a492-8cd1ad4291cf
2017-12-29 19:51:55,752 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/192.168.1.102:50010
2017-12-29 19:51:55,793 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(192.168.1.103, datanodeUuid=f82ecc71-3014-4c25-9c75-013de0470b2c, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-291bf135-e81a-466b-8cca-005142eed37a;nsid=18366549;c=0) storage f82ecc71-3014-4c25-9c75-013de0470b2c
2017-12-29 19:51:55,795 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/192.168.1.103:50010
2017-12-29 19:51:55,800 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(192.168.1.101, datanodeUuid=c1a65381-b373-45ea-8031-47c9f6c4e577, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-291bf135-e81a-466b-8cca-005142eed37a;nsid=18366549;c=0) storage c1a65381-b373-45ea-8031-47c9f6c4e577
2017-12-29 19:51:55,804 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/192.168.1.101:50010
2017-12-29 19:51:56,514 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-b50a7f4e-71dd-4065-a0c8-0dde4734ec7d for DN 192.168.1.103:50010
2017-12-29 19:51:56,522 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-7cdd7c35-81c1-401d-ac3b-cde27a144a3d for DN 192.168.1.102:50010
2017-12-29 19:51:56,571 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-fa575c26-9138-4923-adfe-224bf6e42868 for DN 192.168.1.101:50010
2017-12-29 19:51:56,806 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from DatanodeStorage[DS-7cdd7c35-81c1-401d-ac3b-cde27a144a3d,DISK,NORMAL] after starting up or becoming active. Its block contents are no longer considered stale
2017-12-29 19:51:56,811 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from DatanodeStorage[DS-b50a7f4e-71dd-4065-a0c8-0dde4734ec7d,DISK,NORMAL] after starting up or becoming active. Its block contents are no longer considered stale
2017-12-29 19:51:56,811 INFO BlockStateChange: BLOCK* processReport: from storage DS-b50a7f4e-71dd-4065-a0c8-0dde4734ec7d node DatanodeRegistration(192.168.1.103, datanodeUuid=f82ecc71-3014-4c25-9c75-013de0470b2c, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-291bf135-e81a-466b-8cca-005142eed37a;nsid=18366549;c=0), blocks: 2, hasStaleStorages: false, processing time: 1 msecs
2017-12-29 19:51:56,819 INFO BlockStateChange: BLOCK* processReport: from storage DS-7cdd7c35-81c1-401d-ac3b-cde27a144a3d node DatanodeRegistration(192.168.1.102, datanodeUuid=39baae53-80c7-4807-a492-8cd1ad4291cf, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-291bf135-e81a-466b-8cca-005142eed37a;nsid=18366549;c=0), blocks: 2, hasStaleStorages: false, processing time: 74 msecs
2017-12-29 19:51:56,895 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from DatanodeStorage[DS-fa575c26-9138-4923-adfe-224bf6e42868,DISK,NORMAL] after starting up or becoming active. Its block contents are no longer considered stale
2017-12-29 19:51:56,896 INFO BlockStateChange: BLOCK* processReport: from storage DS-fa575c26-9138-4923-adfe-224bf6e42868 node DatanodeRegistration(192.168.1.101, datanodeUuid=c1a65381-b373-45ea-8031-47c9f6c4e577, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-291bf135-e81a-466b-8cca-005142eed37a;nsid=18366549;c=0), blocks: 2, hasStaleStorages: false, processing time: 1 msecs
2017-12-29 19:52:04,045 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Stopping services started for standby state
2017-12-29 19:52:04,045 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:337)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-29 19:52:04,074 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2017-12-29 19:52:04,083 WARN org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory: The property 'ssl.client.truststore.location' has not been set, no TrustStore will be loaded
2017-12-29 19:52:04,118 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Starting recovery process for unclosed journal segments...
2017-12-29 19:52:04,460 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Successfully started new epoch 2
2017-12-29 19:52:04,461 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Beginning recovery of unclosed segment starting at txid 20
2017-12-29 19:52:04,770 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Recovery prepare phase complete. Responses:
192.168.1.101:8485: segmentState { startTxId: 20 endTxId: 20 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 19
192.168.1.102:8485: segmentState { startTxId: 20 endTxId: 20 isInProgress: true } lastWriterEpoch: 1 lastCommittedTxId: 19
2017-12-29 19:52:04,772 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Using longest log: 192.168.1.101:8485=segmentState {
  startTxId: 20
  endTxId: 20
  isInProgress: true
}
lastWriterEpoch: 1
lastCommittedTxId: 19

2017-12-29 19:52:05,162 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:05,175 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt/hadoop2/dfs/name/current
2017-12-29 19:52:05,259 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000020 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000020-0000000000000000020
2017-12-29 19:52:05,287 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Catching up to latest edits from old active before taking over writer role in edits logs
2017-12-29 19:52:05,305 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@52234cc4 expecting start txid #20
2017-12-29 19:52:05,305 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=20&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a, http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=20&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a, /opt/hadoop2/dfs/name/current/edits_0000000000000000020-0000000000000000020
2017-12-29 19:52:05,306 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=20&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a, http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=20&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 20
2017-12-29 19:52:05,306 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=20&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 20
2017-12-29 19:52:05,352 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=20&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a, http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=20&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a, /opt/hadoop2/dfs/name/current/edits_0000000000000000020-0000000000000000020 of size 1048576 edits # 1 loaded in 0 seconds
2017-12-29 19:52:05,352 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Loaded 1 edits starting from txid 19 
2017-12-29 19:52:05,352 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: Marking all datandoes as stale
2017-12-29 19:52:05,355 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Reprocessing replication and invalidation queues
2017-12-29 19:52:05,355 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2017-12-29 19:52:05,356 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Will take over writing edit logs at txnid 21
2017-12-29 19:52:05,374 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 21
2017-12-29 19:52:05,865 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-12-29 19:52:05,865 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning because of pending operations
2017-12-29 19:52:05,889 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 2
2017-12-29 19:52:05,889 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2017-12-29 19:52:05,889 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2017-12-29 19:52:05,889 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2017-12-29 19:52:05,889 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2017-12-29 19:52:05,889 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 529 msec
2017-12-29 19:52:05,933 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 68 millisecond(s).
2017-12-29 19:52:06,163 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:07,129 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: there are no corrupt file blocks.
2017-12-29 19:52:07,165 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:08,167 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:09,169 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:11,171 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:12,173 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:13,175 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:14,176 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:15,178 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:16,184 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:17,189 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:18,191 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:19,204 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:20,206 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:21,208 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:22,172 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: there are no corrupt file blocks.
2017-12-29 19:52:22,211 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:23,213 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:24,216 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:26,219 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:27,222 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:28,225 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:29,227 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:30,230 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:31,231 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:32,233 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:33,235 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:34,239 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:35,241 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:35,866 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 19:52:35,867 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 19:52:37,246 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:38,250 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:39,252 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:40,254 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:41,255 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:42,257 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:43,262 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:44,267 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:45,274 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:46,275 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:47,278 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:48,281 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:49,283 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:50,287 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:51,292 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:52,295 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:53,301 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:54,307 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:56,311 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:57,313 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:58,315 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:52:59,323 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:00,325 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:01,328 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:03,335 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:05,340 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:05,867 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 19:53:05,868 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 19:53:06,350 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:07,353 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:08,355 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:09,359 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:10,362 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:12,373 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:13,375 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:14,377 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:15,379 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:16,381 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:17,385 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:18,065 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: there are no corrupt file blocks.
2017-12-29 19:53:18,391 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:19,396 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:19,521 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: there are no corrupt file blocks.
2017-12-29 19:53:21,400 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:22,405 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:25,411 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:26,413 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:27,415 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:28,419 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:29,493 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:30,496 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:31,498 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:32,500 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:33,502 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:34,503 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:35,868 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 19:53:35,869 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 19:53:36,508 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:37,510 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:38,512 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:39,515 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:40,539 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:41,541 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:42,544 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:43,550 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:44,552 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:45,555 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:53:45,557 WARN org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Remote journal 192.168.1.103:8485 failed to write txns 21-21. Will try to write to this JN again after the next log roll.
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy9.journal(Unknown Source)
	at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolTranslatorPB.journal(QJournalProtocolTranslatorPB.java:167)
	at org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel$7.call(IPCLoggerChannel.java:357)
	at org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel$7.call(IPCLoggerChannel.java:350)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 10 more
2017-12-29 19:53:45,559 WARN org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Took 11054ms to send a batch of 1 edits (17 bytes) to remote journal 192.168.1.103:8485
2017-12-29 19:54:05,869 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 19:54:05,870 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 19:54:35,872 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30003 milliseconds
2017-12-29 19:54:35,873 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 19:54:50,713 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 19:54:50,714 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 19:54:50,714 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 21
2017-12-29 19:54:50,716 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 42 29 
2017-12-29 19:54:50,743 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 3 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 68 30 
2017-12-29 19:54:50,759 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000021 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000021-0000000000000000023
2017-12-29 19:54:50,759 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 24
2017-12-29 19:54:51,728 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:54:52,730 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:54:53,732 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:54:54,734 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:54:55,737 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:54:56,739 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:54:57,741 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:54:58,743 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:55:00,746 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:55:01,748 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:55:02,758 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:55:03,762 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:55:04,765 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:55:05,767 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:55:05,873 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 19:55:05,874 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 19:55:07,770 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:55:08,772 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:55:10,775 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:55:11,777 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:55:13,779 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:55:14,781 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:55:15,789 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:55:16,791 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:55:17,793 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:55:18,795 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:55:19,797 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:55:20,799 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:55:21,800 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:55:22,802 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:55:23,806 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:55:24,808 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:55:35,875 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 19:55:35,876 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 19:56:05,876 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 19:56:05,877 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 19:56:35,877 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 19:56:35,877 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 19:56:50,915 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 19:56:50,915 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 19:56:50,915 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 24
2017-12-29 19:56:50,916 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 7 9 
2017-12-29 19:56:50,933 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 23 10 
2017-12-29 19:56:50,945 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000024 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000024-0000000000000000025
2017-12-29 19:56:50,945 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 26
2017-12-29 19:56:51,928 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:56:52,930 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:56:53,932 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:56:54,935 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:56:56,939 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:56:57,941 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:56:58,943 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:56:59,946 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:57:00,947 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:57:01,949 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:57:02,974 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:57:03,976 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:57:04,979 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:57:05,877 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 19:57:05,878 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 19:57:05,989 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:57:06,990 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:57:09,033 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:57:10,036 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:57:11,037 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:57:12,039 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:57:13,042 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:57:14,047 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:57:15,049 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:57:16,050 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:57:17,053 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:57:18,056 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:57:19,063 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:57:20,065 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:57:21,067 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:57:22,071 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:57:23,073 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:57:35,878 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 19:57:35,879 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 19:58:05,879 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 19:58:05,879 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 19:58:35,880 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 19:58:35,881 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 19:58:51,077 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 19:58:51,077 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 19:58:51,077 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 26
2017-12-29 19:58:51,078 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 7 11 
2017-12-29 19:58:51,106 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 32 14 
2017-12-29 19:58:51,114 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000026 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000026-0000000000000000027
2017-12-29 19:58:51,114 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 28
2017-12-29 19:58:53,099 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:58:54,106 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:58:56,109 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:58:57,111 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:58:58,113 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:58:59,116 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:59:00,118 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:59:01,121 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:59:02,123 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:59:03,125 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:59:04,132 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:59:05,134 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:59:05,881 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 19:59:05,882 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 19:59:06,136 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:59:07,138 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:59:08,140 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:59:09,142 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:59:10,145 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:59:12,147 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:59:13,150 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:59:14,152 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:59:15,157 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:59:16,161 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:59:17,163 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:59:18,166 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:59:19,168 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:59:20,170 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:59:21,172 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:59:22,174 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:59:23,176 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:59:24,179 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 19:59:35,882 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 19:59:35,883 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:00:05,883 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:00:05,883 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 20:00:35,885 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 20:00:35,886 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 20:00:51,224 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 20:00:51,225 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 20:00:51,225 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 28
2017-12-29 20:00:51,225 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 6 14 
2017-12-29 20:00:51,289 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 31 53 
2017-12-29 20:00:51,304 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000028 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000028-0000000000000000029
2017-12-29 20:00:51,305 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 30
2017-12-29 20:00:52,238 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:00:53,240 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:00:54,242 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:00:55,244 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:00:56,247 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:00:57,248 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:00:58,251 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:00:59,253 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:01:00,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:01:02,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:01:03,267 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:01:04,269 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:01:05,272 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:01:05,886 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:01:05,887 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:01:06,274 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:01:07,276 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:01:08,278 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:01:09,280 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:01:10,282 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:01:11,285 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:01:12,287 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:01:13,292 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:01:14,296 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:01:15,298 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:01:17,299 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:01:18,302 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:01:19,315 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:01:21,319 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:01:23,322 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:01:24,324 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:01:25,326 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:01:35,889 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 20:01:35,890 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2017-12-29 20:02:05,889 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:02:05,889 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 20:02:35,891 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 20:02:35,891 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 20:02:51,496 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 20:02:51,496 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 20:02:51,496 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 30
2017-12-29 20:02:51,497 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 43 23 
2017-12-29 20:02:51,514 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 58 23 
2017-12-29 20:02:51,538 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000030 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000030-0000000000000000031
2017-12-29 20:02:51,538 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 32
2017-12-29 20:02:52,509 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:02:53,511 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:02:54,513 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:02:55,516 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:02:56,518 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:02:58,524 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:02:59,527 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:03:01,529 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:03:02,532 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:03:03,533 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:03:04,539 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:03:05,541 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:03:05,892 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:03:05,893 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:03:06,543 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:03:07,545 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:03:08,547 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:03:09,549 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:03:11,553 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:03:13,557 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:03:14,559 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:03:16,561 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:03:17,566 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:03:18,568 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:03:19,570 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:03:20,572 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:03:22,575 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:03:23,577 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:03:24,580 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:03:25,582 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:03:26,584 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:03:27,587 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:03:35,893 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:03:35,894 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:04:05,894 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:04:05,895 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 20:04:35,896 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:04:35,896 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:04:51,677 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 20:04:51,677 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 20:04:51,678 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 32
2017-12-29 20:04:51,678 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 11 12 
2017-12-29 20:04:51,707 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 39 13 
2017-12-29 20:04:51,721 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000032 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000032-0000000000000000033
2017-12-29 20:04:51,722 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 34
2017-12-29 20:04:53,685 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:04:54,688 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:04:55,690 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:04:57,695 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:04:58,697 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:04:59,699 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:05:00,702 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:05:02,708 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:05:03,710 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:05:04,714 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:05:05,719 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:05:05,896 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:05:05,897 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:05:06,723 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:05:08,729 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:05:09,733 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:05:10,735 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:05:11,737 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:05:13,741 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:05:14,745 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:05:15,751 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:05:16,753 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:05:18,759 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:05:20,763 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:05:21,765 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:05:22,767 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:05:23,769 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:05:24,773 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:05:25,776 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:05:26,790 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:05:27,792 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:05:28,794 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:05:35,901 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-12-29 20:05:35,904 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 3 millisecond(s).
2017-12-29 20:06:05,902 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:06:05,903 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:06:35,905 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30003 milliseconds
2017-12-29 20:06:35,907 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2017-12-29 20:06:51,918 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 20:06:51,919 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 20:06:51,919 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 34
2017-12-29 20:06:51,920 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 12 11 
2017-12-29 20:06:51,946 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 35 13 
2017-12-29 20:06:51,967 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000034 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000034-0000000000000000035
2017-12-29 20:06:51,967 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 36
2017-12-29 20:06:52,936 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:06:53,943 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:06:54,948 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:06:55,950 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:06:56,953 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:06:57,957 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:06:59,962 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:07:00,964 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:07:01,966 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:07:02,969 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:07:03,982 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:07:05,906 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:07:05,909 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2017-12-29 20:07:05,985 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:07:06,990 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:07:07,992 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:07:08,997 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:07:09,999 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:07:11,001 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:07:12,004 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:07:13,006 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:07:14,008 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:07:15,015 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:07:16,019 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:07:17,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:07:18,025 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:07:19,028 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:07:21,031 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:07:22,036 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:07:23,040 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:07:24,042 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:07:25,044 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:07:35,908 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 20:07:35,908 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 20:08:05,909 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:08:05,910 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:08:35,910 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:08:35,911 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:08:52,129 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 20:08:52,129 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 20:08:52,129 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 36
2017-12-29 20:08:52,130 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 8 18 
2017-12-29 20:08:52,168 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 43 21 
2017-12-29 20:08:52,190 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000036 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000036-0000000000000000037
2017-12-29 20:08:52,190 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 38
2017-12-29 20:08:53,144 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:08:54,146 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:08:56,151 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:08:57,169 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:08:58,172 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:08:59,174 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:09:00,178 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:09:01,181 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:09:02,192 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:09:04,195 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:09:05,200 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:09:05,911 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:09:05,913 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:09:06,203 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:09:07,205 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:09:08,207 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:09:09,209 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:09:10,212 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:09:11,216 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:09:13,220 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:09:14,225 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:09:15,228 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:09:16,234 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:09:18,245 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:09:19,248 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:09:20,251 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:09:21,254 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:09:22,257 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:09:23,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:09:24,263 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:09:25,267 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:09:27,270 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:09:35,913 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 20:09:35,913 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 20:10:05,915 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:10:05,915 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:10:35,915 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:10:35,916 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:10:52,512 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 20:10:52,512 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 20:10:52,512 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 38
2017-12-29 20:10:52,513 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 8 13 
2017-12-29 20:10:52,532 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 26 14 
2017-12-29 20:10:52,546 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000038 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000038-0000000000000000039
2017-12-29 20:10:52,546 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 40
2017-12-29 20:10:53,524 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:10:54,526 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:10:56,528 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:10:58,530 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:10:59,532 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:11:01,534 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:11:02,536 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:11:03,543 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:11:04,547 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:11:05,551 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:11:05,916 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:11:05,917 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 20:11:06,557 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:11:07,560 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:11:08,563 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:11:09,565 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:11:10,567 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:11:11,569 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:11:12,571 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:11:13,573 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:11:14,582 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:11:16,593 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:11:17,598 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:11:18,601 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:11:19,603 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:11:20,605 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:11:21,612 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:11:23,616 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:11:24,618 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:11:25,621 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:11:26,624 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:11:27,641 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:11:35,917 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:11:35,918 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:12:05,918 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:12:05,919 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:12:35,924 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-12-29 20:12:35,924 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:12:52,688 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 20:12:52,688 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 20:12:52,688 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 40
2017-12-29 20:12:52,689 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 19 13 
2017-12-29 20:12:52,725 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 52 15 
2017-12-29 20:12:52,745 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000040 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000040-0000000000000000041
2017-12-29 20:12:52,747 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 42
2017-12-29 20:12:53,712 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:12:54,714 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:12:55,716 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:12:56,719 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:12:57,721 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:12:58,724 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:13:00,727 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:13:02,730 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:13:03,734 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:13:04,736 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:13:05,742 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:13:05,924 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:13:05,925 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:13:06,745 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:13:08,748 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:13:10,753 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:13:11,757 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:13:13,768 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:13:14,779 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:13:15,781 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:13:17,784 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:13:18,786 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:13:19,791 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:13:20,793 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:13:21,795 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:13:22,831 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:13:24,835 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:13:25,837 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:13:26,839 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:13:27,841 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:13:28,843 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:13:29,845 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:13:35,925 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:13:35,926 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 20:14:05,928 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30003 milliseconds
2017-12-29 20:14:05,930 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:14:35,931 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30003 milliseconds
2017-12-29 20:14:35,932 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:14:52,912 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 20:14:52,912 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 20:14:52,912 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 42
2017-12-29 20:14:52,913 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 10 12 
2017-12-29 20:14:52,947 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 41 14 
2017-12-29 20:14:52,967 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000042 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000042-0000000000000000043
2017-12-29 20:14:52,967 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 44
2017-12-29 20:14:53,947 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:14:54,949 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:14:55,951 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:14:56,953 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:14:58,958 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:14:59,961 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:15:01,964 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:15:02,967 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:15:03,971 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:15:04,974 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:15:05,932 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:15:05,934 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2017-12-29 20:15:05,980 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:15:06,982 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:15:07,986 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:15:08,989 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:15:09,992 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:15:10,994 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:15:11,997 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:15:13,001 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:15:15,004 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:15:16,007 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:15:17,012 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:15:18,014 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:15:19,017 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:15:20,019 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:15:21,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:15:22,025 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:15:23,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:15:24,029 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:15:25,031 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:15:26,033 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:15:35,939 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30007 milliseconds
2017-12-29 20:15:35,940 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:16:05,941 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 20:16:05,942 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:16:35,956 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30015 milliseconds
2017-12-29 20:16:35,957 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:16:53,137 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 20:16:53,138 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 20:16:53,138 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 44
2017-12-29 20:16:53,138 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 9 16 
2017-12-29 20:16:53,168 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 37 17 
2017-12-29 20:16:53,178 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000044 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000044-0000000000000000045
2017-12-29 20:16:53,178 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 46
2017-12-29 20:16:54,143 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:16:55,145 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:16:56,147 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:16:57,149 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:16:58,151 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:17:00,154 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:17:01,156 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:17:02,158 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:17:03,160 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:17:04,162 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:17:05,167 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:17:05,957 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:17:05,958 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:17:06,169 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:17:07,197 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:17:08,199 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:17:09,201 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:17:10,203 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:17:11,211 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:17:12,214 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:17:13,217 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:17:14,219 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:17:16,225 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:17:17,226 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:17:18,230 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:17:19,231 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:17:20,234 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:17:21,236 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:17:22,238 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:17:23,240 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:17:24,243 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:17:25,247 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:17:35,960 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30003 milliseconds
2017-12-29 20:17:35,961 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:18:05,963 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30003 milliseconds
2017-12-29 20:18:05,965 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2017-12-29 20:18:35,965 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:18:35,965 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:18:53,285 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 20:18:53,285 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 20:18:53,285 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 46
2017-12-29 20:18:53,286 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 5 11 
2017-12-29 20:18:53,310 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 28 12 
2017-12-29 20:18:53,322 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000046 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000046-0000000000000000047
2017-12-29 20:18:53,322 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 48
2017-12-29 20:18:54,296 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:18:56,299 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:18:57,301 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:18:58,303 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:18:59,305 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:19:01,307 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:19:02,317 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:19:04,320 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:19:05,324 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:19:05,965 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:19:05,966 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:19:06,326 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:19:07,333 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:19:08,335 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:19:09,337 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:19:10,342 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:19:11,345 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:19:13,348 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:19:14,356 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:19:15,359 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:19:17,362 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:19:18,364 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:19:19,370 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:19:21,373 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:19:22,375 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:19:23,377 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:19:25,381 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:19:26,383 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:19:27,386 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:19:28,390 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:19:29,392 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:19:30,394 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:19:35,966 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:19:35,967 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:20:05,967 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:20:05,968 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:20:35,968 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 20:20:35,968 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:20:53,443 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 20:20:53,443 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 20:20:53,443 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 48
2017-12-29 20:20:53,444 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 5 10 
2017-12-29 20:20:53,467 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 27 11 
2017-12-29 20:20:53,480 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000048 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000048-0000000000000000049
2017-12-29 20:20:53,481 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 50
2017-12-29 20:20:54,454 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:20:55,456 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:20:56,459 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:20:57,461 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:20:58,463 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:20:59,465 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:21:00,467 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:21:01,471 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:21:02,475 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:21:03,477 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:21:04,482 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:21:05,486 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:21:05,968 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:21:05,970 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2017-12-29 20:21:06,488 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:21:07,491 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:21:08,493 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:21:09,495 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:21:10,498 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:21:11,500 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:21:12,502 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:21:13,505 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:21:14,511 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:21:15,514 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:21:16,517 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:21:17,519 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:21:18,521 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:21:19,523 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:21:20,526 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:21:21,528 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:21:22,530 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:21:23,532 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:21:35,969 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:21:35,970 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:22:05,970 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:22:05,970 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 20:22:35,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 20:22:35,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:22:53,646 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 20:22:53,646 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 20:22:53,646 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 50
2017-12-29 20:22:53,647 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 7 18 
2017-12-29 20:22:53,671 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 30 19 
2017-12-29 20:22:53,682 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000050 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000050-0000000000000000051
2017-12-29 20:22:53,682 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 52
2017-12-29 20:22:54,657 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:22:55,660 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:22:56,665 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:22:57,667 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:22:58,669 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:22:59,672 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:23:00,676 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:23:01,678 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:23:02,680 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:23:03,681 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:23:04,685 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:23:05,973 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:23:05,974 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:23:06,691 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:23:07,693 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:23:09,695 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:23:10,696 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:23:11,698 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:23:12,701 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:23:13,703 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:23:14,705 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:23:15,708 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:23:16,713 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:23:17,715 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:23:18,717 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:23:19,719 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:23:20,721 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:23:21,723 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:23:22,726 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:23:23,728 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:23:24,731 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:23:25,733 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:23:35,974 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:23:35,975 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:24:05,975 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:24:05,975 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 20:24:35,977 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:24:35,977 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:24:53,845 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 20:24:53,846 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 20:24:53,846 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 52
2017-12-29 20:24:53,846 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 10 12 
2017-12-29 20:24:53,918 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 72 22 
2017-12-29 20:24:53,929 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000052 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000052-0000000000000000053
2017-12-29 20:24:53,930 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 54
2017-12-29 20:24:54,859 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:24:55,861 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:24:56,863 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:24:58,865 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:25:00,867 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:25:01,869 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:25:02,871 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:25:03,873 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:25:04,876 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:25:05,878 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:25:05,977 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:25:05,978 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:25:06,916 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:25:07,918 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:25:08,920 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:25:09,922 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:25:10,925 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:25:11,980 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:25:12,982 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:25:13,984 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:25:14,986 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:25:15,988 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:25:16,994 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:25:17,996 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:25:18,998 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:25:20,000 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:25:21,002 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:25:22,004 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:25:23,006 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:25:24,008 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:25:25,010 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:25:27,012 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:25:35,978 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:25:35,979 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:26:05,979 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:26:05,980 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:26:35,980 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:26:35,981 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:26:55,561 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 20:26:55,562 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 20:26:55,562 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 54
2017-12-29 20:26:55,562 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 13 143 
2017-12-29 20:26:55,579 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 29 144 
2017-12-29 20:26:55,587 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000054 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000054-0000000000000000055
2017-12-29 20:26:55,587 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 56
2017-12-29 20:26:56,567 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:26:57,569 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:26:59,571 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:27:00,574 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:27:01,576 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:27:03,579 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:27:04,581 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:27:05,583 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:27:05,981 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:27:05,981 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 20:27:06,586 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:27:07,589 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:27:08,593 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:27:09,594 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:27:10,596 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:27:11,598 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:27:12,601 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:27:13,603 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:27:14,607 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:27:16,611 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:27:18,615 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:27:19,617 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:27:20,625 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:27:21,628 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:27:22,630 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:27:23,632 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:27:24,634 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:27:25,636 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:27:26,639 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:27:27,641 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:27:28,643 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:27:29,645 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:27:35,982 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:27:35,983 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:28:05,983 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:28:05,984 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:28:35,984 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:28:35,985 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 20:28:55,681 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 20:28:55,682 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 20:28:55,682 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 56
2017-12-29 20:28:55,682 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 4 10 
2017-12-29 20:28:55,701 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 21 10 
2017-12-29 20:28:55,714 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000056 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000056-0000000000000000057
2017-12-29 20:28:55,714 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 58
2017-12-29 20:28:56,694 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:28:57,697 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:28:58,699 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:28:59,708 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:29:00,709 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:29:01,711 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:29:02,713 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:29:03,716 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:29:04,717 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:29:05,720 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:29:05,985 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:29:05,986 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:29:06,724 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:29:07,728 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:29:08,730 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:29:09,732 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:29:10,734 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:29:11,736 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:29:12,740 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:29:13,743 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:29:14,745 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:29:15,747 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:29:16,751 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:29:17,753 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:29:18,755 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:29:19,757 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:29:20,760 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:29:21,763 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:29:22,765 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:29:23,767 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:29:24,769 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:29:25,771 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:29:35,986 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:29:35,988 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:30:05,987 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:30:05,988 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:30:35,988 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:30:35,989 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:30:55,891 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 20:30:55,891 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 20:30:55,892 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 58
2017-12-29 20:30:55,892 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 7 10 
2017-12-29 20:30:55,915 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 29 11 
2017-12-29 20:30:55,925 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000058 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000058-0000000000000000059
2017-12-29 20:30:55,925 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 60
2017-12-29 20:30:57,900 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:30:58,912 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:30:59,914 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:31:00,916 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:31:01,918 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:31:02,921 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:31:03,924 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:31:05,928 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:31:05,990 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 20:31:05,991 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:31:06,930 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:31:07,932 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:31:08,953 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:31:09,955 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:31:11,957 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:31:12,959 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:31:13,961 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:31:15,964 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:31:16,966 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:31:17,968 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:31:18,970 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:31:19,972 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:31:22,031 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:31:23,032 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:31:24,038 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:31:25,040 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:31:26,042 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:31:27,044 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:31:28,046 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:31:29,048 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:31:30,050 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:31:31,052 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:31:35,991 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:31:35,992 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:32:05,999 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30008 milliseconds
2017-12-29 20:32:06,000 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:32:36,000 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:32:36,001 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:32:56,133 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 20:32:56,133 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 20:32:56,133 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 60
2017-12-29 20:32:56,134 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 5 12 
2017-12-29 20:32:56,159 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 29 13 
2017-12-29 20:32:56,195 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000060 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000060-0000000000000000061
2017-12-29 20:32:56,195 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 62
2017-12-29 20:32:57,148 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:32:58,150 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:32:59,152 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:33:00,154 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:33:01,157 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:33:02,159 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:33:03,161 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:33:04,163 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:33:05,167 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:33:06,000 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 20:33:06,002 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2017-12-29 20:33:06,170 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:33:07,175 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:33:08,178 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:33:09,180 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:33:10,182 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:33:12,186 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:33:13,188 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:33:14,193 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:33:15,195 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:33:17,202 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:33:18,207 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:33:19,217 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:33:21,233 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:33:22,238 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:33:23,240 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:33:24,243 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:33:25,247 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:33:26,250 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:33:27,254 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:33:28,262 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:33:29,266 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:33:36,001 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:33:36,002 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:34:06,002 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:34:06,003 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:34:36,003 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:34:36,003 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 20:34:56,424 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 20:34:56,424 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 20:34:56,424 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 62
2017-12-29 20:34:56,425 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 6 14 
2017-12-29 20:34:56,575 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 155 15 
2017-12-29 20:34:56,587 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000062 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000062-0000000000000000063
2017-12-29 20:34:56,587 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 64
2017-12-29 20:34:57,460 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:34:58,570 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:34:59,577 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:35:01,579 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:35:02,581 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:35:03,584 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:35:05,588 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:35:06,005 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 20:35:06,006 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 20:35:06,591 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:35:07,593 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:35:09,597 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:35:10,629 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:35:11,633 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:35:12,635 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:35:13,638 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:35:14,649 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:35:15,651 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:35:16,655 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:35:17,661 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:35:18,667 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:35:19,670 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:35:20,712 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:35:21,717 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:35:23,719 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:35:24,723 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:35:25,729 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:35:26,731 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:35:27,733 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:35:28,735 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:35:29,737 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:35:30,740 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:35:36,006 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:35:36,007 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:36:06,007 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:36:06,008 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 20:36:36,009 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 20:36:36,010 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 20:36:56,756 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 20:36:56,757 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 20:36:56,757 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 64
2017-12-29 20:36:56,758 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 7 12 
2017-12-29 20:36:56,785 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 32 14 
2017-12-29 20:36:56,972 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000064 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000064-0000000000000000065
2017-12-29 20:36:56,972 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 66
2017-12-29 20:36:57,772 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:36:58,775 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:36:59,777 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:37:00,778 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:37:01,781 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:37:02,783 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:37:03,786 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:37:04,797 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:37:05,801 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:37:06,011 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:37:06,011 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:37:06,803 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:37:07,819 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:37:08,822 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:37:09,825 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:37:10,828 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:37:11,830 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:37:12,832 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:37:13,834 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:37:14,836 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:37:15,838 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:37:16,846 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:37:17,854 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:37:18,860 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:37:19,863 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:37:20,864 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:37:21,872 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:37:22,878 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:37:23,881 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:37:24,884 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:37:26,888 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:37:27,890 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:37:36,011 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:37:36,012 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:38:06,012 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:38:06,013 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:38:36,013 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:38:36,014 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:38:57,298 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 20:38:57,298 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 20:38:57,298 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 66
2017-12-29 20:38:57,300 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 13 97 
2017-12-29 20:38:57,376 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 86 99 
2017-12-29 20:38:57,389 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000066 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000066-0000000000000000067
2017-12-29 20:38:57,390 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 68
2017-12-29 20:38:58,310 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:39:00,314 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:39:02,326 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:39:03,328 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:39:04,330 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:39:05,332 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:39:06,014 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:39:06,014 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 20:39:06,334 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:39:07,336 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:39:08,338 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:39:09,342 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:39:10,372 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:39:11,376 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:39:12,378 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:39:13,380 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:39:14,384 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:39:15,386 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:39:16,392 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:39:18,394 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:39:20,402 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:39:21,404 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:39:22,413 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:39:23,419 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:39:24,421 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:39:25,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:39:26,426 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:39:27,429 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:39:28,432 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:39:30,435 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:39:31,438 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:39:32,440 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:39:36,015 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:39:36,016 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:40:06,016 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:40:06,017 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:40:36,017 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:40:36,018 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:40:57,603 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 20:40:57,603 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 20:40:57,603 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 68
2017-12-29 20:40:57,603 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 8 17 
2017-12-29 20:40:57,664 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 68 18 
2017-12-29 20:40:57,679 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000068 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000068-0000000000000000069
2017-12-29 20:40:57,679 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 70
2017-12-29 20:40:58,623 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:40:59,631 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:41:00,633 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:41:01,636 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:41:02,638 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:41:03,643 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:41:05,646 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:41:06,018 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:41:06,019 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:41:06,648 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:41:07,650 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:41:08,652 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:41:09,661 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:41:10,667 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:41:12,673 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:41:14,677 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:41:15,680 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:41:16,682 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:41:17,684 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:41:18,686 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:41:19,688 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:41:20,692 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:41:21,699 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:41:22,702 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:41:23,712 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:41:24,714 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:41:25,717 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:41:26,722 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:41:27,727 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:41:28,730 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:41:29,732 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:41:30,734 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:41:36,019 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:41:36,024 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:42:06,023 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30004 milliseconds
2017-12-29 20:42:06,024 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:42:36,026 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30003 milliseconds
2017-12-29 20:42:36,027 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:42:57,833 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 20:42:57,833 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 20:42:57,833 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 70
2017-12-29 20:42:57,833 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 12 13 
2017-12-29 20:42:57,899 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 76 14 
2017-12-29 20:42:57,914 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000070 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000070-0000000000000000071
2017-12-29 20:42:57,915 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 72
2017-12-29 20:42:58,842 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:42:59,846 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:43:00,848 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:43:01,850 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:43:02,852 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:43:03,854 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:43:04,858 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:43:05,866 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:43:06,027 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:43:06,027 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 20:43:06,875 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:43:07,884 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:43:08,899 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:43:09,901 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:43:10,904 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:43:11,907 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:43:12,910 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:43:13,912 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:43:14,918 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:43:15,925 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:43:16,928 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:43:17,930 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:43:18,985 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:43:19,987 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:43:20,989 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:43:21,992 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:43:22,995 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:43:23,997 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:43:25,008 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:43:27,011 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:43:28,013 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:43:29,018 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:43:36,029 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:43:36,029 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:44:06,030 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:44:06,030 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:44:36,030 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:44:36,031 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:44:58,104 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 20:44:58,104 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 20:44:58,104 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 72
2017-12-29 20:44:58,105 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 6 13 
2017-12-29 20:44:58,230 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 130 14 
2017-12-29 20:44:58,241 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000072 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000072-0000000000000000073
2017-12-29 20:44:58,242 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 74
2017-12-29 20:44:59,122 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:45:00,124 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:45:01,126 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:45:02,128 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:45:03,130 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:45:04,132 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:45:05,134 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:45:06,031 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:45:06,032 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:45:06,136 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:45:07,138 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:45:08,157 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:45:09,173 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:45:10,175 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:45:11,178 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:45:12,180 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:45:13,182 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:45:14,184 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:45:15,186 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:45:16,189 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:45:18,192 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:45:19,194 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:45:20,199 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:45:21,201 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:45:22,203 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:45:23,205 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:45:24,208 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:45:25,210 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:45:27,214 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:45:28,216 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:45:29,219 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:45:30,221 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:45:36,032 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 20:45:36,032 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:46:06,032 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:46:06,033 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:46:36,033 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:46:36,034 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:46:58,431 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 20:46:58,432 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 20:46:58,432 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 74
2017-12-29 20:46:58,433 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 10 13 
2017-12-29 20:46:59,568 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:47:01,105 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:47:02,594 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:47:02,599 WARN org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Took 4163ms to send a batch of 1 edits (17 bytes) to remote journal 192.168.1.102:8485
2017-12-29 20:47:03,836 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:47:04,298 WARN org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Took 5864ms to send a batch of 1 edits (17 bytes) to remote journal 192.168.1.101:8485
2017-12-29 20:47:06,053 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30020 milliseconds
2017-12-29 20:47:06,185 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7176 ms (timeout=20000 ms) for a response for sendEdits. Succeeded so far: [192.168.1.102:8485]
2017-12-29 20:47:13,753 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:47:13,780 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 7763 7607 
2017-12-29 20:47:13,809 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000074 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000074-0000000000000000075
2017-12-29 20:47:13,809 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 76
2017-12-29 20:47:15,295 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1378ms
No GCs detected
2017-12-29 20:47:15,979 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 9926 millisecond(s).
2017-12-29 20:47:16,292 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:47:17,295 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:47:18,304 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:47:19,311 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:47:20,313 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:47:22,328 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:47:23,332 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:47:24,340 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:47:25,347 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:47:26,352 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:47:27,363 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:47:28,369 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:47:29,417 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:47:30,421 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:47:31,424 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:47:32,430 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:47:33,433 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:47:34,437 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:47:35,442 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:47:36,054 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 20:47:36,054 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:47:36,447 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:47:37,449 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:47:38,452 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:47:39,454 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:47:40,457 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:47:41,487 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:48:06,058 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-12-29 20:48:06,059 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:48:36,059 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:48:36,060 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:49:06,063 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30004 milliseconds
2017-12-29 20:49:06,064 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:49:16,183 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 20:49:16,183 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 20:49:16,183 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 76
2017-12-29 20:49:16,184 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 7 31 
2017-12-29 20:49:16,261 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 82 32 
2017-12-29 20:49:16,297 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000076 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000076-0000000000000000077
2017-12-29 20:49:16,298 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 78
2017-12-29 20:49:17,213 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:49:18,216 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:49:19,219 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:49:20,220 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:49:21,222 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:49:22,226 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:49:24,228 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:49:25,230 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:49:26,232 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:49:27,233 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:49:29,240 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:49:31,248 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:49:32,250 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:49:33,253 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:49:34,255 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:49:35,262 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:49:36,064 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:49:36,065 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:49:36,265 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:49:38,268 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:49:39,270 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:49:40,272 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:49:42,278 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:49:43,280 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:49:44,282 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:49:45,284 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:49:46,287 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:49:47,289 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:49:48,291 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:49:49,292 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:49:50,296 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:49:51,298 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:50:06,065 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:50:06,066 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:50:36,067 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 20:50:36,068 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:51:06,068 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:51:06,069 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:51:16,484 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 20:51:16,484 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 20:51:16,484 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 78
2017-12-29 20:51:16,485 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 8 13 
2017-12-29 20:51:16,503 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 24 15 
2017-12-29 20:51:16,650 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000078 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000078-0000000000000000079
2017-12-29 20:51:16,650 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 80
2017-12-29 20:51:17,501 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:18,504 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:19,520 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:20,522 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:21,525 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:23,527 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:24,529 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:25,532 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:26,535 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:27,572 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:28,593 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:29,601 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:30,603 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:31,605 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:32,607 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:33,610 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:34,612 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:35,614 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:36,069 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:51:36,070 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:51:36,618 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:37,622 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:38,631 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:39,634 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:41,638 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:42,641 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:43,644 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:44,646 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:45,650 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:47,660 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:48,046 WARN org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory: The property 'ssl.client.truststore.location' has not been set, no TrustStore will be loaded
2017-12-29 20:51:48,169 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.04s at 0.00 KB/s
2017-12-29 20:51:48,170 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000079 size 594 bytes.
2017-12-29 20:51:48,197 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 0
2017-12-29 20:51:48,663 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:49,665 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:50,670 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:51,672 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:52,674 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:53,677 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:55,740 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:56,743 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:57,745 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:58,749 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:51:59,752 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:52:00,757 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:52:06,069 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 20:52:06,071 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:52:36,070 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:52:36,071 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:53:06,071 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:53:06,072 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:53:16,770 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 20:53:16,770 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 20:53:16,771 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 80
2017-12-29 20:53:16,772 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 8 10 
2017-12-29 20:53:16,824 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 58 12 
2017-12-29 20:53:16,843 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000080 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000080-0000000000000000081
2017-12-29 20:53:16,843 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 82
2017-12-29 20:53:17,800 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:53:18,805 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:53:20,810 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:53:21,813 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:53:22,816 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:53:23,819 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:53:24,821 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:53:25,824 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:53:27,832 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:53:28,837 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:53:29,846 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:53:30,849 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:53:31,851 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:53:32,853 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:53:33,855 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:53:35,858 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:53:36,073 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 20:53:36,074 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 20:53:36,861 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:53:37,863 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:53:38,867 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:53:39,869 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:53:40,874 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:53:41,877 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:53:42,879 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:53:43,881 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:53:44,883 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:53:45,887 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:53:46,890 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:53:47,895 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:53:48,898 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:53:49,900 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:54:06,075 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:54:06,076 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2017-12-29 20:54:36,076 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 20:54:36,077 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:55:06,077 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:55:06,078 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:55:17,136 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 20:55:17,136 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 20:55:17,136 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 82
2017-12-29 20:55:17,137 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 13 95 
2017-12-29 20:55:17,175 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 50 96 
2017-12-29 20:55:17,195 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000082 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000082-0000000000000000083
2017-12-29 20:55:17,196 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 84
2017-12-29 20:55:18,150 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:55:19,152 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:55:20,154 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:55:21,156 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:55:22,158 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:55:23,161 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:55:24,165 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:55:26,167 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:55:27,169 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:55:28,172 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:55:29,181 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:55:30,183 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:55:31,186 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:55:32,188 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:55:33,190 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:55:34,193 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:55:35,196 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:55:36,078 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:55:36,079 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:55:36,200 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:55:37,203 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:55:38,205 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:55:39,213 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:55:40,221 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:55:41,224 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:55:42,227 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:55:44,230 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:55:45,232 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:55:46,234 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:55:47,235 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:55:48,237 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:55:49,239 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:56:06,078 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 20:56:06,079 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:56:36,079 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:56:36,080 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:57:06,080 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:57:06,081 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:57:17,323 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 20:57:17,323 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 20:57:17,323 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 84
2017-12-29 20:57:17,324 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 7 13 
2017-12-29 20:57:17,370 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 52 14 
2017-12-29 20:57:17,383 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000084 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000084-0000000000000000085
2017-12-29 20:57:17,384 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 86
2017-12-29 20:57:18,338 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:57:19,340 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:57:20,343 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:57:21,346 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:57:22,348 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:57:23,351 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:57:24,352 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:57:25,355 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:57:27,358 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:57:28,360 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:57:29,367 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:57:30,368 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:57:31,371 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:57:32,373 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:57:33,376 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:57:34,378 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:57:35,381 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:57:36,081 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:57:36,081 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 20:57:36,383 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:57:37,385 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:57:38,387 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:57:39,390 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:57:40,393 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:57:41,395 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:57:42,397 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:57:43,399 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:57:44,401 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:57:45,403 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:57:46,405 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:57:47,407 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:57:48,409 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:58:06,083 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 20:58:06,085 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2017-12-29 20:58:36,083 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 20:58:36,084 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:59:06,084 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:59:06,085 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 20:59:17,546 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 20:59:17,547 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 20:59:17,547 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 86
2017-12-29 20:59:17,557 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 11 11 
2017-12-29 20:59:17,725 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 176 13 
2017-12-29 20:59:17,741 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000086 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000086-0000000000000000087
2017-12-29 20:59:17,741 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 88
2017-12-29 20:59:18,562 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:59:19,564 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:59:20,566 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:59:21,571 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:59:22,573 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:59:24,575 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:59:26,578 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:59:27,580 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:59:28,582 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:59:30,584 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:59:31,594 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:59:32,596 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:59:33,599 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:59:34,601 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:59:35,603 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:59:36,085 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 20:59:36,086 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 20:59:36,605 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:59:37,607 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:59:38,611 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:59:39,614 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:59:40,615 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:59:41,621 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:59:42,623 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:59:43,626 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:59:44,631 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:59:45,633 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:59:46,635 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:59:47,637 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:59:48,639 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:59:49,643 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 20:59:50,650 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:00:06,087 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:00:06,087 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:00:36,087 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:00:36,088 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:01:06,088 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:01:06,089 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:01:17,954 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 21:01:17,955 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 21:01:17,955 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 88
2017-12-29 21:01:17,955 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 6 11 
2017-12-29 21:01:18,006 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 37 31 
2017-12-29 21:01:18,015 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000088 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000088-0000000000000000089
2017-12-29 21:01:18,016 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 90
2017-12-29 21:01:18,979 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:01:19,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:01:20,982 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:01:21,984 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:01:22,986 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:01:23,988 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:01:24,991 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:01:25,994 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:01:26,996 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:01:27,998 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:01:29,001 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:01:30,005 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:01:31,007 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:01:32,010 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:01:33,014 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:01:34,035 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:01:35,037 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:01:36,040 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:01:36,089 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:01:36,089 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 21:01:37,044 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:01:38,046 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:01:39,050 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:01:40,051 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:01:41,053 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:01:42,055 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:01:43,057 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:01:44,059 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:01:45,061 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:01:46,064 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:01:47,066 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:01:48,068 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:02:06,090 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:02:06,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:02:36,092 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:02:36,093 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2017-12-29 21:03:06,092 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:03:06,093 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:03:18,118 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 21:03:18,119 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 21:03:18,119 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 90
2017-12-29 21:03:18,120 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 5 9 
2017-12-29 21:03:18,175 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 59 10 
2017-12-29 21:03:18,191 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000090 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000090-0000000000000000091
2017-12-29 21:03:18,192 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 92
2017-12-29 21:03:19,131 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:03:20,134 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:03:22,138 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:03:23,141 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:03:24,144 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:03:26,147 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:03:27,150 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:03:28,157 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:03:29,160 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:03:30,162 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:03:31,167 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:03:32,170 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:03:33,209 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:03:34,213 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:03:35,218 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:03:36,094 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 21:03:36,095 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:03:36,230 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:03:37,232 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:03:38,234 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:03:39,236 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:03:40,242 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:03:41,249 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:03:42,253 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:03:43,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:03:44,262 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:03:45,267 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:03:46,269 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:03:47,271 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:03:48,273 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:03:49,275 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:03:50,278 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:04:06,095 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:04:06,096 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:04:36,099 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30003 milliseconds
2017-12-29 21:04:36,100 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2017-12-29 21:05:06,099 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:05:06,100 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:05:18,418 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 21:05:18,418 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 21:05:18,418 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 92
2017-12-29 21:05:18,419 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 8 65 
2017-12-29 21:05:18,514 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 102 65 
2017-12-29 21:05:18,533 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000092 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000092-0000000000000000093
2017-12-29 21:05:18,533 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 94
2017-12-29 21:05:19,433 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:05:20,437 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:05:21,438 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:05:22,441 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:05:23,447 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:05:24,450 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:05:25,453 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:05:26,455 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:05:27,457 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:05:28,460 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:05:29,466 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:05:30,468 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:05:31,470 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:05:32,472 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:05:33,474 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:05:34,476 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:05:35,479 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:05:36,100 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:05:36,101 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:05:36,482 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:05:37,484 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:05:38,486 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:05:39,490 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:05:40,492 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:05:41,494 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:05:42,499 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:05:43,583 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:05:44,585 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:05:46,587 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:05:47,589 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:05:48,591 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:05:49,594 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:06:06,102 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 21:06:06,103 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:06:36,103 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 21:06:36,103 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:07:06,103 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:07:06,104 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:07:18,719 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 21:07:18,719 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 21:07:18,719 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 94
2017-12-29 21:07:18,720 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 9 13 
2017-12-29 21:07:19,201 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 489 14 
2017-12-29 21:07:19,215 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000094 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000094-0000000000000000095
2017-12-29 21:07:19,215 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 96
2017-12-29 21:07:20,163 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:07:21,168 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:07:22,170 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:07:23,172 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:07:24,174 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:07:26,177 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:07:27,179 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:07:28,181 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:07:29,183 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:07:30,185 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:07:31,190 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:07:32,195 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:07:33,197 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:07:34,200 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:07:35,202 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:07:36,104 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:07:36,105 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 21:07:36,204 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:07:37,206 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:07:38,209 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:07:39,211 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:07:40,213 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:07:42,219 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:07:43,221 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:07:44,223 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:07:45,227 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:07:46,229 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:07:47,234 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:07:49,237 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:07:50,239 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:07:51,241 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:07:52,243 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:08:06,106 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 21:08:06,106 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 21:08:36,108 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:08:36,109 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:09:06,108 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:09:06,109 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:09:19,468 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 21:09:19,469 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 21:09:19,469 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 96
2017-12-29 21:09:19,469 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 8 35 
2017-12-29 21:09:19,614 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 148 39 
2017-12-29 21:09:19,702 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000096 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000096-0000000000000000097
2017-12-29 21:09:19,702 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 98
2017-12-29 21:09:20,545 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:09:21,547 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:09:22,549 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:09:23,551 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:09:24,553 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:09:26,555 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:09:28,564 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:09:30,568 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:09:31,570 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:09:33,573 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:09:35,578 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:09:36,110 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 21:09:36,111 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:09:37,580 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:09:38,582 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:09:39,584 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:09:40,586 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:09:41,588 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:09:42,589 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:09:43,591 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:09:44,593 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:09:45,595 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:09:46,598 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:09:47,650 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:09:48,652 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:09:49,655 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:09:50,658 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:09:52,661 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:09:53,662 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:09:54,664 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:09:55,666 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:09:56,692 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:10:06,111 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:10:06,112 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:10:36,112 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:10:36,113 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:11:06,112 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 21:11:06,113 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:11:19,961 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 21:11:19,962 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 21:11:19,962 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 98
2017-12-29 21:11:19,963 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 17 32 
2017-12-29 21:11:20,036 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 88 33 
2017-12-29 21:11:20,051 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000098 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000098-0000000000000000099
2017-12-29 21:11:20,051 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 100
2017-12-29 21:11:20,976 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:11:21,979 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:11:22,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:11:23,983 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:11:24,985 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:11:25,987 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:11:26,989 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:11:28,011 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:11:29,016 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:11:30,019 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:11:31,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:11:32,038 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:11:33,040 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:11:34,048 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:11:35,050 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:11:36,052 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:11:36,113 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 21:11:36,113 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:11:37,055 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:11:38,057 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:11:40,063 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:11:41,065 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:11:42,070 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:11:43,072 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:11:44,074 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:11:46,077 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:11:47,079 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:11:48,083 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:11:49,085 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:11:50,089 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:11:51,100 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:11:53,101 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:12:06,113 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:12:06,113 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 21:12:36,114 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:12:36,114 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 21:13:06,116 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:13:06,116 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:13:20,229 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 21:13:20,229 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 21:13:20,229 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 100
2017-12-29 21:13:20,230 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 7 10 
2017-12-29 21:13:20,321 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 97 11 
2017-12-29 21:13:20,331 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000100 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000100-0000000000000000101
2017-12-29 21:13:20,331 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 102
2017-12-29 21:13:21,283 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:13:22,285 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:13:23,287 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:13:24,290 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:13:25,292 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:13:26,294 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:13:28,297 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:13:30,303 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:13:31,305 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:13:32,308 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:13:33,318 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:13:34,322 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:13:35,324 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:13:36,116 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:13:36,117 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:13:36,327 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:13:38,329 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:13:39,363 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:13:40,367 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:13:41,370 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:13:42,373 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:13:43,375 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:13:45,380 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:13:46,382 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:13:48,384 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:13:49,386 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:13:50,389 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:13:51,396 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:13:52,399 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:13:53,402 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:13:54,404 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:13:55,407 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:14:06,117 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:14:06,118 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 21:14:36,181 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30064 milliseconds
2017-12-29 21:14:36,182 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:15:06,181 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 21:15:06,182 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:15:20,444 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 21:15:20,444 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 21:15:20,444 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 102
2017-12-29 21:15:20,445 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 8 13 
2017-12-29 21:15:20,467 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 29 14 
2017-12-29 21:15:20,488 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000102 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000102-0000000000000000103
2017-12-29 21:15:20,488 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 104
2017-12-29 21:15:21,459 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:15:23,465 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:15:24,467 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:15:25,469 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:15:26,471 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:15:27,473 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:15:28,475 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:15:29,477 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:15:31,482 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:15:32,488 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:15:34,496 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:15:35,498 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:15:36,182 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:15:36,183 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:15:36,500 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:15:37,502 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:15:38,530 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:15:39,532 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:15:40,534 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:15:41,536 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:15:43,539 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:15:44,541 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:15:45,545 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:15:46,547 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:15:47,549 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:15:48,551 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:15:49,553 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:15:50,555 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:15:51,558 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:15:52,560 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:15:53,562 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:15:55,565 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:16:06,183 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:16:06,184 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:16:36,184 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:16:36,184 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 21:17:06,185 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:17:06,186 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:17:21,231 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 21:17:21,231 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 21:17:21,231 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 104
2017-12-29 21:17:21,231 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 7 13 
2017-12-29 21:17:21,272 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 47 14 
2017-12-29 21:17:21,281 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000104 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000104-0000000000000000105
2017-12-29 21:17:21,282 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 106
2017-12-29 21:17:22,262 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:17:24,264 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:17:25,266 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:17:26,268 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:17:27,270 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:17:28,273 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:17:29,275 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:17:30,279 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:17:31,281 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:17:32,283 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:17:33,291 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:17:34,294 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:17:35,296 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:17:36,186 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:17:36,187 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:17:36,298 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:17:37,300 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:17:38,303 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:17:40,306 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:17:41,316 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:17:42,319 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:17:43,322 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:17:44,329 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:17:45,331 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:17:46,333 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:17:47,335 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:17:49,338 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:17:50,340 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:17:51,342 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:17:52,344 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:17:53,346 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:17:54,348 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:18:06,187 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:18:06,188 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:18:36,188 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:18:36,189 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:19:06,188 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 21:19:06,189 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:19:21,398 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 21:19:21,398 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 21:19:21,399 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 106
2017-12-29 21:19:21,399 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 5 13 
2017-12-29 21:19:21,428 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 33 14 
2017-12-29 21:19:21,440 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000106 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000106-0000000000000000107
2017-12-29 21:19:21,440 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 108
2017-12-29 21:19:22,404 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:19:23,406 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:19:24,414 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:19:25,416 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:19:26,418 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:19:27,420 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:19:28,422 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:19:29,424 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:19:30,426 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:19:31,428 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:19:32,434 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:19:33,437 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:19:34,439 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:19:35,441 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:19:36,188 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 21:19:36,190 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2017-12-29 21:19:36,444 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:19:37,447 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:19:38,482 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:19:39,484 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:19:40,486 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:19:41,488 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:19:42,497 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:19:44,502 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:19:45,504 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:19:46,506 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:19:47,509 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:19:48,512 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:19:49,514 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:19:50,522 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:19:51,524 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:19:52,527 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:20:06,190 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 21:20:06,190 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 21:20:36,192 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 21:20:36,192 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 21:21:06,197 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-12-29 21:21:06,199 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2017-12-29 21:21:21,638 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 21:21:21,638 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 21:21:21,638 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 108
2017-12-29 21:21:21,639 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 8 13 
2017-12-29 21:21:21,670 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 38 14 
2017-12-29 21:21:21,681 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000108 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000108-0000000000000000109
2017-12-29 21:21:21,681 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 110
2017-12-29 21:21:22,646 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:21:23,648 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:21:24,650 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:21:25,652 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:21:26,654 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:21:27,656 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:21:28,658 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:21:29,662 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:21:30,664 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:21:31,666 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:21:32,671 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:21:34,674 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:21:35,676 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:21:36,199 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 21:21:36,200 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:21:36,679 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:21:37,680 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:21:38,685 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:21:40,687 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:21:41,689 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:21:42,691 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:21:43,695 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:21:44,701 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:21:45,703 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:21:46,704 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:21:47,706 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:21:48,716 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:21:49,728 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:21:50,731 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:21:51,733 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:21:52,737 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:21:54,741 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:22:06,201 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 21:22:06,202 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:22:36,202 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:22:36,202 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 21:23:06,204 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:23:06,204 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:23:21,786 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 21:23:21,786 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 21:23:21,786 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 110
2017-12-29 21:23:21,786 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 5 11 
2017-12-29 21:23:21,808 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 25 13 
2017-12-29 21:23:21,816 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000110 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000110-0000000000000000111
2017-12-29 21:23:21,817 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 112
2017-12-29 21:23:22,795 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:23:23,797 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:23:24,799 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:23:25,801 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:23:26,803 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:23:27,805 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:23:28,807 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:23:29,810 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:23:30,812 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:23:31,814 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:23:32,818 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:23:33,820 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:23:34,822 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:23:35,824 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:23:36,204 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:23:36,205 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:23:36,826 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:23:38,831 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:23:39,835 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:23:40,836 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:23:41,838 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:23:42,841 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:23:44,851 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:23:45,854 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:23:46,855 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:23:47,859 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:23:48,861 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:23:50,864 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:23:51,866 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:23:52,869 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:23:53,871 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:23:54,873 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:24:06,205 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:24:06,206 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:24:36,206 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:24:36,206 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 21:25:06,208 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:25:06,208 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:25:21,937 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 21:25:21,937 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 21:25:21,937 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 112
2017-12-29 21:25:21,938 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 7 10 
2017-12-29 21:25:21,966 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 31 14 
2017-12-29 21:25:21,985 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000112 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000112-0000000000000000113
2017-12-29 21:25:21,985 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 114
2017-12-29 21:25:22,952 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:25:23,954 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:25:25,955 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:25:26,957 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:25:27,959 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:25:28,962 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:25:29,964 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:25:30,966 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:25:31,968 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:25:32,970 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:25:33,974 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:25:34,978 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:25:35,980 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:25:36,208 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:25:36,209 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:25:36,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:25:37,983 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:25:38,985 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:25:40,988 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:25:41,990 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:25:42,997 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:25:45,000 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:25:46,002 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:25:47,004 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:25:48,005 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:25:49,008 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:25:50,010 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:25:51,012 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:25:52,014 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:25:53,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:25:54,036 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:25:55,038 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:26:06,209 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:26:06,210 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:26:36,210 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:26:36,211 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:27:06,211 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:27:06,211 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 21:27:22,206 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 21:27:22,206 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 21:27:22,207 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 114
2017-12-29 21:27:22,208 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 7 13 
2017-12-29 21:27:22,234 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 32 14 
2017-12-29 21:27:22,250 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000114 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000114-0000000000000000115
2017-12-29 21:27:22,251 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 116
2017-12-29 21:27:23,215 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:27:24,217 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:27:25,219 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:27:26,221 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:27:27,223 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:27:28,225 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:27:29,227 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:27:30,229 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:27:31,231 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:27:32,233 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:27:33,237 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:27:34,246 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:27:35,248 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:27:36,212 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:27:36,213 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:27:36,250 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:27:37,252 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:27:38,254 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:27:39,257 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:27:41,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:27:42,262 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:27:43,265 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:27:44,269 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:27:45,274 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:27:46,276 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:27:47,278 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:27:48,282 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:27:50,286 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:27:52,288 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:27:53,290 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:27:54,292 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:27:55,295 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:28:06,214 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 21:28:06,215 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:28:36,215 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:28:36,216 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:29:06,216 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:29:06,217 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 21:29:22,376 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 21:29:22,376 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 21:29:22,376 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 116
2017-12-29 21:29:22,377 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 5 11 
2017-12-29 21:29:22,401 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 26 14 
2017-12-29 21:29:22,475 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000116 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000116-0000000000000000117
2017-12-29 21:29:22,475 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 118
2017-12-29 21:29:23,385 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:29:25,389 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:29:26,391 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:29:27,393 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:29:28,395 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:29:29,429 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:29:30,432 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:29:32,435 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:29:33,437 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:29:34,439 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:29:35,442 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:29:36,217 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:29:36,218 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:29:36,445 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:29:38,448 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:29:39,450 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:29:40,451 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:29:41,453 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:29:42,456 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:29:43,458 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:29:44,460 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:29:45,463 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:29:46,467 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:29:47,469 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:29:48,474 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:29:50,483 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:29:51,485 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:29:52,488 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:29:53,491 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:29:54,493 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:29:55,495 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:29:56,498 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:30:06,217 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 21:30:06,218 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:30:36,218 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:30:36,218 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 21:31:06,220 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 21:31:06,220 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 21:31:22,749 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 21:31:22,749 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 21:31:22,749 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 118
2017-12-29 21:31:22,749 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 12 17 
2017-12-29 21:31:22,795 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 56 19 
2017-12-29 21:31:22,807 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000118 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000118-0000000000000000119
2017-12-29 21:31:22,807 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 120
2017-12-29 21:31:23,784 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:31:24,787 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:31:25,789 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:31:26,791 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:31:27,793 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:31:29,797 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:31:30,799 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:31:31,802 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:31:32,804 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:31:34,808 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:31:35,814 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:31:36,221 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:31:36,222 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:31:36,817 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:31:37,818 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:31:38,821 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:31:39,823 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:31:40,825 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:31:41,827 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:31:42,829 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:31:44,832 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:31:45,834 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:31:46,839 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:31:48,842 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:31:49,844 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:31:50,847 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:31:52,851 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:31:53,853 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:31:54,855 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:31:55,857 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:31:56,859 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:31:58,861 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:32:06,221 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 21:32:06,222 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:32:36,222 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:32:36,223 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:33:06,223 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:33:06,223 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 21:33:22,929 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 21:33:22,929 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 21:33:22,930 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 120
2017-12-29 21:33:22,930 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 7 11 
2017-12-29 21:33:22,958 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 33 13 
2017-12-29 21:33:22,979 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000120 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000120-0000000000000000121
2017-12-29 21:33:22,979 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 122
2017-12-29 21:33:23,944 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:33:24,947 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:33:25,949 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:33:26,951 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:33:27,953 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:33:29,956 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:33:30,958 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:33:31,961 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:33:32,963 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:33:33,966 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:33:34,994 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:33:35,999 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:33:36,224 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:33:36,225 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:33:38,002 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:33:39,004 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:33:40,006 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:33:41,008 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:33:42,010 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:33:43,016 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:33:45,020 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:33:46,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:33:47,032 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:33:48,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:33:49,036 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:33:50,038 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:33:51,040 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:33:52,042 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:33:53,044 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:33:54,049 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:33:55,052 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:33:56,055 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:34:06,225 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:34:06,226 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:34:36,226 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:34:36,227 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:35:06,227 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:35:06,227 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 21:35:23,250 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 21:35:23,250 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 21:35:23,250 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 122
2017-12-29 21:35:23,251 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 9 15 
2017-12-29 21:35:23,271 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 27 17 
2017-12-29 21:35:23,286 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000122 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000122-0000000000000000123
2017-12-29 21:35:23,286 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 124
2017-12-29 21:35:24,256 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:35:25,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:35:26,261 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:35:27,264 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:35:28,265 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:35:29,267 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:35:30,269 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:35:31,271 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:35:32,273 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:35:33,275 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:35:35,284 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:35:36,228 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:35:36,229 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:35:36,287 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:35:37,288 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:35:38,290 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:35:39,292 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:35:40,294 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:35:41,296 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:35:42,301 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:35:43,303 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:35:45,305 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:35:47,316 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:35:49,319 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:35:50,321 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:35:51,323 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:35:52,325 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:35:53,327 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:35:54,329 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:35:56,331 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:35:57,333 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:35:58,335 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:36:06,229 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:36:06,230 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:36:36,233 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30004 milliseconds
2017-12-29 21:36:36,234 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:37:06,235 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 21:37:06,235 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 21:37:23,508 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 21:37:23,508 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 21:37:23,509 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 124
2017-12-29 21:37:23,509 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 4 10 
2017-12-29 21:37:23,583 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 76 10 
2017-12-29 21:37:23,594 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000124 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000124-0000000000000000125
2017-12-29 21:37:23,594 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 126
2017-12-29 21:37:24,533 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:37:25,537 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:37:26,539 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:37:27,541 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:37:28,543 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:37:30,546 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:37:31,548 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:37:32,550 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:37:33,553 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:37:34,555 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:37:35,560 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:37:36,237 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:37:36,237 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:37:37,566 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:37:38,570 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:37:39,574 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:37:40,576 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:37:41,580 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:37:42,582 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:37:43,583 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:37:44,585 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:37:46,587 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:37:47,592 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:37:48,594 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:37:49,596 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:37:50,598 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:37:51,600 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:37:52,602 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:37:53,605 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:37:54,607 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:37:55,609 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:37:57,613 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:38:06,237 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 21:38:06,237 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:38:36,237 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:38:36,237 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 21:39:06,238 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:39:06,239 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:39:23,718 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 21:39:23,718 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 21:39:23,718 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 126
2017-12-29 21:39:23,719 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 7 13 
2017-12-29 21:39:23,736 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 23 14 
2017-12-29 21:39:23,782 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000126 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000126-0000000000000000127
2017-12-29 21:39:23,783 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 128
2017-12-29 21:39:24,731 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:39:25,733 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:39:26,735 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:39:27,737 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:39:28,740 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:39:29,742 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:39:30,745 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:39:31,747 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:39:32,749 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:39:33,764 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:39:34,771 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:39:35,774 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:39:36,239 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 21:39:36,239 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:39:37,778 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:39:38,785 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:39:39,787 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:39:40,790 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:39:41,792 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:39:42,794 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:39:43,796 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:39:45,800 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:39:47,805 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:39:48,807 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:39:49,809 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:39:50,811 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:39:51,813 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:39:52,816 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:39:53,818 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:39:54,820 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:39:55,822 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:39:56,823 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:40:06,239 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:40:06,240 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:40:36,240 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:40:36,241 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:41:06,241 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:41:06,254 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 13 millisecond(s).
2017-12-29 21:41:24,374 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 21:41:24,374 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 21:41:24,374 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 128
2017-12-29 21:41:24,375 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 20 27 
2017-12-29 21:41:24,400 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 44 28 
2017-12-29 21:41:24,416 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000128 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000128-0000000000000000129
2017-12-29 21:41:24,416 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 130
2017-12-29 21:41:25,379 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:41:26,383 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:41:27,386 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:41:29,388 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:41:30,390 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:41:31,393 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:41:32,395 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:41:34,398 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:41:35,400 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:41:36,242 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:41:36,242 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 21:41:36,402 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:41:37,405 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:41:38,407 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:41:39,409 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:41:41,412 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:41:42,414 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:41:43,417 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:41:44,421 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:41:45,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:41:46,425 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:41:47,427 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:41:48,435 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:41:49,437 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:41:51,439 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:41:52,441 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:41:53,445 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:41:54,448 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:41:55,450 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:41:56,452 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:41:57,454 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:41:58,456 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:42:06,244 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:42:06,244 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:42:36,245 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 21:42:36,246 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:43:06,246 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:43:06,247 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:43:24,595 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 21:43:24,595 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 21:43:24,595 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 130
2017-12-29 21:43:24,596 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 5 10 
2017-12-29 21:43:24,616 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 24 11 
2017-12-29 21:43:24,625 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000130 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000130-0000000000000000131
2017-12-29 21:43:24,625 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 132
2017-12-29 21:43:25,607 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:43:26,629 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:43:28,631 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:43:29,634 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:43:30,636 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:43:31,638 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:43:32,641 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:43:33,643 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:43:34,646 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:43:35,651 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:43:36,253 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30007 milliseconds
2017-12-29 21:43:36,253 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 21:43:37,668 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:43:38,671 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:43:39,679 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:43:40,687 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:43:42,740 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:43:43,788 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:43:44,801 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:43:45,804 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:43:46,844 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:43:47,880 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:43:49,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:43:51,023 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:43:52,032 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:43:53,040 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:43:54,063 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:43:55,075 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:43:56,129 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:43:57,135 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:43:58,142 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:43:59,237 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:44:06,256 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30003 milliseconds
2017-12-29 21:44:06,256 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 21:44:36,266 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30010 milliseconds
2017-12-29 21:44:36,279 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 13 millisecond(s).
2017-12-29 21:45:06,267 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:45:06,268 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:45:24,771 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 21:45:24,771 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 21:45:24,771 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 132
2017-12-29 21:45:24,771 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 5 10 
2017-12-29 21:45:24,819 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 52 10 
2017-12-29 21:45:24,828 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000132 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000132-0000000000000000133
2017-12-29 21:45:24,829 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 134
2017-12-29 21:45:25,790 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:45:26,792 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:45:27,794 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:45:29,797 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:45:30,799 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:45:31,801 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:45:32,803 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:45:33,805 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:45:34,807 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:45:35,809 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:45:36,268 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:45:36,268 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 21:45:37,813 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:45:38,815 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:45:39,818 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:45:40,820 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:45:41,822 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:45:43,824 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:45:44,826 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:45:45,829 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:45:46,831 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:45:47,833 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:45:48,836 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:45:49,838 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:45:50,841 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:45:52,843 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:45:53,849 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:45:55,854 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:45:56,875 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:45:57,876 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:45:58,878 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:46:00,885 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:46:06,270 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 21:46:06,271 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:46:36,270 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 21:46:36,271 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:47:06,275 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30005 milliseconds
2017-12-29 21:47:06,276 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:47:24,990 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 21:47:24,990 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 21:47:24,990 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 134
2017-12-29 21:47:24,991 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 6 9 
2017-12-29 21:47:25,038 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 23 39 
2017-12-29 21:47:25,048 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000134 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000134-0000000000000000135
2017-12-29 21:47:25,048 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 136
2017-12-29 21:47:26,002 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:47:27,004 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:47:28,006 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:47:29,008 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:47:30,010 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:47:31,013 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:47:33,017 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:47:34,019 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:47:35,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:47:36,276 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:47:36,277 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 21:47:37,023 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:47:38,028 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:47:39,030 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:47:40,032 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:47:41,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:47:43,036 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:47:44,038 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:47:45,040 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:47:46,043 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:47:48,053 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:47:49,058 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:47:50,062 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:47:51,064 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:47:52,066 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:47:53,068 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:47:54,072 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:47:56,074 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:47:57,077 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:47:58,080 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:47:59,082 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:48:00,084 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:48:06,278 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 21:48:06,279 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 21:48:36,279 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:48:36,280 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:49:06,280 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:49:06,281 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:49:25,141 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 21:49:25,141 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 21:49:25,141 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 136
2017-12-29 21:49:25,142 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 6 9 
2017-12-29 21:49:25,165 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 25 13 
2017-12-29 21:49:25,173 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000136 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000136-0000000000000000137
2017-12-29 21:49:25,173 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 138
2017-12-29 21:49:26,158 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:49:27,159 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:49:28,162 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:49:30,165 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:49:31,170 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:49:32,172 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:49:33,174 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:49:34,176 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:49:35,178 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:49:36,181 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:49:36,282 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 21:49:36,282 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 21:49:38,189 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:49:39,191 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:49:40,193 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:49:41,200 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:49:42,205 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:49:43,208 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:49:44,217 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:49:46,218 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:49:48,221 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:49:49,223 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:49:50,228 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:49:51,230 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:49:52,233 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:49:53,236 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:49:54,238 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:49:55,239 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:49:56,241 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:49:57,243 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:49:58,247 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:49:59,250 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:50:06,283 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:50:06,283 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 21:50:36,285 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:50:36,285 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:51:06,285 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:51:06,286 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:51:25,275 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 21:51:25,275 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 21:51:25,275 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 138
2017-12-29 21:51:25,276 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 7 9 
2017-12-29 21:51:25,300 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 29 10 
2017-12-29 21:51:25,312 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000138 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000138-0000000000000000139
2017-12-29 21:51:25,312 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 140
2017-12-29 21:51:26,296 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:51:27,298 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:51:28,300 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:51:29,302 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:51:30,304 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:51:31,306 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:51:32,308 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:51:33,310 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:51:34,313 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:51:36,286 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:51:36,287 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:51:36,317 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:51:38,324 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:51:39,326 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:51:40,334 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:51:41,336 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:51:43,340 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:51:44,345 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:51:45,353 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:51:46,355 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:51:47,357 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:51:48,359 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:51:48,925 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.02s at 0.00 KB/s
2017-12-29 21:51:48,926 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000139 size 595 bytes.
2017-12-29 21:51:48,962 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 79
2017-12-29 21:51:48,963 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop2/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2017-12-29 21:51:49,365 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:51:50,367 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:51:51,369 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:51:52,371 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:51:53,373 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:51:54,376 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:51:55,379 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:51:56,381 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:51:57,384 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:51:58,386 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:51:59,390 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:52:00,393 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:52:01,395 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:52:02,398 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:52:03,400 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:52:04,402 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:52:05,404 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:52:06,287 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:52:06,287 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 21:52:06,406 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:52:07,408 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:52:08,410 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:52:36,289 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:52:36,289 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:53:06,289 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:53:06,290 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:53:25,512 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 21:53:25,513 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 21:53:25,513 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 140
2017-12-29 21:53:25,513 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 4 11 
2017-12-29 21:53:25,531 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 21 12 
2017-12-29 21:53:25,542 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000140 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000140-0000000000000000141
2017-12-29 21:53:25,542 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 142
2017-12-29 21:53:26,519 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:53:27,522 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:53:29,524 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:53:30,547 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:53:31,549 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:53:32,553 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:53:33,555 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:53:34,557 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:53:35,559 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:53:36,290 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:53:36,291 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 21:53:36,562 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:53:38,570 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:53:39,572 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:53:40,574 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:53:41,576 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:53:43,579 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:53:44,582 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:53:45,583 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:53:46,586 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:53:48,588 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:53:49,590 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:53:50,595 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:53:51,596 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:53:52,599 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:53:53,600 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:53:54,603 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:53:56,606 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:53:57,608 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:53:58,610 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:53:59,612 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:54:01,614 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:54:06,292 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 21:54:06,292 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 21:54:36,294 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:54:36,294 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:55:06,295 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:55:06,295 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:55:25,664 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 21:55:25,664 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 21:55:25,664 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 142
2017-12-29 21:55:25,664 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 6 10 
2017-12-29 21:55:25,685 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 26 11 
2017-12-29 21:55:25,692 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000142 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000142-0000000000000000143
2017-12-29 21:55:25,692 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 144
2017-12-29 21:55:26,674 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:55:27,676 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:55:28,678 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:55:29,680 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:55:31,683 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:55:32,685 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:55:33,687 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:55:34,690 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:55:35,692 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:55:36,296 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 21:55:36,297 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:55:36,696 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:55:37,704 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:55:38,706 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:55:39,708 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:55:40,710 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:55:41,715 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:55:42,720 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:55:43,721 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:55:44,723 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:55:45,725 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:55:46,729 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:55:48,735 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:55:49,737 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:55:50,739 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:55:51,741 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:55:52,744 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:55:53,746 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:55:54,748 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:55:55,751 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:55:56,753 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:55:57,755 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:56:06,297 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:56:06,297 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 21:56:36,299 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 21:56:36,300 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:57:06,301 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:57:06,301 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:57:25,857 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 21:57:25,857 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 21:57:25,857 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 144
2017-12-29 21:57:25,858 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 5 10 
2017-12-29 21:57:25,895 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 41 11 
2017-12-29 21:57:25,903 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000144 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000144-0000000000000000145
2017-12-29 21:57:25,904 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 146
2017-12-29 21:57:26,887 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:57:27,889 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:57:28,891 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:57:29,893 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:57:30,895 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:57:31,898 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:57:32,901 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:57:33,903 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:57:34,905 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:57:36,303 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30003 milliseconds
2017-12-29 21:57:36,303 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 21:57:36,907 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:57:37,914 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:57:38,915 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:57:39,917 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:57:40,919 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:57:41,922 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:57:42,924 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:57:43,929 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:57:44,936 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:57:45,938 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:57:46,940 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:57:48,946 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:57:49,950 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:57:50,953 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:57:51,954 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:57:53,959 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:57:55,966 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:57:56,968 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:57:57,970 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:57:58,972 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:57:59,974 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:58:06,304 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:58:06,305 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 21:58:36,306 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 21:58:36,306 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 21:59:06,310 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30003 milliseconds
2017-12-29 21:59:06,312 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 3 millisecond(s).
2017-12-29 21:59:26,004 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 21:59:26,004 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 21:59:26,004 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 146
2017-12-29 21:59:26,004 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 5 10 
2017-12-29 21:59:26,094 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 88 17 
2017-12-29 21:59:26,104 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000146 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000146-0000000000000000147
2017-12-29 21:59:26,130 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 148
2017-12-29 21:59:27,059 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:59:28,061 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:59:29,063 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:59:30,065 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:59:31,067 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:59:32,069 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:59:33,085 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:59:35,086 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:59:36,088 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:59:36,310 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 21:59:36,311 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 21:59:37,090 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:59:38,096 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:59:39,098 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:59:40,100 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:59:41,102 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:59:42,104 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:59:43,106 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:59:44,108 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:59:45,111 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:59:46,114 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:59:47,116 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:59:48,122 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:59:50,125 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:59:51,126 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:59:52,129 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:59:53,133 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:59:54,135 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:59:55,138 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:59:56,142 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:59:57,145 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 21:59:58,147 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:00:06,311 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:00:06,315 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 4 millisecond(s).
2017-12-29 22:00:36,312 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:00:36,313 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:01:06,315 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30003 milliseconds
2017-12-29 22:01:06,315 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:01:26,656 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 22:01:26,657 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 22:01:26,657 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 148
2017-12-29 22:01:26,657 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 14 233 
2017-12-29 22:01:26,675 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 32 233 
2017-12-29 22:01:26,687 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000148 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000148-0000000000000000149
2017-12-29 22:01:26,688 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 150
2017-12-29 22:01:27,666 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:01:28,668 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:01:29,670 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:01:30,672 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:01:31,673 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:01:32,675 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:01:33,677 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:01:34,679 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:01:35,681 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:01:36,316 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:01:36,317 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:01:36,683 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:01:37,686 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:01:38,687 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:01:39,689 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:01:40,690 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:01:41,692 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:01:42,695 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:01:44,696 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:01:45,698 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:01:46,701 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:01:47,703 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:01:48,707 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:01:49,708 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:01:50,714 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:01:51,717 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:01:53,719 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:01:54,726 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:01:55,730 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:01:56,732 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:01:57,734 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:01:58,736 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:02:06,317 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:02:06,318 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:02:36,318 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:02:36,319 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:03:06,319 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 22:03:06,319 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:03:26,847 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 22:03:26,847 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 22:03:26,847 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 150
2017-12-29 22:03:26,848 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 6 11 
2017-12-29 22:03:26,866 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 23 12 
2017-12-29 22:03:26,971 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000150 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000150-0000000000000000151
2017-12-29 22:03:26,971 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 152
2017-12-29 22:03:27,859 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:03:28,860 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:03:29,863 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:03:30,865 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:03:31,867 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:03:32,869 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:03:33,871 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:03:34,873 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:03:35,875 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:03:36,319 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:03:36,320 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:03:36,877 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:03:37,886 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:03:39,888 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:03:40,890 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:03:41,892 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:03:42,894 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:03:43,896 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:03:44,898 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:03:45,903 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:03:46,905 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:03:48,908 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:03:49,916 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:03:50,919 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:03:51,923 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:03:53,926 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:03:54,928 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:03:55,930 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:03:56,932 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:03:57,934 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:03:58,936 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:03:59,937 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:04:06,319 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 22:04:06,320 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:04:36,320 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:04:36,321 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:05:06,321 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 22:05:06,321 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:05:27,116 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 22:05:27,116 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 22:05:27,116 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 152
2017-12-29 22:05:27,117 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 8 12 
2017-12-29 22:05:27,136 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 26 13 
2017-12-29 22:05:27,145 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000152 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000152-0000000000000000153
2017-12-29 22:05:27,145 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 154
2017-12-29 22:05:28,122 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:05:29,124 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:05:30,127 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:05:32,133 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:05:33,135 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:05:34,137 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:05:35,139 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:05:36,141 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:05:36,321 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 22:05:36,321 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:05:37,143 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:05:38,146 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:05:39,153 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:05:41,155 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:05:42,166 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:05:43,169 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:05:44,171 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:05:45,174 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:05:46,176 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:05:47,178 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:05:48,180 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:05:49,182 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:05:50,186 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:05:51,196 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:05:52,200 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:05:53,202 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:05:54,204 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:05:55,206 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:05:56,209 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:05:57,218 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:05:58,222 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:06:00,225 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:06:06,321 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:06:06,321 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:06:36,322 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:06:36,323 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:07:06,324 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:07:06,324 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:07:27,240 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 22:07:27,240 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 22:07:27,240 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 154
2017-12-29 22:07:27,240 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 6 10 
2017-12-29 22:07:27,259 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 23 12 
2017-12-29 22:07:27,269 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000154 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000154-0000000000000000155
2017-12-29 22:07:27,270 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 156
2017-12-29 22:07:28,251 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:07:29,253 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:07:30,255 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:07:31,257 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:07:32,259 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:07:33,266 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:07:34,269 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:07:35,271 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:07:36,273 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:07:36,324 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:07:36,325 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:07:37,275 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:07:38,283 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:07:39,287 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:07:40,289 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:07:41,303 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:07:42,305 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:07:43,307 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:07:44,311 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:07:45,313 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:07:46,315 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:07:47,317 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:07:48,320 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:07:49,323 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:07:50,325 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:07:52,327 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:07:53,330 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:07:54,336 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:07:55,340 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:07:56,342 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:07:57,344 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:07:58,346 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:08:06,324 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 22:08:06,325 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:08:36,325 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:08:36,325 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:09:06,326 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:09:06,327 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:09:27,375 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 22:09:27,376 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 22:09:27,376 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 156
2017-12-29 22:09:27,376 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 10 12 
2017-12-29 22:09:27,394 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 27 13 
2017-12-29 22:09:27,410 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000156 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000156-0000000000000000157
2017-12-29 22:09:27,410 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 158
2017-12-29 22:09:28,388 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:09:29,390 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:09:30,392 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:09:31,394 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:09:32,397 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:09:33,401 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:09:34,404 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:09:36,327 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:09:36,328 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:09:36,406 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:09:37,408 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:09:38,410 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:09:40,418 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:09:41,420 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:09:42,422 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:09:43,424 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:09:44,427 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:09:45,429 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:09:46,433 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:09:47,435 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:09:48,437 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:09:49,439 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:09:51,443 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:09:52,445 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:09:53,448 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:09:54,450 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:09:55,452 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:09:56,454 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:09:57,456 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:09:58,458 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:09:59,460 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:10:00,462 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:10:06,327 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 22:10:06,328 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:10:36,327 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 22:10:36,328 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:11:06,328 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:11:06,329 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:11:27,555 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 22:11:27,555 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 22:11:27,556 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 158
2017-12-29 22:11:27,556 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 6 10 
2017-12-29 22:11:27,573 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 22 11 
2017-12-29 22:11:27,588 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000158 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000158-0000000000000000159
2017-12-29 22:11:27,588 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 160
2017-12-29 22:11:28,568 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:11:29,571 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:11:30,572 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:11:31,574 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:11:32,577 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:11:33,579 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:11:34,583 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:11:35,585 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:11:36,328 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 22:11:36,330 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:11:36,587 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:11:37,589 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:11:38,594 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:11:39,597 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:11:40,599 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:11:41,602 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:11:42,604 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:11:43,606 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:11:44,609 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:11:45,611 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:11:46,625 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:11:47,627 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:11:49,632 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:11:51,636 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:11:52,638 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:11:53,640 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:11:54,642 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:11:55,644 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:11:56,646 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:11:57,648 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:11:58,650 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:11:59,652 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:12:06,329 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:12:06,330 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:12:36,330 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:12:36,331 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:13:06,331 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 22:13:06,331 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:13:27,744 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 22:13:27,744 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 22:13:27,744 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 160
2017-12-29 22:13:27,744 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 10 9 
2017-12-29 22:13:27,780 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 45 10 
2017-12-29 22:13:27,791 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000160 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000160-0000000000000000161
2017-12-29 22:13:27,812 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 162
2017-12-29 22:13:28,770 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:13:29,771 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:13:30,773 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:13:31,775 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:13:32,777 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:13:34,780 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:13:35,781 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:13:36,330 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 22:13:36,331 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:13:36,784 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:13:37,785 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:13:38,787 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:13:40,791 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:13:41,793 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:13:42,801 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:13:43,803 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:13:44,805 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:13:45,807 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:13:46,809 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:13:47,810 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:13:48,812 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:13:49,815 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:13:50,819 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:13:51,822 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:13:52,824 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:13:53,826 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:13:54,828 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:13:55,829 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:13:56,832 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:13:57,834 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:13:58,836 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:13:59,838 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:14:06,331 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:14:06,332 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:14:36,332 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:14:36,333 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:15:06,333 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:15:06,334 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:15:27,961 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 22:15:27,961 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 22:15:27,961 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 162
2017-12-29 22:15:27,961 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 4 14 
2017-12-29 22:15:27,989 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 30 16 
2017-12-29 22:15:28,015 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000162 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000162-0000000000000000163
2017-12-29 22:15:28,015 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 164
2017-12-29 22:15:28,983 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:15:30,985 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:15:31,987 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:15:33,993 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:15:34,995 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:15:35,999 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:15:36,334 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:15:36,335 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:15:37,003 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:15:38,004 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:15:39,007 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:15:40,011 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:15:41,017 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:15:43,020 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:15:44,022 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:15:45,025 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:15:46,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:15:47,028 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:15:48,030 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:15:49,032 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:15:50,033 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:15:51,037 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:15:53,042 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:15:55,044 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:15:56,046 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:15:57,048 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:15:58,050 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:15:59,052 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:16:00,054 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:16:01,056 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:16:02,058 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:16:03,060 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:16:06,334 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 22:16:06,335 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:16:36,335 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:16:36,335 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:17:06,337 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 22:17:06,337 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:17:28,192 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 22:17:28,192 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 22:17:28,192 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 164
2017-12-29 22:17:28,193 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 6 24 
2017-12-29 22:17:28,212 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 24 25 
2017-12-29 22:17:28,223 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000164 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000164-0000000000000000165
2017-12-29 22:17:28,223 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 166
2017-12-29 22:17:29,200 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:17:30,202 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:17:31,205 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:17:32,207 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:17:33,212 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:17:34,214 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:17:35,216 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:17:36,219 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:17:36,338 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 22:17:36,338 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:17:37,222 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:17:38,224 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:17:39,228 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:17:40,233 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:17:41,235 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:17:42,237 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:17:43,239 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:17:44,241 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:17:45,245 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:17:46,247 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:17:48,249 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:17:49,251 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:17:50,257 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:17:51,259 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:17:52,261 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:17:53,263 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:17:54,265 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:17:55,269 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:17:56,273 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:17:57,274 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:17:58,276 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:17:59,278 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:18:06,338 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:18:06,339 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:18:36,339 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:18:36,340 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:19:06,340 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:19:06,341 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:19:28,319 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 22:19:28,319 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 22:19:28,319 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 166
2017-12-29 22:19:28,320 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 5 9 
2017-12-29 22:19:28,340 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 24 10 
2017-12-29 22:19:28,349 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000166 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000166-0000000000000000167
2017-12-29 22:19:28,349 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 168
2017-12-29 22:19:29,327 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:19:30,330 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:19:31,332 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:19:32,333 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:19:33,335 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:19:34,338 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:19:35,340 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:19:36,342 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:19:36,342 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:19:36,342 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:19:37,344 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:19:38,346 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:19:39,352 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:19:40,355 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:19:41,357 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:19:42,359 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:19:43,360 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:19:44,362 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:19:45,365 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:19:46,367 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:19:47,369 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:19:48,370 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:19:49,374 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:19:50,378 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:19:52,381 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:19:53,384 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:19:54,386 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:19:55,389 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:19:56,391 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:19:57,393 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:19:58,395 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:19:59,397 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:20:06,342 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:20:06,343 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:20:36,343 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:20:36,344 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:21:06,345 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 22:21:06,346 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:21:28,492 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 22:21:28,492 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 22:21:28,492 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 168
2017-12-29 22:21:28,492 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 6 10 
2017-12-29 22:21:28,511 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 24 11 
2017-12-29 22:21:28,520 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000168 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000168-0000000000000000169
2017-12-29 22:21:28,521 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 170
2017-12-29 22:21:29,497 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:21:30,505 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:21:31,507 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:21:32,509 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:21:33,511 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:21:34,513 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:21:36,348 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30003 milliseconds
2017-12-29 22:21:36,348 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:21:36,518 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:21:37,520 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:21:38,522 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:21:39,539 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:21:41,544 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:21:42,546 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:21:43,548 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:21:44,550 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:21:45,553 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:21:46,555 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:21:47,557 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:21:48,559 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:21:49,560 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:21:50,562 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:21:51,568 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:21:52,569 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:21:53,593 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:21:54,595 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:21:55,597 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:21:56,599 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:21:57,601 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:21:58,603 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:21:59,605 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:22:00,607 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:22:06,349 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:22:06,350 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:22:36,351 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:22:36,351 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:23:06,352 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 22:23:06,352 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:23:28,633 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 22:23:28,633 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 22:23:28,633 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 170
2017-12-29 22:23:28,633 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 12 10 
2017-12-29 22:23:28,661 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 38 11 
2017-12-29 22:23:28,670 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000170 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000170-0000000000000000171
2017-12-29 22:23:28,670 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 172
2017-12-29 22:23:29,653 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:23:31,657 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:23:32,659 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:23:33,661 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:23:34,663 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:23:35,665 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:23:36,354 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 22:23:36,354 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:23:36,667 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:23:37,669 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:23:39,672 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:23:40,674 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:23:42,679 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:23:43,682 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:23:44,684 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:23:46,686 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:23:47,688 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:23:48,691 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:23:49,694 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:23:50,696 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:23:51,699 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:23:53,701 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:23:54,706 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:23:55,707 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:23:56,709 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:23:57,711 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:23:59,714 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:24:01,719 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:24:02,721 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:24:03,723 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:24:04,725 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:24:05,727 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:24:06,355 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:24:06,356 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:24:36,355 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 22:24:36,356 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:25:06,356 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:25:06,356 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:25:28,796 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 22:25:28,796 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 22:25:28,796 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 172
2017-12-29 22:25:28,797 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 6 10 
2017-12-29 22:25:28,821 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 29 11 
2017-12-29 22:25:28,833 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000172 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000172-0000000000000000173
2017-12-29 22:25:28,833 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 174
2017-12-29 22:25:29,803 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:25:31,805 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:25:32,807 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:25:33,809 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:25:34,811 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:25:35,813 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:25:36,358 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 22:25:36,358 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:25:36,815 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:25:37,819 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:25:38,821 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:25:39,823 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:25:41,830 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:25:42,833 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:25:43,835 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:25:44,837 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:25:45,841 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:25:46,843 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:25:47,845 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:25:49,848 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:25:50,850 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:25:51,852 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:25:52,859 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:25:53,872 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:25:54,875 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:25:55,876 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:25:56,879 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:25:57,890 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:25:58,892 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:26:00,895 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:26:02,899 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:26:03,900 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:26:06,358 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 22:26:06,359 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:26:36,359 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:26:36,360 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:27:06,361 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 22:27:06,362 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:27:28,960 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 22:27:28,960 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 22:27:28,960 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 174
2017-12-29 22:27:28,961 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 7 12 
2017-12-29 22:27:28,994 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 39 13 
2017-12-29 22:27:29,003 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000174 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000174-0000000000000000175
2017-12-29 22:27:29,003 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 176
2017-12-29 22:27:29,986 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:27:31,988 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:27:32,990 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:27:34,992 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:27:35,994 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:27:36,363 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 22:27:36,364 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:27:36,996 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:27:37,998 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:27:40,001 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:27:41,003 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:27:42,005 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:27:43,009 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:27:44,011 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:27:45,013 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:27:46,015 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:27:47,017 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:27:48,019 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:27:49,020 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:27:50,022 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:27:51,024 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:27:52,026 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:27:54,033 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:27:55,035 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:27:56,037 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:27:57,043 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:27:59,048 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:28:00,051 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:28:01,052 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:28:02,055 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:28:03,057 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:28:04,059 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:28:06,364 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:28:06,364 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:28:36,371 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30007 milliseconds
2017-12-29 22:28:36,371 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:29:06,372 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:29:06,373 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:29:29,156 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 22:29:29,156 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 22:29:29,156 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 176
2017-12-29 22:29:29,156 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 6 10 
2017-12-29 22:29:29,172 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 22 10 
2017-12-29 22:29:29,183 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000176 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000176-0000000000000000177
2017-12-29 22:29:29,184 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 178
2017-12-29 22:29:30,168 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:29:31,169 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:29:33,173 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:29:34,177 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:29:35,179 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:29:36,182 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:29:36,374 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 22:29:36,374 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:29:37,185 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:29:38,187 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:29:39,190 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:29:40,192 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:29:41,197 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:29:42,200 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:29:43,202 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:29:44,204 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:29:46,206 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:29:47,208 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:29:48,210 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:29:49,211 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:29:50,213 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:29:52,218 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:29:53,222 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:29:54,224 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:29:55,226 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:29:56,228 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:29:57,230 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:29:58,237 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:30:00,239 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:30:01,241 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:30:02,246 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:30:03,247 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:30:06,376 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:30:06,376 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:30:36,376 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:30:36,377 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:31:06,377 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 22:31:06,377 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:31:29,332 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 22:31:29,332 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 22:31:29,332 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 178
2017-12-29 22:31:29,332 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 5 11 
2017-12-29 22:31:29,353 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 25 12 
2017-12-29 22:31:29,363 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000178 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000178-0000000000000000179
2017-12-29 22:31:29,363 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 180
2017-12-29 22:31:30,340 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:31:31,342 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:31:32,344 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:31:33,346 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:31:34,348 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:31:36,350 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:31:36,377 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:31:36,377 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:31:37,352 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:31:38,354 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:31:39,356 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:31:40,358 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:31:41,362 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:31:43,368 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:31:44,370 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:31:45,372 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:31:46,374 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:31:47,376 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:31:48,378 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:31:49,380 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:31:50,382 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:31:51,384 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:31:52,389 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:31:53,391 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:31:54,393 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:31:55,395 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:31:56,397 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:31:57,399 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:31:58,402 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:31:59,405 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:32:00,407 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:32:01,409 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:32:06,381 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30004 milliseconds
2017-12-29 22:32:06,382 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:32:36,382 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 22:32:36,382 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:33:06,382 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:33:06,383 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:33:29,473 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 22:33:29,473 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 22:33:29,473 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 180
2017-12-29 22:33:29,474 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 7 11 
2017-12-29 22:33:29,497 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 29 12 
2017-12-29 22:33:29,507 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000180 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000180-0000000000000000181
2017-12-29 22:33:29,508 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 182
2017-12-29 22:33:30,479 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:33:31,481 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:33:32,483 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:33:33,486 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:33:34,489 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:33:35,491 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:33:36,383 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:33:36,383 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:33:36,493 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:33:37,495 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:33:38,497 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:33:39,499 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:33:40,505 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:33:41,507 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:33:42,509 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:33:43,511 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:33:44,513 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:33:45,518 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:33:46,520 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:33:47,537 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:33:48,539 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:33:50,541 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:33:51,547 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:33:52,550 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:33:53,552 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:33:55,556 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:33:56,558 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:33:57,561 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:33:58,563 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:34:00,566 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:34:01,568 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:34:02,572 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:34:06,384 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:34:06,385 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:34:36,386 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 22:34:36,387 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:35:06,387 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:35:06,388 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:35:29,621 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 22:35:29,621 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 22:35:29,621 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 182
2017-12-29 22:35:29,622 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 11 10 
2017-12-29 22:35:29,642 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 30 11 
2017-12-29 22:35:29,653 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000182 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000182-0000000000000000183
2017-12-29 22:35:29,653 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 184
2017-12-29 22:35:30,626 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:35:31,628 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:35:32,630 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:35:33,632 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:35:34,634 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:35:35,637 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:35:36,388 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:35:36,388 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:35:36,639 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:35:37,641 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:35:38,643 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:35:39,645 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:35:40,650 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:35:41,652 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:35:42,654 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:35:43,656 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:35:44,658 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:35:45,661 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:35:46,663 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:35:48,667 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:35:49,668 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:35:50,670 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:35:51,675 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:35:52,677 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:35:53,679 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:35:54,681 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:35:56,687 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:35:58,692 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:35:59,695 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:36:00,697 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:36:02,701 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:36:03,704 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:36:06,390 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 22:36:06,390 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:36:36,391 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:36:36,392 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:37:06,392 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:37:06,393 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:37:29,778 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 22:37:29,778 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 22:37:29,778 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 184
2017-12-29 22:37:29,779 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 5 11 
2017-12-29 22:37:29,818 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 44 11 
2017-12-29 22:37:29,827 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000184 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000184-0000000000000000185
2017-12-29 22:37:29,828 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 186
2017-12-29 22:37:30,809 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:37:31,811 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:37:32,813 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:37:33,815 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:37:34,817 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:37:35,819 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:37:36,392 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 22:37:36,393 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:37:36,821 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:37:38,829 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:37:39,837 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:37:41,840 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:37:42,844 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:37:43,846 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:37:44,848 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:37:45,850 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:37:46,852 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:37:47,854 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:37:48,857 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:37:49,858 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:37:50,860 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:37:51,862 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:37:52,868 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:37:53,871 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:37:54,872 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:37:55,874 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:37:56,876 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:37:57,878 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:37:58,881 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:37:59,883 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:38:01,886 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:38:02,888 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:38:06,393 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:38:06,393 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:38:36,394 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:38:36,395 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:39:06,395 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:39:06,396 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:39:29,960 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 22:39:29,960 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 22:39:29,961 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 186
2017-12-29 22:39:29,961 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 5 11 
2017-12-29 22:39:29,980 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 23 12 
2017-12-29 22:39:29,989 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000186 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000186-0000000000000000187
2017-12-29 22:39:29,989 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 188
2017-12-29 22:39:30,967 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:39:31,969 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:39:32,971 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:39:33,973 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:39:34,975 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:39:35,977 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:39:36,395 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 22:39:36,395 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:39:36,979 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:39:37,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:39:38,983 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:39:39,985 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:39:40,991 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:39:41,993 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:39:42,995 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:39:43,997 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:39:44,999 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:39:46,001 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:39:47,003 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:39:48,005 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:39:49,007 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:39:51,009 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:39:52,013 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:39:53,016 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:39:54,018 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:39:56,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:39:57,023 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:39:59,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:40:00,029 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:40:01,031 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:40:03,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:40:04,036 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:40:06,397 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 22:40:06,398 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:40:36,398 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:40:36,398 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:41:06,399 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 22:41:06,399 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:41:30,139 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 22:41:30,140 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 22:41:30,140 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 188
2017-12-29 22:41:30,140 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 6 11 
2017-12-29 22:41:30,174 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 39 12 
2017-12-29 22:41:30,215 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000188 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000188-0000000000000000189
2017-12-29 22:41:30,215 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 190
2017-12-29 22:41:31,162 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:41:32,164 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:41:33,166 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:41:35,168 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:41:36,170 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:41:36,400 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:41:36,400 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:41:37,172 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:41:38,174 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:41:39,176 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:41:40,178 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:41:41,186 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:41:42,191 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:41:43,194 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:41:44,196 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:41:45,199 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:41:46,200 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:41:47,203 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:41:48,205 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:41:49,208 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:41:50,212 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:41:51,215 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:41:53,224 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:41:54,226 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:41:56,228 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:41:57,231 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:41:58,235 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:41:59,238 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:42:00,240 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:42:01,242 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:42:03,244 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:42:04,246 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:42:06,400 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:42:06,401 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:42:36,401 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 22:42:36,401 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:43:06,401 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:43:06,402 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:43:30,320 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 22:43:30,329 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 22:43:30,329 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 190
2017-12-29 22:43:30,329 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 4 9 
2017-12-29 22:43:30,351 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 25 10 
2017-12-29 22:43:30,359 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000190 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000190-0000000000000000191
2017-12-29 22:43:30,360 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 192
2017-12-29 22:43:31,344 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:43:32,346 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:43:33,348 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:43:34,350 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:43:35,352 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:43:36,354 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:43:36,402 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:43:36,403 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:43:37,356 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:43:38,444 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:43:39,448 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:43:40,449 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:43:41,585 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:43:42,590 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:43:43,592 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:43:44,594 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:43:45,596 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:43:46,597 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:43:47,599 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:43:48,601 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:43:49,603 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:43:50,604 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:43:51,609 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:43:52,611 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:43:53,613 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:43:54,614 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:43:55,617 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:43:56,619 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:43:57,622 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:43:58,624 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:43:59,626 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:44:00,628 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:44:06,403 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:44:06,404 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:44:36,404 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:44:36,405 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:45:06,406 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 22:45:06,406 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:45:30,477 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 22:45:30,477 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 22:45:30,477 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 192
2017-12-29 22:45:30,479 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 6 12 
2017-12-29 22:45:30,497 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 23 13 
2017-12-29 22:45:30,507 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000192 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000192-0000000000000000193
2017-12-29 22:45:30,508 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 194
2017-12-29 22:45:32,488 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:45:33,490 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:45:34,492 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:45:35,494 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:45:36,407 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 22:45:36,407 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:45:36,517 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:45:37,519 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:45:38,520 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:45:39,522 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:45:40,524 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:45:42,527 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:45:43,530 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:45:44,532 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:45:45,534 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:45:46,538 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:45:47,540 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:45:48,544 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:45:49,546 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:45:50,548 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:45:51,550 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:45:52,552 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:45:53,558 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:45:54,560 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:45:55,562 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:45:56,564 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:45:57,566 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:45:59,568 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:46:00,571 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:46:01,573 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:46:02,575 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:46:03,577 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:46:06,408 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 22:46:06,409 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:46:36,409 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:46:36,410 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:47:06,410 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:47:06,411 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:47:33,042 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 22:47:33,042 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 22:47:33,042 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 194
2017-12-29 22:47:33,043 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 8 11 
2017-12-29 22:47:33,068 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 31 13 
2017-12-29 22:47:33,077 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000194 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000194-0000000000000000195
2017-12-29 22:47:33,077 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 196
2017-12-29 22:47:34,058 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:47:35,060 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:47:36,062 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:47:36,411 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 22:47:36,411 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:47:37,064 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:47:39,068 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:47:40,070 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:47:41,072 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:47:42,074 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:47:43,076 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:47:44,078 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:47:45,085 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:47:46,087 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:47:48,091 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:47:49,093 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:47:50,095 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:47:51,098 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:47:52,102 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:47:53,104 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:47:55,106 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:47:56,108 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:47:57,112 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:47:58,115 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:48:00,118 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:48:02,120 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:48:04,123 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:48:05,125 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:48:06,127 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:48:06,411 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:48:06,412 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:48:08,130 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:48:09,133 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:48:10,135 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:48:36,412 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:48:36,413 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:49:06,413 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:49:06,413 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:49:33,205 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 22:49:33,206 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 22:49:33,206 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 196
2017-12-29 22:49:33,206 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 5 10 
2017-12-29 22:49:33,222 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 20 11 
2017-12-29 22:49:33,235 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000196 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000196-0000000000000000197
2017-12-29 22:49:33,236 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 198
2017-12-29 22:49:34,215 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:49:35,217 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:49:36,220 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:49:36,415 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:49:36,417 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 3 millisecond(s).
2017-12-29 22:49:37,222 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:49:38,223 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:49:39,226 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:49:40,228 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:49:41,230 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:49:42,232 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:49:43,236 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:49:44,240 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:49:45,244 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:49:46,246 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:49:47,248 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:49:48,252 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:49:49,254 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:49:50,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:49:51,261 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:49:52,263 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:49:53,266 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:49:54,270 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:49:55,273 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:49:56,275 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:49:57,277 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:49:58,279 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:49:59,281 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:50:00,284 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:50:02,287 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:50:04,290 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:50:05,292 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:50:06,414 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 22:50:06,415 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:50:36,415 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:50:36,416 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:51:06,416 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:51:06,416 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:51:33,339 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 22:51:33,339 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 22:51:33,340 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 198
2017-12-29 22:51:33,341 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 7 10 
2017-12-29 22:51:33,366 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 30 12 
2017-12-29 22:51:33,376 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000198 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000198-0000000000000000199
2017-12-29 22:51:33,377 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 200
2017-12-29 22:51:34,357 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:51:35,389 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:51:36,391 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:51:36,418 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 22:51:36,418 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:51:37,393 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:51:39,397 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:51:40,399 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:51:41,402 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:51:42,403 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:51:43,405 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:51:44,407 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:51:45,413 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:51:46,415 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:51:47,417 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:51:48,419 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:51:49,421 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:51:49,508 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Transfer took 0.00s at 0.00 KB/s
2017-12-29 22:51:49,508 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000199 size 595 bytes.
2017-12-29 22:51:49,513 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 139
2017-12-29 22:51:49,513 INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/opt/hadoop2/dfs/name/current/fsimage_0000000000000000079, cpktTxId=0000000000000000079)
2017-12-29 22:51:51,431 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:51:53,444 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:51:54,447 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:51:55,449 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:51:56,451 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:51:57,456 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:51:58,458 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:51:59,460 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:52:01,463 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:52:02,465 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:52:03,466 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:52:05,469 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:52:06,419 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:52:06,420 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:52:06,471 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:52:07,474 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:52:08,476 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:52:10,481 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:52:11,486 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:52:12,488 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:52:13,491 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:52:14,492 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:52:15,494 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:52:17,496 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:52:19,501 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:52:20,503 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:52:21,505 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:52:36,420 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:52:36,421 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:53:06,422 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 22:53:06,423 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:53:33,518 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 22:53:33,518 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 22:53:33,518 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 200
2017-12-29 22:53:33,519 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 9 10 
2017-12-29 22:53:33,539 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 28 11 
2017-12-29 22:53:33,547 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000200 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000200-0000000000000000201
2017-12-29 22:53:33,548 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 202
2017-12-29 22:53:34,535 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:53:35,538 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:53:36,423 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:53:36,424 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:53:36,540 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:53:37,542 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:53:38,545 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:53:39,547 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:53:40,552 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:53:41,554 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:53:42,556 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:53:43,558 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:53:44,561 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:53:45,566 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:53:46,569 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:53:47,571 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:53:48,574 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:53:49,578 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:53:50,581 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:53:51,584 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:53:52,587 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:53:53,594 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:53:55,599 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:53:56,601 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:53:57,603 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:53:58,605 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:53:59,609 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:54:01,612 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:54:02,614 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:54:03,618 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:54:04,621 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:54:05,623 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:54:06,424 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 22:54:06,424 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:54:36,424 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:54:36,425 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:55:06,425 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:55:06,426 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:55:33,651 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 22:55:33,651 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 22:55:33,651 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 202
2017-12-29 22:55:33,652 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 6 9 
2017-12-29 22:55:33,671 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 24 10 
2017-12-29 22:55:33,681 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000202 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000202-0000000000000000203
2017-12-29 22:55:33,681 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 204
2017-12-29 22:55:34,659 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:55:35,661 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:55:36,427 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:55:36,427 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:55:36,663 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:55:37,665 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:55:38,667 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:55:39,669 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:55:40,671 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:55:41,673 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:55:42,675 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:55:43,677 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:55:44,681 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:55:45,692 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:55:46,694 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:55:47,697 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:55:48,699 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:55:49,701 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:55:50,705 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:55:51,707 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:55:52,709 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:55:54,711 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:55:55,718 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:55:56,721 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:55:57,723 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:55:58,726 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:55:59,729 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:56:00,730 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:56:01,737 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:56:02,739 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:56:03,741 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:56:04,744 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:56:06,426 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 22:56:06,428 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2017-12-29 22:56:36,426 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 22:56:36,427 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:57:06,427 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:57:06,428 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:57:33,908 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 22:57:33,908 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 22:57:33,908 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 204
2017-12-29 22:57:33,908 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 6 12 
2017-12-29 22:57:33,924 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 21 13 
2017-12-29 22:57:33,932 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000204 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000204-0000000000000000205
2017-12-29 22:57:33,932 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 206
2017-12-29 22:57:34,920 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:57:35,922 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:57:36,428 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:57:36,429 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:57:36,924 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:57:37,926 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:57:38,928 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:57:39,930 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:57:41,934 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:57:42,953 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:57:43,955 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:57:44,957 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:57:45,961 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:57:46,963 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:57:47,965 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:57:48,967 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:57:49,969 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:57:50,974 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:57:52,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:57:53,984 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:57:54,987 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:57:55,989 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:57:56,995 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:57:57,998 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:57:59,000 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:58:00,002 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:58:01,005 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:58:02,008 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:58:03,012 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:58:04,014 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:58:05,016 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:58:06,020 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:58:06,428 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 22:58:06,428 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:58:36,429 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:58:36,430 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 22:59:06,430 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 22:59:06,431 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:59:34,045 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 22:59:34,045 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 22:59:34,045 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 206
2017-12-29 22:59:34,046 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 9 10 
2017-12-29 22:59:34,068 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 30 11 
2017-12-29 22:59:34,077 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000206 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000206-0000000000000000207
2017-12-29 22:59:34,077 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 208
2017-12-29 22:59:35,054 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:59:36,056 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:59:36,432 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 22:59:36,432 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 22:59:37,058 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:59:38,060 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:59:39,063 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:59:40,065 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:59:41,068 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:59:42,071 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:59:43,073 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:59:44,075 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:59:45,082 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:59:46,087 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:59:48,089 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:59:49,092 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:59:50,094 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:59:51,097 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:59:52,108 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:59:53,110 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:59:54,114 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:59:56,117 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:59:57,124 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:59:58,126 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 22:59:59,128 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:00:00,130 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:00:01,132 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:00:02,135 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:00:03,137 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:00:04,139 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:00:05,142 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:00:06,144 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:00:06,434 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 23:00:06,434 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 23:00:36,435 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:00:36,436 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:01:06,436 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:01:06,437 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:01:34,191 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 23:01:34,191 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 23:01:34,192 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 208
2017-12-29 23:01:34,192 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 5 8 
2017-12-29 23:01:34,219 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 31 9 
2017-12-29 23:01:34,228 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000208 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000208-0000000000000000209
2017-12-29 23:01:34,228 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 210
2017-12-29 23:01:35,210 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:01:36,212 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:01:36,437 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:01:36,438 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:01:37,215 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:01:38,217 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:01:39,219 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:01:40,221 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:01:41,223 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:01:42,225 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:01:43,227 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:01:45,229 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:01:46,234 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:01:47,237 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:01:48,240 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:01:49,242 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:01:50,244 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:01:51,248 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:01:52,252 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:01:53,254 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:01:54,256 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:01:55,259 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:01:56,264 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:01:57,267 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:01:58,269 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:01:59,271 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:02:00,273 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:02:01,275 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:02:02,277 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:02:03,279 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:02:04,281 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:02:05,284 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:02:06,438 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 23:02:06,439 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:02:36,439 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:02:36,439 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:03:06,439 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:03:06,440 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 23:03:34,383 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 23:03:34,383 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 23:03:34,383 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 210
2017-12-29 23:03:34,383 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 7 11 
2017-12-29 23:03:34,405 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 27 12 
2017-12-29 23:03:34,419 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000210 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000210-0000000000000000211
2017-12-29 23:03:34,419 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 212
2017-12-29 23:03:35,388 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:03:36,392 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:03:36,441 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 23:03:36,441 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 23:03:38,395 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:03:39,397 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:03:40,399 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:03:41,402 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:03:42,404 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:03:43,408 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:03:44,411 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:03:45,413 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:03:46,419 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:03:48,421 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:03:49,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:03:50,433 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:03:51,436 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:03:52,440 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:03:54,441 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:03:55,443 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:03:56,448 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:03:57,450 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:03:58,453 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:04:00,455 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:04:01,457 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:04:02,459 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:04:03,462 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:04:04,464 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:04:05,474 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:04:06,442 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:04:06,442 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 23:04:06,476 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:04:07,478 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:04:08,482 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:04:36,443 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:04:36,444 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:05:06,446 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30003 milliseconds
2017-12-29 23:05:06,447 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:05:34,567 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 23:05:34,568 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 23:05:34,568 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 212
2017-12-29 23:05:34,568 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 5 10 
2017-12-29 23:05:34,778 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 211 14 
2017-12-29 23:05:34,787 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000212 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000212-0000000000000000213
2017-12-29 23:05:34,787 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 214
2017-12-29 23:05:36,447 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:05:36,447 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 23:05:36,762 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:05:37,764 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:05:38,766 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:05:39,768 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:05:40,770 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:05:41,774 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:05:42,776 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:05:43,779 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:05:44,781 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:05:45,783 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:05:46,790 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:05:47,793 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:05:48,794 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:05:49,796 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:05:50,802 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:05:51,803 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:05:52,805 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:05:53,809 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:05:54,811 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:05:55,814 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:05:56,820 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:05:58,826 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:05:59,830 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:06:00,831 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:06:01,834 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:06:02,839 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:06:03,840 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:06:04,843 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:06:05,847 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:06:06,449 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:06:06,449 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:06:06,850 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:06:36,449 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:06:36,450 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:07:06,450 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:07:06,452 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2017-12-29 23:07:34,939 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 23:07:34,939 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 23:07:34,939 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 214
2017-12-29 23:07:34,940 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 7 29 
2017-12-29 23:07:34,970 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 34 32 
2017-12-29 23:07:34,986 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000214 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000214-0000000000000000215
2017-12-29 23:07:34,987 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 216
2017-12-29 23:07:35,951 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:07:36,451 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:07:36,452 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:07:36,954 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:07:37,956 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:07:38,958 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:07:39,960 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:07:40,962 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:07:41,964 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:07:42,966 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:07:43,968 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:07:44,971 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:07:45,975 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:07:46,978 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:07:47,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:07:48,984 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:07:49,986 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:07:50,988 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:07:51,990 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:07:52,993 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:07:53,995 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:07:54,997 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:07:56,003 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:07:57,005 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:07:58,009 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:07:59,010 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:08:00,013 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:08:01,016 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:08:02,019 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:08:03,022 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:08:04,025 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:08:05,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:08:06,452 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:08:06,453 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 23:08:36,453 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:08:36,454 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:09:06,454 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:09:06,455 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:09:35,083 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 23:09:35,083 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 23:09:35,083 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 216
2017-12-29 23:09:35,084 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 5 11 
2017-12-29 23:09:35,116 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 36 12 
2017-12-29 23:09:35,124 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000216 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000216-0000000000000000217
2017-12-29 23:09:35,125 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 218
2017-12-29 23:09:36,108 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:09:36,454 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 23:09:36,455 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:09:38,110 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:09:39,112 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:09:40,114 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:09:41,116 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:09:42,118 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:09:43,120 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:09:45,123 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:09:46,126 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:09:47,128 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:09:48,135 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:09:49,137 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:09:50,139 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:09:52,142 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:09:53,146 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:09:54,148 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:09:55,151 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:09:56,153 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:09:57,155 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:09:58,158 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:09:59,163 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:10:00,164 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:10:01,170 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:10:02,174 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:10:03,176 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:10:04,178 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:10:05,180 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:10:06,182 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:10:06,455 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 23:10:06,455 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:10:07,184 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:10:08,187 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:10:36,455 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:10:36,456 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:11:06,456 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:11:06,457 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:11:35,254 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 23:11:35,254 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 23:11:35,255 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 218
2017-12-29 23:11:35,256 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 5 10 
2017-12-29 23:11:35,280 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 27 11 
2017-12-29 23:11:35,288 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000218 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000218-0000000000000000219
2017-12-29 23:11:35,288 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 220
2017-12-29 23:11:36,271 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:11:36,457 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:11:36,458 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:11:38,274 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:11:39,277 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:11:40,279 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:11:41,281 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:11:42,284 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:11:44,288 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:11:45,290 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:11:46,292 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:11:47,294 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:11:50,303 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:11:51,305 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:11:52,307 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:11:53,309 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:11:54,311 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:11:55,313 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:11:56,315 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:11:57,318 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:11:58,319 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:11:59,323 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:12:01,330 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:12:02,332 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:12:03,335 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:12:04,337 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:12:05,341 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:12:06,343 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:12:06,458 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:12:06,459 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 23:12:07,345 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:12:08,347 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:12:09,349 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:12:10,351 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:12:36,459 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:12:36,461 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:13:06,460 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:13:06,461 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:13:35,502 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 23:13:35,503 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 23:13:35,503 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 220
2017-12-29 23:13:35,504 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 5 14 
2017-12-29 23:13:35,528 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 27 16 
2017-12-29 23:13:35,542 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000220 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000220-0000000000000000221
2017-12-29 23:13:35,542 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 222
2017-12-29 23:13:36,461 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:13:36,462 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:13:37,518 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:13:38,520 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:13:39,522 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:13:40,524 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:13:41,526 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:13:42,531 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:13:43,533 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:13:44,535 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:13:45,537 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:13:46,539 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:13:47,545 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:13:48,547 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:13:49,549 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:13:50,554 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:13:51,556 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:13:52,558 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:13:53,562 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:13:54,564 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:13:55,566 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:13:56,568 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:13:57,574 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:13:58,577 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:13:59,580 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:14:01,582 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:14:02,584 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:14:03,587 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:14:04,589 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:14:05,591 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:14:06,462 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:14:06,463 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:14:06,593 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:14:07,595 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:14:36,463 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 23:14:36,464 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2017-12-29 23:15:06,463 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 23:15:06,464 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2017-12-29 23:15:35,766 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 23:15:35,766 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 23:15:35,766 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 222
2017-12-29 23:15:35,767 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 8 13 
2017-12-29 23:15:35,789 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 28 15 
2017-12-29 23:15:35,798 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000222 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000222-0000000000000000223
2017-12-29 23:15:35,798 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 224
2017-12-29 23:15:36,463 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:15:36,464 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:15:36,781 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:15:37,783 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:15:38,785 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:15:39,788 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:15:40,790 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:15:41,792 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:15:42,794 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:15:43,796 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:15:44,798 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:15:45,801 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:15:46,807 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:15:47,812 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:15:48,814 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:15:49,816 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:15:50,818 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:15:51,820 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:15:52,824 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:15:53,826 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:15:54,828 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:15:55,831 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:15:57,839 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:15:58,841 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:15:59,843 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:16:00,845 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:16:01,847 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:16:02,849 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:16:04,855 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:16:05,857 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:16:06,464 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:16:06,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:16:06,860 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:16:07,862 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:16:36,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 23:16:36,466 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:17:06,465 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:17:06,466 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:17:31,077 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from DatanodeStorage[DS-7cdd7c35-81c1-401d-ac3b-cde27a144a3d,DISK,NORMAL] after starting up or becoming active. Its block contents are no longer considered stale
2017-12-29 23:17:31,078 INFO BlockStateChange: BLOCK* processReport: from storage DS-7cdd7c35-81c1-401d-ac3b-cde27a144a3d node DatanodeRegistration(192.168.1.102, datanodeUuid=39baae53-80c7-4807-a492-8cd1ad4291cf, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-291bf135-e81a-466b-8cca-005142eed37a;nsid=18366549;c=0), blocks: 2, hasStaleStorages: false, processing time: 60 msecs
2017-12-29 23:17:35,892 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 23:17:35,892 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 23:17:35,892 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 224
2017-12-29 23:17:35,893 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 4 10 
2017-12-29 23:17:35,917 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 27 11 
2017-12-29 23:17:35,930 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000224 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000224-0000000000000000225
2017-12-29 23:17:35,930 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 226
2017-12-29 23:17:36,466 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:17:36,467 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:17:36,908 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:17:37,910 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:17:38,912 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:17:39,914 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:17:40,916 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:17:42,919 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:17:43,922 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:17:44,924 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:17:45,926 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:17:46,928 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:17:47,934 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:17:48,937 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:17:49,939 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:17:50,941 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:17:51,943 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:17:52,945 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:17:53,952 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:17:54,954 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:17:55,957 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:17:56,959 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:17:57,963 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:17:58,966 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:17:59,969 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:18:00,971 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:18:01,973 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:18:02,975 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:18:03,978 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:18:04,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:18:05,983 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:18:06,467 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:18:06,468 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:18:06,986 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:18:36,468 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 23:18:36,469 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:19:06,468 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:19:06,469 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:19:36,070 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 23:19:36,070 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 23:19:36,070 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 226
2017-12-29 23:19:36,072 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 5 9 
2017-12-29 23:19:36,099 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 31 10 
2017-12-29 23:19:36,107 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000226 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000226-0000000000000000227
2017-12-29 23:19:36,107 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 228
2017-12-29 23:19:36,469 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:19:36,470 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:19:37,086 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:19:38,088 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:19:39,090 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:19:40,092 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:19:41,094 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:19:42,096 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:19:43,098 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:19:44,100 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:19:45,102 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:19:46,104 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:19:47,110 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:19:49,115 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:19:50,117 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:19:51,120 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:19:52,122 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:19:53,126 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:19:54,128 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:19:55,130 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:19:56,132 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:19:57,134 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:19:58,141 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:19:59,144 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:20:00,147 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:20:01,149 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:20:02,151 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:20:03,153 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:20:04,155 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:20:05,157 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:20:06,159 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:20:06,470 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:20:06,471 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:20:07,161 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:20:36,471 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:20:36,472 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:21:06,471 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 23:21:06,472 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:21:36,260 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 23:21:36,260 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 23:21:36,260 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 228
2017-12-29 23:21:36,261 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 5 28 
2017-12-29 23:21:36,283 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 26 29 
2017-12-29 23:21:36,293 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000228 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000228-0000000000000000229
2017-12-29 23:21:36,293 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 230
2017-12-29 23:21:36,472 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:21:36,473 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:21:37,277 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:21:38,279 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:21:39,282 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:21:40,284 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:21:41,286 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:21:42,288 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:21:43,290 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:21:44,292 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:21:45,294 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:21:46,296 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:21:47,302 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:21:48,306 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:21:49,308 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:21:50,310 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:21:51,313 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:21:52,314 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:21:53,318 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:21:54,320 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:21:55,322 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:21:56,324 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:21:58,329 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:21:59,331 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:22:01,334 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:22:02,336 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:22:03,338 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:22:04,343 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:22:05,345 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:22:06,347 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:22:06,473 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:22:06,474 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:22:07,349 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:22:08,351 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:22:36,474 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:22:36,474 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 23:23:06,476 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:23:06,477 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:23:36,464 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 23:23:36,464 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 23:23:36,464 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 230
2017-12-29 23:23:36,465 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 8 14 
2017-12-29 23:23:36,481 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30006 milliseconds
2017-12-29 23:23:36,487 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 29 15 
2017-12-29 23:23:36,496 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000230 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000230-0000000000000000231
2017-12-29 23:23:36,496 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 232
2017-12-29 23:23:36,536 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 55 millisecond(s).
2017-12-29 23:23:37,481 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:23:38,484 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:23:40,487 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:23:41,488 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:23:42,491 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:23:43,493 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:23:44,495 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:23:45,497 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:23:46,499 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:23:47,501 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:23:48,509 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:23:49,513 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:23:50,515 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:23:51,518 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:23:52,520 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:23:53,522 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:23:54,524 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:23:55,526 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:23:56,528 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:23:57,530 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:23:58,536 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:23:59,538 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:24:01,541 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:24:02,543 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:24:03,545 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:24:04,547 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:24:05,549 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:24:06,482 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:24:06,483 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:24:06,551 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:24:07,554 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:24:08,556 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:24:28,129 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from DatanodeStorage[DS-fa575c26-9138-4923-adfe-224bf6e42868,DISK,NORMAL] after starting up or becoming active. Its block contents are no longer considered stale
2017-12-29 23:24:28,130 INFO BlockStateChange: BLOCK* processReport: from storage DS-fa575c26-9138-4923-adfe-224bf6e42868 node DatanodeRegistration(192.168.1.101, datanodeUuid=c1a65381-b373-45ea-8031-47c9f6c4e577, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-291bf135-e81a-466b-8cca-005142eed37a;nsid=18366549;c=0), blocks: 2, hasStaleStorages: false, processing time: 0 msecs
2017-12-29 23:24:36,484 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-29 23:24:36,485 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:25:06,484 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 23:25:06,485 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:25:36,485 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:25:36,486 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:25:36,593 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 23:25:36,593 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 23:25:36,593 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 232
2017-12-29 23:25:36,594 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 5 9 
2017-12-29 23:25:36,616 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 26 10 
2017-12-29 23:25:36,628 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000232 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000232-0000000000000000233
2017-12-29 23:25:36,628 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 234
2017-12-29 23:25:37,609 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:25:38,610 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:25:39,613 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:25:40,614 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:25:41,616 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:25:42,618 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:25:43,620 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:25:44,622 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:25:45,624 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:25:46,626 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:25:47,631 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:25:48,637 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:25:49,639 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:25:50,641 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:25:51,644 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:25:52,646 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:25:54,651 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:25:55,653 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:25:56,655 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:25:57,657 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:25:58,663 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:25:59,665 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:26:00,667 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:26:01,669 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:26:02,671 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:26:03,673 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:26:04,678 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:26:05,680 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:26:06,486 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:26:06,487 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:26:06,682 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:26:07,684 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:26:36,487 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:26:36,488 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:27:06,488 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:27:06,489 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:27:36,503 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30015 milliseconds
2017-12-29 23:27:36,504 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 23:27:36,723 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 23:27:36,723 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 23:27:36,723 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 234
2017-12-29 23:27:36,724 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 4 10 
2017-12-29 23:27:36,798 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 77 11 
2017-12-29 23:27:36,806 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000234 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000234-0000000000000000235
2017-12-29 23:27:36,806 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 236
2017-12-29 23:27:37,785 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:27:38,787 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:27:39,789 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:27:40,791 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:27:41,793 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:27:42,795 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:27:43,798 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:27:44,800 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:27:45,804 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:27:46,806 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:27:47,813 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:27:48,819 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:27:49,822 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:27:50,824 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:27:51,826 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:27:52,830 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:27:54,835 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:27:55,838 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:27:56,840 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:27:57,842 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:27:59,850 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:28:00,852 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:28:01,854 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:28:02,858 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:28:03,864 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:28:04,866 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:28:05,868 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:28:06,504 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:28:06,504 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-29 23:28:06,871 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:28:07,874 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:28:08,924 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:28:36,505 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:28:36,506 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:29:06,506 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:29:06,507 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:29:36,507 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:29:36,508 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:29:36,943 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 23:29:36,943 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 23:29:36,943 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 236
2017-12-29 23:29:36,943 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 5 10 
2017-12-29 23:29:36,961 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 21 12 
2017-12-29 23:29:36,973 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000236 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000236-0000000000000000237
2017-12-29 23:29:36,974 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 238
2017-12-29 23:29:37,954 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:29:38,957 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:29:39,959 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:29:40,961 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:29:41,963 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:29:42,965 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:29:43,967 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:29:44,970 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:29:45,971 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:29:46,974 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:29:47,979 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:29:48,984 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:29:49,986 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:29:50,988 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:29:51,990 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:29:52,993 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:29:53,998 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:29:55,000 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:29:56,002 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:29:57,004 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:29:58,008 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:29:59,013 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:30:00,015 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:30:01,017 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:30:02,019 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:30:03,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:30:04,023 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:30:05,025 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:30:06,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:30:06,508 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:30:06,509 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:30:07,030 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:30:36,509 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:30:36,510 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:31:06,510 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 23:31:06,511 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:31:36,510 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:31:36,511 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:31:37,109 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 23:31:37,110 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 23:31:37,110 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 238
2017-12-29 23:31:37,111 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 5 35 
2017-12-29 23:31:37,132 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 25 36 
2017-12-29 23:31:37,140 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000238 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000238-0000000000000000239
2017-12-29 23:31:37,141 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 240
2017-12-29 23:31:38,125 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:31:39,128 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:31:41,131 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:31:42,134 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:31:43,136 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:31:44,138 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:31:46,141 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:31:48,145 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:31:49,149 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:31:50,151 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:31:51,157 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:31:52,159 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:31:53,161 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:31:54,163 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:31:55,167 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:31:56,169 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:31:57,171 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:31:58,173 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:31:59,175 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:32:00,177 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:32:01,183 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:32:02,185 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:32:03,187 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:32:04,189 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:32:05,191 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:32:06,195 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:32:06,511 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:32:06,512 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:32:07,197 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:32:08,199 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:32:09,201 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:32:10,203 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:32:36,512 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:32:36,513 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:33:06,513 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 23:33:06,514 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2017-12-29 23:33:36,512 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 23:33:36,513 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:33:37,305 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 23:33:37,305 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 23:33:37,305 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 240
2017-12-29 23:33:37,306 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 5 10 
2017-12-29 23:33:37,331 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 29 11 
2017-12-29 23:33:37,377 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000240 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000240-0000000000000000241
2017-12-29 23:33:37,377 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 242
2017-12-29 23:33:38,323 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:33:39,327 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:33:40,330 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:33:41,332 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:33:42,335 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:33:43,336 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:33:44,339 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:33:45,341 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:33:46,343 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:33:47,345 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:33:49,351 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:33:50,353 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:33:51,355 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:33:52,357 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:33:53,359 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:33:54,362 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:33:55,366 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:33:56,370 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:33:57,374 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:33:58,408 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:33:59,412 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:34:00,415 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:34:01,417 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:34:02,419 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:34:03,422 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:34:04,424 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:34:05,426 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:34:06,430 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:34:06,513 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:34:06,514 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:34:07,432 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:34:08,434 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:34:36,514 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:34:36,515 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:34:46,164 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 3390ms
GC pool 'MarkSweepCompact' had collection(s): count=1 time=3428ms
GC pool 'Copy' had collection(s): count=1 time=37ms
2017-12-29 23:35:06,515 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:35:06,516 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:35:36,515 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-29 23:35:36,516 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:35:37,483 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-29 23:35:37,484 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-29 23:35:37,484 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 242
2017-12-29 23:35:37,484 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 7 9 
2017-12-29 23:35:37,507 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 29 9 
2017-12-29 23:35:37,515 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000242 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000242-0000000000000000243
2017-12-29 23:35:37,515 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 244
2017-12-29 23:35:39,493 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:35:40,496 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:35:41,498 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:35:42,500 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:35:43,502 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:35:44,504 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:35:45,506 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:35:46,508 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:35:47,510 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:35:48,512 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:35:49,522 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:35:50,525 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:35:51,527 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:35:52,529 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:35:54,532 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:35:55,538 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:35:56,540 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:35:57,542 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:35:58,544 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:35:59,546 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:00,555 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:01,557 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:02,559 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:03,561 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:04,563 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:05,565 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:06,516 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:36:06,517 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-29 23:36:06,567 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:07,569 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:08,571 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:09,574 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:33,410 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Stopping services started for active state
2017-12-29 23:36:33,414 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 244
2017-12-29 23:36:33,425 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: NameNodeEditLogRoller was interrupted, exiting
2017-12-29 23:36:33,565 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 139 23 
2017-12-29 23:36:33,802 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000244 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000244-0000000000000000245
2017-12-29 23:36:34,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:35,425 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:36,427 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:36,517 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-29 23:36:37,429 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:38,483 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:39,486 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:40,488 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:41,490 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:42,509 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:43,547 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:43,972 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2017-12-29 23:36:43,986 WARN org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory: The property 'ssl.client.truststore.location' has not been set, no TrustStore will be loaded
2017-12-29 23:36:44,099 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node at slave101/192.168.1.101:8020 every 120 seconds.
2017-12-29 23:36:44,106 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN at http://slave101:50070
Serving checkpoints at http://master100:50070
2017-12-29 23:36:44,107 WARN org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020, call org.apache.hadoop.ha.HAServiceProtocol.transitionToStandby from 192.168.1.100:58404 Call#26770 Retry#0: output error
2017-12-29 23:36:44,107 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020 caught an exception
java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:270)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:479)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:2538)
	at org.apache.hadoop.ipc.Server.access$1900(Server.java:130)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:965)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1030)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2068)
2017-12-29 23:36:44,112 WARN org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020, call org.apache.hadoop.ha.HAServiceProtocol.transitionToStandby from 192.168.1.101:60289 Call#26811 Retry#0: output error
2017-12-29 23:36:44,112 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 8020 caught an exception
java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:270)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:479)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:2538)
	at org.apache.hadoop.ipc.Server.access$1900(Server.java:130)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:965)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1030)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2068)
2017-12-29 23:36:44,113 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Shutting down CacheReplicationMonitor.
2017-12-29 23:36:45,241 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:45,478 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Stopping services started for standby state
2017-12-29 23:36:45,479 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:337)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-29 23:36:46,256 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:47,259 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:48,353 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:49,355 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:50,357 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:51,359 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:52,361 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:53,363 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:54,448 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:54,540 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2017-12-29 23:36:54,548 WARN org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory: The property 'ssl.client.truststore.location' has not been set, no TrustStore will be loaded
2017-12-29 23:36:54,565 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Starting recovery process for unclosed journal segments...
2017-12-29 23:36:55,581 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:55,694 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:56,644 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:57,703 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:58,859 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:36:59,898 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:37:00,915 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:37:01,957 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:37:03,013 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:37:04,473 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:37:05,858 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:37:15,720 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); maxRetries=45
2017-12-29 23:37:30,585 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 36016 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:37:31,609 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 37041 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:37:32,397 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 4183ms
No GCs detected
2017-12-29 23:37:32,644 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 38075 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:37:33,646 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 39077 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:37:34,647 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 40078 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:37:34,648 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:37:35,656 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 41088 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:37:36,662 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 42093 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:37:37,673 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:37:37,675 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 43106 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:37:38,734 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 44165 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:37:39,735 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 45166 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:37:40,733 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:37:40,736 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 46168 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:37:41,740 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 47171 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:37:42,742 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 48173 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:37:43,738 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:37:43,744 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 49176 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:37:44,746 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 50177 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:37:45,748 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 51179 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:37:46,738 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:37:46,750 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 52182 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:37:47,753 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 53184 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:37:48,760 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 54192 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:37:49,761 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 55193 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:37:50,743 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:37:50,762 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 56194 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:37:51,786 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 57217 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:37:52,787 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 58219 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:37:53,792 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 59224 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:37:54,795 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 60227 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:37:55,796 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 61228 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:37:56,797 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 62229 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:37:57,798 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 63230 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:37:58,799 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 64231 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:37:59,800 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 65232 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:38:00,837 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 66268 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:38:01,838 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 67270 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:38:02,840 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 68271 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:38:03,842 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 69273 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:38:04,851 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 70283 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:38:05,853 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 71284 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:38:06,854 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 72285 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:38:07,856 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 73287 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:38:08,858 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 74289 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:38:09,865 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 75296 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:38:10,765 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); maxRetries=45
2017-12-29 23:38:10,866 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 76297 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:38:11,766 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:38:11,868 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 77299 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:38:12,767 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:38:12,870 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 78301 ms (timeout=120000 ms) for a response for getJournalState(). Succeeded so far: [192.168.1.101:8485]. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-29 23:38:13,769 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-29 23:38:13,775 FATAL org.apache.hadoop.hdfs.server.namenode.FSEditLog: Error: recoverUnfinalizedSegments failed for required journal (JournalAndStream(mgr=QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485], stream=null))
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 1 successful responses:
192.168.1.101:8485: lastPromisedEpoch: 2
httpPort: 8480
fromURL: "http://0.0.0.0:8480"

2 exceptions thrown:
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: Failed on local exception: java.net.SocketException: 网络不可达; Host Details : local host is: "master100/192.168.1.100"; destination host is: "slave102":8485; 
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.createNewUniqueEpoch(QuorumJournalManager.java:182)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.recoverUnfinalizedSegments(QuorumJournalManager.java:436)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet$7.apply(JournalSet.java:590)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.mapJournalsAndReportErrors(JournalSet.java:359)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.recoverUnfinalizedSegments(JournalSet.java:587)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.recoverUnclosedStreams(FSEditLog.java:1361)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startActiveServices(FSNamesystem.java:1068)
	at org.apache.hadoop.hdfs.server.namenode.NameNode$NameNodeHAContext.startActiveServices(NameNode.java:1624)
	at org.apache.hadoop.hdfs.server.namenode.ha.ActiveState.enterState(ActiveState.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.HAState.setStateInternal(HAState.java:63)
	at org.apache.hadoop.hdfs.server.namenode.ha.StandbyState.setState(StandbyState.java:49)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.transitionToActive(NameNode.java:1502)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.transitionToActive(NameNodeRpcServer.java:1197)
	at org.apache.hadoop.ha.protocolPB.HAServiceProtocolServerSideTranslatorPB.transitionToActive(HAServiceProtocolServerSideTranslatorPB.java:107)
	at org.apache.hadoop.ha.proto.HAServiceProtocolProtos$HAServiceProtocolService$2.callBlockingMethod(HAServiceProtocolProtos.java:4460)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)
2017-12-29 23:38:13,899 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2017-12-29 23:38:13,959 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at master100/192.168.1.100
************************************************************/
2017-12-30 00:42:34,228 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = master100/192.168.1.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.1
STARTUP_MSG:   classpath = /home/tools/hadoop-2.5.1/etc/hadoop:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jsch-0.1.42.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-el-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/xz-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/asm-3.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/junit-4.11.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/hadoop-auth-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/hadoop-annotations-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jettison-1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/activation-1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/hadoop-nfs-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/hadoop-common-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/hadoop-common-2.5.1-tests.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-2.5.1-tests.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jline-0.9.94.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-client-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-api-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-common-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-common-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.1-tests.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-10-20T05:53Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2017-12-30 00:42:34,459 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-12-30 00:42:34,493 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2017-12-30 00:42:35,888 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-12-30 00:42:38,062 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-12-30 00:42:38,062 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2017-12-30 00:42:38,068 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://aaaaa
2017-12-30 00:42:38,081 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use aaaaa to access this namenode/service.
2017-12-30 00:42:41,283 INFO org.apache.hadoop.hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
2017-12-30 00:42:41,283 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://master100:50070
2017-12-30 00:42:42,456 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-12-30 00:42:42,463 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2017-12-30 00:42:42,502 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-12-30 00:42:42,516 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-12-30 00:42:42,516 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-12-30 00:42:42,516 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-12-30 00:42:43,312 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-12-30 00:42:43,510 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-12-30 00:42:45,752 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2017-12-30 00:42:45,752 INFO org.mortbay.log: jetty-6.1.26
2017-12-30 00:42:49,225 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: 'signature.secret' configuration not set, using a random value as secret
2017-12-30 00:42:50,252 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@master100:50070
2017-12-30 00:42:51,386 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-12-30 00:42:52,747 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2017-12-30 00:42:53,829 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2017-12-30 00:42:53,829 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2017-12-30 00:42:53,834 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-12-30 00:42:53,837 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2017 十二月 30 00:42:53
2017-12-30 00:42:53,842 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2017-12-30 00:42:53,842 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-12-30 00:42:53,965 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2017-12-30 00:42:53,965 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2017-12-30 00:42:54,040 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2017-12-30 00:42:54,040 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2017-12-30 00:42:54,040 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2017-12-30 00:42:54,040 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2017-12-30 00:42:54,041 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2017-12-30 00:42:54,041 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2017-12-30 00:42:54,041 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2017-12-30 00:42:54,041 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2017-12-30 00:42:54,041 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2017-12-30 00:42:54,058 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2017-12-30 00:42:54,059 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2017-12-30 00:42:54,059 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2017-12-30 00:42:54,060 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Determined nameservice ID: aaaaa
2017-12-30 00:42:54,060 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: true
2017-12-30 00:42:54,069 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2017-12-30 00:43:04,222 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2017-12-30 00:43:04,222 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-12-30 00:43:04,223 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2017-12-30 00:43:04,223 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2017-12-30 00:43:04,229 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2017-12-30 00:43:04,290 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2017-12-30 00:43:04,290 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-12-30 00:43:04,291 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2017-12-30 00:43:04,291 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2017-12-30 00:43:04,294 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-12-30 00:43:04,294 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2017-12-30 00:43:04,294 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2017-12-30 00:43:04,297 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2017-12-30 00:43:04,304 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-12-30 00:43:04,309 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2017-12-30 00:43:04,309 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-12-30 00:43:04,313 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 966.7 MB = 297.0 KB
2017-12-30 00:43:04,313 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2017-12-30 00:43:04,336 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2017-12-30 00:43:04,336 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2017-12-30 00:43:04,336 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2017-12-30 00:43:04,837 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop2/dfs/name/in_use.lock acquired by nodename 2420@master100
2017-12-30 00:43:10,778 WARN org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory: The property 'ssl.client.truststore.location' has not been set, no TrustStore will be loaded
2017-12-30 00:43:18,709 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:18,710 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:18,710 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:19,534 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:43:19,713 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:19,713 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:20,536 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:43:20,713 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:20,716 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:20,716 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:21,538 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:43:21,714 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:21,718 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:21,719 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:22,539 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9007 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:43:22,721 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:22,722 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:22,722 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:23,540 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10008 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:43:23,724 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:23,725 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:23,725 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:24,541 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11009 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:43:24,726 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:24,728 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:24,728 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:25,546 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12015 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:43:25,728 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:25,730 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:25,731 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:26,548 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 13016 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:43:26,735 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:26,737 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:26,737 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:27,549 WARN org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 14017 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:43:27,740 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:27,741 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:27,744 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:28,550 WARN org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 15019 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 00:43:29,551 WARN org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 16020 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 00:43:29,752 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:29,755 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:636)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:279)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:955)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:700)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:529)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:751)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:735)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1473)
2017-12-30 00:43:29,759 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2017-12-30 00:43:30,244 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 4 INodes.
2017-12-30 00:43:32,016 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 1 seconds.
2017-12-30 00:43:32,016 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 199 from /opt/hadoop2/dfs/name/current/fsimage_0000000000000000199
2017-12-30 00:43:32,052 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=true, haEnabled=true, isRollingUpgrade=false)
2017-12-30 00:43:32,053 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2017-12-30 00:43:32,053 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 27717 msecs
2017-12-30 00:43:39,533 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to master100:8020
2017-12-30 00:43:39,552 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-12-30 00:43:39,630 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2017-12-30 00:43:39,858 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2017-12-30 00:43:39,931 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2017-12-30 00:43:39,931 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2017-12-30 00:43:39,933 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 2.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-12-30 00:43:40,352 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-12-30 00:43:40,359 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2017-12-30 00:43:40,421 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: master100/192.168.1.100:8020
2017-12-30 00:43:40,421 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2017-12-30 00:43:40,447 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node at slave101/192.168.1.101:8020 every 120 seconds.
2017-12-30 00:43:40,483 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN at http://slave101:50070
Serving checkpoints at http://master100:50070
2017-12-30 00:43:41,492 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:41,494 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:41,495 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:42,504 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:42,506 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:42,508 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:43,519 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:43,520 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:43,521 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:44,522 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:44,523 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:44,532 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:45,525 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:45,527 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:45,534 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:46,491 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:43:46,529 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:46,536 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:46,530 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:47,493 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:43:47,588 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:47,589 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:47,592 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:48,495 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8008 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:43:48,592 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:48,594 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:48,595 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:49,496 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9009 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:43:49,597 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:49,598 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:49,599 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:50,498 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10011 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:43:50,601 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:50,602 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:50,603 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:43:50,608 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 00:44:51,619 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:44:51,622 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:44:51,622 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:44:52,621 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:44:52,624 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:44:52,625 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:44:53,623 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:44:53,626 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:44:53,627 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:44:54,626 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:44:54,629 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:44:54,629 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:44:55,629 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:44:55,631 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:44:55,631 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:44:56,616 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:44:56,631 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:44:56,634 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:44:56,635 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:44:57,617 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:44:57,638 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:44:57,639 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:44:57,640 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:44:58,619 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:44:58,642 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:44:58,643 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:44:58,644 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:44:59,620 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:44:59,645 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:44:59,646 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:45:00,620 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:45:00,645 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:45:00,648 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:45:00,649 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:45:01,622 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11007 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 00:45:01,647 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:45:01,650 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 00:46:01,654 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 00:46:02,802 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:03,804 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:04,806 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:05,809 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:06,810 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:07,814 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:08,816 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:09,818 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:10,821 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:11,823 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:11,826 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 00:46:12,831 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:12,834 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:12,835 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:13,835 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:13,836 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:14,838 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:14,839 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:15,839 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:15,841 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:15,841 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:16,844 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:17,836 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:46:17,841 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:17,843 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:17,846 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:18,838 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:46:18,844 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:18,845 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:18,849 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:19,840 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:46:19,846 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:19,847 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:19,850 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:20,841 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:46:20,848 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:20,859 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:21,848 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10014 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:46:21,849 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:21,849 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:21,861 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:22,851 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11016 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:46:22,863 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:22,864 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:22,865 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:23,852 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12017 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 00:46:23,867 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:24,854 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 13019 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 00:46:24,869 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:46:24,871 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 00:47:24,873 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 00:47:26,879 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:27,882 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:28,885 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:29,887 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:30,891 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:31,894 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:32,896 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:33,900 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:35,904 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:36,905 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:36,907 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 00:47:37,912 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:37,915 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:37,916 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:38,916 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:38,917 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:38,918 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:39,937 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:39,949 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:40,920 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:40,940 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:40,952 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:41,923 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:41,942 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:41,954 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:42,917 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:47:42,925 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:42,944 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:42,956 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:43,920 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:47:43,927 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:43,946 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:43,958 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:44,923 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:47:44,930 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:44,947 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:44,961 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:45,924 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9007 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:47:45,932 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:45,949 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:45,964 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:46,926 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10009 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:47:46,934 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:46,955 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:46,966 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:47,927 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11010 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 00:47:47,936 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:47:48,929 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12012 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 00:47:48,939 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 00:48:48,940 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 00:48:50,944 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:48:51,947 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:48:53,949 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:48:54,952 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:48:55,956 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:48:56,960 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:48:57,987 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:48:58,989 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:48:59,991 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:49:01,995 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:49:01,997 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 00:49:03,005 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:49:03,007 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:49:03,010 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:49:04,009 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:49:04,011 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:49:04,012 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:49:05,016 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:49:05,017 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:49:05,017 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:49:06,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:49:06,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:49:06,022 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:49:07,023 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:49:07,024 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:49:07,025 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:49:08,012 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:49:08,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:49:08,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:49:08,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:49:09,013 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:49:09,029 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:49:09,031 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:49:10,015 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:49:10,030 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:49:10,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:49:10,035 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:49:11,017 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9007 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:49:11,033 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:49:11,037 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:49:11,039 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:49:12,019 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10009 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:49:12,043 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:49:13,021 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11011 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:49:13,039 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:49:13,041 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:49:13,046 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:49:14,023 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12013 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 00:49:14,051 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 00:50:14,054 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 00:50:15,059 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:16,061 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:17,062 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:18,065 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:19,068 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:20,070 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:21,082 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:22,086 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:23,088 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:24,090 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:24,092 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 00:50:25,095 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:25,097 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:25,097 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:26,101 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:26,102 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:26,103 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:27,105 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:27,106 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:27,107 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:28,109 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:28,110 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:28,112 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:29,114 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:29,115 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:29,116 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:30,097 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:50:30,117 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:30,118 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:31,098 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:50:31,118 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:31,119 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:31,119 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:32,100 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:50:32,122 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:32,124 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:32,124 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:33,101 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:50:33,125 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:33,126 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:33,127 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:34,103 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:50:34,128 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:34,129 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:34,130 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:35,104 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11008 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:50:35,133 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:50:35,142 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 00:51:35,149 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 00:51:36,151 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:37,156 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:38,160 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:40,163 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:41,168 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:42,170 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:43,172 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:44,175 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:45,177 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:46,182 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:46,184 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 00:51:47,188 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:47,190 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:47,192 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:48,191 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:48,191 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:48,194 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:49,193 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:49,195 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:49,197 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:50,195 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:50,199 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:50,197 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:51,203 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:51,204 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:51,205 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:52,193 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:51:52,209 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:52,210 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:52,211 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:53,194 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:51:53,213 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:53,213 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:54,196 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:51:54,213 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:54,214 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:54,214 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:55,197 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:51:55,217 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:55,218 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:55,219 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:56,198 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10007 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:51:56,223 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:56,224 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:56,224 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:57,201 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11009 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 00:51:57,227 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:51:58,203 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12011 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 00:51:58,232 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 00:52:58,237 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 00:52:59,240 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:00,243 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:01,246 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:02,250 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:03,253 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:04,256 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:05,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:06,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:07,262 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:08,265 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:08,269 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 00:53:09,278 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:09,283 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:09,284 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:10,281 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:10,286 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:10,288 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:11,285 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:11,289 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:11,290 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:12,287 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:12,290 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:12,291 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:13,289 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:13,291 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:13,293 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:14,286 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:53:14,295 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:14,296 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:15,287 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:53:15,295 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:15,298 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:15,300 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:16,301 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8021 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:53:16,302 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:16,306 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:16,307 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:17,302 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9022 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:53:18,304 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10024 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:53:18,309 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:18,310 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:18,310 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:19,306 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11026 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:53:19,312 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:19,314 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:20,308 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12027 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 00:53:20,314 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:21,311 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 13030 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 00:53:21,317 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:53:21,320 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 00:54:21,325 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 00:54:22,329 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:23,332 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:24,333 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:25,335 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:26,337 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:27,339 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:28,341 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:29,344 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:30,346 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:31,349 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:31,351 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 00:54:32,358 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:32,363 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:32,359 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:33,373 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:33,374 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:33,375 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:34,378 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:35,376 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:35,377 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:36,380 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:36,381 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:37,363 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:54:37,380 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:37,383 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:37,383 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:38,364 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:54:38,382 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:38,385 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:38,385 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:39,367 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:54:39,384 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:39,386 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:39,387 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:40,368 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:54:40,388 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:41,369 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:54:41,386 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:41,389 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:41,390 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:42,371 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11008 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:54:42,389 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:42,391 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:42,391 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:43,373 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12010 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 00:54:43,391 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:43,395 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:44,375 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 13012 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 00:54:44,393 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:54:44,400 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 00:55:44,403 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 00:55:45,406 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:55:46,409 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:55:47,411 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:55:48,413 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:55:49,417 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:55:50,419 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:55:51,421 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:55:52,424 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:55:53,426 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:55:54,427 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:55:54,433 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 00:55:55,440 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:55:55,443 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:55:55,444 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:55:56,441 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:55:56,446 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:55:56,447 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:55:57,443 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:55:57,448 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:55:57,449 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:55:58,446 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:55:58,453 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:55:59,448 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:55:59,453 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:55:59,454 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:56:00,446 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:56:00,451 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:56:00,456 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:56:00,457 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:56:01,447 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:56:01,460 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:56:02,448 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:56:02,455 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:56:02,460 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:56:02,460 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:56:03,450 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:56:03,457 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:56:03,462 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:56:03,464 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:56:04,451 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10007 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:56:04,460 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:56:05,454 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11009 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:56:05,462 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:56:05,465 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:56:05,467 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:56:06,456 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12011 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 00:56:07,458 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 13013 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 00:56:07,470 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:56:07,471 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:56:07,475 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 00:57:07,478 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 00:57:08,482 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:09,484 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:10,486 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:11,490 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:12,492 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:13,496 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:14,499 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:15,502 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:16,504 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:17,508 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:17,512 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 00:57:18,518 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:18,519 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:18,519 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:19,521 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:19,521 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:19,522 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:20,523 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:20,524 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:20,526 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:21,532 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:21,533 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:21,533 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:22,535 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:22,536 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:22,536 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:23,522 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:57:23,550 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:23,552 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:24,527 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7008 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:57:24,552 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:25,529 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8010 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:57:25,556 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:25,557 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:25,557 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:26,531 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9012 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:57:26,559 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:26,560 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:27,533 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10013 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:57:27,559 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:27,562 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:27,563 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:28,534 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11014 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:57:28,562 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:28,566 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:28,567 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:29,536 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12015 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 00:57:30,537 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 13017 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 00:57:30,565 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:57:30,568 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 00:58:30,571 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 00:58:32,576 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:33,578 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:34,581 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:35,583 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:37,588 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:38,590 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:39,592 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:40,595 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:41,600 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:43,603 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:43,606 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 00:58:44,614 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:44,617 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:45,615 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:45,616 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:45,618 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:46,619 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:46,620 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:47,620 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:47,622 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:47,623 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:48,624 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:49,617 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:58:49,623 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:49,624 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:49,626 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:50,619 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:58:50,627 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:50,627 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:50,628 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:51,620 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:58:51,629 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:51,630 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:52,621 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:58:52,630 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:52,631 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:52,632 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:53,622 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 00:58:53,634 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:53,635 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:53,636 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:54,622 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11007 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 00:58:54,639 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:54,640 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:55,624 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12009 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 00:58:55,641 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:55,642 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:56,627 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 13011 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 00:58:56,644 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:58:56,646 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 00:59:56,647 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 00:59:57,652 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:59:58,654 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 00:59:59,657 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:00,660 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:01,662 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:02,665 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:03,669 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:04,671 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:05,674 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:06,676 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:06,679 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 01:00:07,684 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:07,686 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:07,687 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:08,686 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:08,688 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:08,690 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:09,688 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:09,689 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:09,692 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:10,691 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:10,692 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:10,693 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:11,694 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:11,695 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:12,690 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:00:12,696 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:12,697 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:12,698 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:13,691 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:00:13,700 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:13,701 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:13,702 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:14,694 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:00:14,704 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:14,705 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:15,696 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9008 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:00:15,704 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:15,707 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:15,708 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:16,697 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10009 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:00:16,705 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:16,709 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:16,710 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:17,699 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11011 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:00:17,707 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:18,700 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12012 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:00:18,709 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:00:18,711 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 01:01:18,716 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 01:01:19,719 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:20,721 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:21,723 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:22,725 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:23,727 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:24,729 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:25,733 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:26,736 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:27,738 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:28,740 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:28,744 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 01:01:29,754 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:29,759 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:30,754 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:30,757 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:30,761 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:31,757 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:31,759 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:31,764 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:32,766 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:33,760 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:33,761 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:33,768 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:34,759 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:01:35,760 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:01:35,763 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:35,764 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:35,771 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:36,761 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:01:36,765 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:36,766 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:36,773 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:37,763 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:01:37,768 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:37,769 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:37,776 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:38,764 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10007 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:01:38,771 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:38,773 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:38,779 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:39,766 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11009 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:01:39,774 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:39,775 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:39,781 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:40,768 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12011 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:01:40,777 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:40,778 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:41,770 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 13013 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:01:41,779 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:01:41,781 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 01:02:41,783 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 01:02:42,787 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:02:43,790 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:02:44,792 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:02:45,795 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:02:46,797 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:02:47,800 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:02:48,803 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:02:49,805 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:02:50,807 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:02:51,809 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:02:51,813 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 01:02:52,816 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:02:52,821 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:02:53,819 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:02:53,821 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:02:53,823 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:02:54,821 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:02:54,822 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:02:54,825 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:02:55,828 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:02:55,828 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:02:56,824 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:02:56,830 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:02:56,830 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:02:57,823 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:02:57,832 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:02:57,833 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:02:58,825 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:02:58,827 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:02:58,834 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:02:58,838 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:02:59,825 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:02:59,830 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:03:00,827 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:03:00,832 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:03:00,839 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:03:00,840 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:03:01,829 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10007 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:03:01,834 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:03:01,842 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:03:01,845 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:03:02,830 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11009 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:03:02,837 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:03:02,847 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:03:02,848 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:03:03,834 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12012 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:03:03,840 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:03:04,837 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 13015 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:03:04,843 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:03:04,847 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 01:04:04,849 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 01:04:05,853 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:06,855 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:07,856 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:08,858 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:10,861 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:11,863 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:12,865 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:13,867 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:15,871 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:16,873 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:16,875 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 01:04:17,880 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:17,880 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:17,882 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:18,882 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:18,884 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:19,884 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:19,885 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:19,888 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:20,887 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:20,889 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:21,887 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:21,889 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:21,892 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:22,883 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:04:22,889 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:22,929 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:23,884 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:04:23,891 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:23,927 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:23,930 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:24,886 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:04:24,895 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:24,929 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:24,932 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:25,887 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:04:25,931 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:25,933 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:26,888 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:04:26,898 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:26,933 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:26,934 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:27,892 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11010 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:04:27,900 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:27,935 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:28,894 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12011 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:04:28,937 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:29,894 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 13012 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:04:29,904 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:04:29,908 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 01:05:29,910 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 01:05:30,913 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:31,915 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:32,917 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:33,920 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:34,925 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:36,934 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:37,936 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:38,939 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:39,942 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:40,944 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:40,945 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 01:05:41,948 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:41,950 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:41,949 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:42,980 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:42,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:43,953 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:43,982 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:43,984 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:44,955 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:44,984 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:44,984 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:45,957 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:45,986 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:45,987 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:46,950 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:05:46,959 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:46,993 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:46,994 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:47,951 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:05:47,996 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:47,996 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:48,952 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:05:48,961 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:48,999 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:49,000 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:49,954 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:05:49,963 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:50,002 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:50,003 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:50,955 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:05:50,965 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:51,004 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:51,004 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:51,957 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11007 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:05:51,967 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:52,958 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12009 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:05:52,969 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:05:52,972 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 01:06:52,973 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 01:06:53,977 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:06:54,979 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:06:55,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:06:56,983 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:06:57,986 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:06:58,990 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:00,993 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:01,995 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:02,997 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:03,999 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:04,001 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 01:07:05,004 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:05,006 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:05,008 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:06,007 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:06,011 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:06,012 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:07,009 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:07,013 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:07,014 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:08,011 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:08,015 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:09,013 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:09,016 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:09,017 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:10,007 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:07:10,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:10,021 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:10,022 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:11,008 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:07:11,024 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:11,024 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:11,025 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:12,009 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:07:12,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:12,028 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:12,029 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:13,023 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9016 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:07:13,031 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:13,031 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:13,031 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:14,024 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10018 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:07:14,033 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:14,033 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:14,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:15,025 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11019 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:07:16,027 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12020 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:07:16,035 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:07:16,037 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 01:08:16,038 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 01:08:18,042 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:19,044 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:20,046 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:21,048 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:22,050 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:23,052 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:24,055 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:25,057 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:26,059 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:27,062 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:27,065 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 01:08:28,071 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:28,074 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:28,075 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:29,073 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:29,077 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:29,078 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:30,075 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:30,079 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:30,081 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:31,082 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:31,084 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:31,084 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:32,089 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:32,093 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:32,096 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:33,072 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:08:33,093 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:33,096 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:33,098 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:34,091 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7023 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:08:34,094 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:34,097 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:34,103 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:35,093 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8024 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:08:35,096 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:35,098 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:35,106 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:36,094 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9025 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:08:36,099 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:36,099 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:36,108 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:37,095 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10026 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:08:37,101 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:37,110 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:38,097 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11028 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:08:38,103 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:08:38,104 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 01:09:38,107 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 01:09:39,111 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:40,113 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:41,117 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:42,120 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:43,123 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:44,129 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:45,133 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:46,136 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:48,138 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:49,147 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:49,149 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 01:09:50,153 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:50,155 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:50,157 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:51,157 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:51,158 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:51,162 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:52,162 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:52,164 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:53,169 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:54,165 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:54,166 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:54,171 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:55,157 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:09:55,168 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:55,169 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:55,173 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:56,158 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:09:56,172 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:56,175 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:57,159 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:09:57,170 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:57,174 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:57,176 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:58,160 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:09:58,175 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:58,175 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:58,178 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:59,161 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:09:59,176 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:59,177 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:09:59,180 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:10:00,162 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11007 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:10:00,179 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:10:00,179 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:10:01,165 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12009 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:10:01,182 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:10:01,182 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:10:01,185 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 01:11:01,194 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 01:11:02,196 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:03,198 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:04,200 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:05,203 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:06,205 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:07,210 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:08,214 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:09,216 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:10,218 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:11,220 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:11,221 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 01:11:12,224 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:12,225 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:12,226 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:13,227 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:13,228 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:14,227 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:14,233 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:14,234 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:15,229 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:15,235 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:15,236 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:16,231 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:16,238 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:16,239 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:17,227 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:11:17,233 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:17,241 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:17,242 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:18,228 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:11:18,234 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:18,244 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:18,245 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:19,228 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:11:19,238 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:19,246 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:19,247 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:20,230 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:11:20,241 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:20,248 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:20,249 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:21,231 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:11:21,247 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:21,251 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:21,252 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:22,237 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11011 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:11:22,248 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:11:22,251 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 01:12:22,253 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 01:12:23,256 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:24,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:25,270 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:26,274 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:27,281 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:28,283 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:30,286 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:31,290 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:32,294 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:33,296 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:33,298 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 01:12:34,304 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:34,305 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:35,305 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:35,308 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:35,310 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:36,311 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:36,311 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:37,306 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:37,314 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:37,314 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:38,308 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:38,317 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:38,317 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:39,306 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:12:39,312 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:39,319 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:39,320 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:40,307 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:12:40,315 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:40,321 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:40,322 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:41,308 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:12:41,317 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:41,325 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:41,325 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:42,310 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:12:42,320 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:42,327 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:42,328 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:43,311 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:12:43,333 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:43,334 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:44,312 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11007 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:12:44,329 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:45,313 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12008 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:12:46,314 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 13009 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:12:46,331 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:47,316 WARN org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 14010 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:12:47,336 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:12:47,339 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 01:13:47,342 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 01:13:48,345 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:13:49,348 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:13:50,352 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:13:51,354 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:13:52,357 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:13:53,360 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:13:54,363 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:13:55,366 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:13:56,368 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:13:57,370 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:13:57,372 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 01:13:58,376 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:13:58,376 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:13:58,377 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:13:59,379 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:13:59,380 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:13:59,380 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:14:00,383 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:14:00,384 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:14:00,384 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:14:01,386 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:14:01,390 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:14:01,391 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:14:02,388 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:14:02,393 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:14:02,394 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:14:03,378 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:14:03,390 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:14:03,396 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:14:03,400 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:14:04,379 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:14:04,398 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:14:04,402 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:14:05,382 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:14:05,397 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:14:05,399 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:14:05,404 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:14:06,383 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:14:06,400 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:14:06,401 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:14:06,408 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:14:07,384 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10007 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:14:07,404 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:14:08,385 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11008 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:14:08,403 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:14:08,411 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:14:09,386 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12009 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:14:09,405 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:14:09,407 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 01:15:09,410 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 01:15:10,413 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:11,415 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:13,418 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:14,420 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:16,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:17,425 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:18,429 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:19,430 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:20,432 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:21,434 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:21,436 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 01:15:22,441 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:22,442 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:22,446 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:23,445 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:23,445 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:23,447 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:24,447 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:24,448 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:24,449 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:25,451 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:25,451 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:25,451 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:26,455 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:26,456 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:26,455 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:27,449 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:15:27,459 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:27,459 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:27,460 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:28,450 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:15:28,461 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:28,461 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:28,462 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:29,451 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:15:29,464 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:29,464 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:29,465 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:30,452 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:15:30,466 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:30,466 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:30,467 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:31,454 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10008 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:15:31,468 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:31,469 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:32,455 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11009 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:15:32,472 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:15:32,474 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 01:16:32,477 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 01:16:33,482 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:35,484 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:36,486 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:37,489 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:38,492 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:39,495 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:40,497 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:41,501 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:42,503 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:43,507 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:43,508 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 01:16:44,511 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:44,514 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:45,513 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:45,514 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:45,516 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:46,515 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:46,518 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:47,515 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:47,517 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:47,520 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:48,518 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:48,520 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:48,522 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:49,516 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:16:49,519 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:49,522 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:49,524 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:50,517 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:16:50,521 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:50,525 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:50,526 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:51,518 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:16:51,529 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:51,529 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:51,531 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:52,519 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:16:52,532 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:52,534 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:52,535 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:53,520 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:16:53,536 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:54,521 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11007 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:16:54,535 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:54,537 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:54,538 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:55,522 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12009 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:16:55,538 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:16:55,540 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 01:17:55,544 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 01:17:57,548 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:17:58,550 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:00,552 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:01,556 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:02,558 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:03,560 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:04,563 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:05,565 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:06,569 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:07,572 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:07,573 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 01:18:08,579 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:08,581 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:09,578 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:09,581 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:09,583 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:10,584 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:11,581 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:11,584 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:11,587 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:12,585 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:12,589 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:12,590 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:13,580 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:18:13,587 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:13,591 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:13,592 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:14,581 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:18:14,588 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:14,595 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:15,583 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:18:15,589 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:15,593 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:15,598 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:16,585 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:18:16,592 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:16,600 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:17,588 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10008 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:18:17,597 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:17,598 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:17,601 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:18,590 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11011 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:18:18,601 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:18,603 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:18,604 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:19,593 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12013 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:18:19,604 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:19,606 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:18:19,610 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 01:19:19,612 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 01:19:20,615 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:21,617 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:22,620 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:23,622 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:24,625 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:25,627 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:26,629 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:27,631 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:28,633 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:29,635 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:29,637 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 01:19:30,642 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:30,643 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:30,644 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:31,644 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:31,645 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:31,647 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:32,647 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:32,648 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:32,649 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:33,651 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:33,652 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:33,652 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:34,654 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:34,655 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:34,656 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:35,646 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:19:35,656 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:35,657 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:35,658 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:36,646 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:19:36,660 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:36,661 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:36,661 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:37,647 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:19:37,663 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:37,664 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:37,664 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:38,650 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:19:38,665 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:38,666 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:39,652 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10007 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:19:39,665 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:39,667 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:39,667 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:40,653 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11009 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:19:40,667 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:19:40,669 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 01:20:40,671 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 01:20:41,674 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:20:42,693 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:20:44,694 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:20:45,701 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:20:47,705 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:20:48,707 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:20:49,709 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:20:50,711 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:20:51,713 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:20:52,715 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:20:52,734 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 01:20:53,738 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:20:53,740 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:20:53,740 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:20:54,743 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:20:54,744 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:20:55,743 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:20:55,749 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:20:55,751 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:20:56,752 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:20:56,753 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:20:57,755 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:20:57,756 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:20:57,758 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:20:58,741 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:20:58,758 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:20:58,759 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:20:58,760 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:20:59,742 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:20:59,760 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:20:59,761 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:20:59,762 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:21:00,743 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:21:00,764 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:21:00,766 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:21:00,767 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:21:01,744 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:21:01,767 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:21:01,768 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:21:01,771 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:21:02,746 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:21:02,769 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:21:02,770 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:21:02,772 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:21:03,746 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11006 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:21:03,772 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:21:03,774 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:21:03,775 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 01:22:03,777 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 01:22:04,787 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:06,789 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:07,792 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:08,794 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:09,798 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:10,799 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:11,801 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:12,803 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:13,806 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:15,810 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:15,811 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 01:22:16,816 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:16,817 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:16,818 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:17,819 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:17,819 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:18,818 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:18,821 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:18,821 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:19,820 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:19,823 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:19,823 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:20,822 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:20,825 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:20,825 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:21,818 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:22:21,825 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:21,828 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:21,828 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:22,819 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:22:22,828 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:22,830 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:22,831 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:23,821 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:22:23,832 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:23,832 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:24,822 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:22:24,831 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:24,835 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:25,823 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10007 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:22:25,833 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:25,834 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:25,838 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:26,824 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11008 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:22:26,836 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:26,837 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:27,826 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12010 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:22:27,839 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:22:27,841 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 01:23:27,843 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 01:23:28,846 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:29,849 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:30,852 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:31,854 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:32,857 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:33,860 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:34,861 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:36,865 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:37,869 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:38,870 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:38,872 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 01:23:39,875 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:39,878 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:39,879 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:40,878 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:40,881 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:40,881 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:41,880 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:41,882 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:41,882 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:42,887 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:42,888 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:42,888 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:43,890 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:43,890 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:43,891 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:44,882 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:23:44,896 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:44,896 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:45,884 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:23:45,892 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:45,899 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:45,899 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:46,885 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:23:46,894 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:46,902 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:46,903 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:47,887 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9008 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:23:47,896 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:47,904 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:47,904 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:48,888 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10009 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:23:48,906 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:48,906 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:49,889 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11010 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:23:49,899 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:50,891 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12011 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:23:50,901 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:23:50,904 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 01:24:50,907 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 01:24:51,911 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:24:52,913 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:24:53,915 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:24:54,917 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:24:56,920 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:24:57,922 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:24:58,926 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:24:59,929 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:25:00,931 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:25:01,934 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:25:01,936 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 01:25:02,942 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:25:03,941 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:25:03,941 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:25:03,944 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:25:04,943 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:25:04,945 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:25:04,946 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:25:05,948 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:25:05,950 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:25:05,951 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:25:06,949 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:25:06,951 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:25:06,952 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:25:07,943 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:25:07,955 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:25:07,956 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:25:07,957 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:25:08,944 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:25:08,957 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:25:08,959 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:25:08,960 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:25:09,945 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:25:09,962 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:25:09,963 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:25:10,950 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9009 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:25:10,961 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:25:10,968 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:25:10,968 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:25:11,951 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10011 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:25:11,963 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:25:11,970 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:25:11,971 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:25:12,954 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11013 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:25:12,965 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:25:12,972 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:25:12,972 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:25:12,975 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 01:26:12,977 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 01:26:13,981 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:14,988 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:15,990 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:16,992 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:17,994 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:18,996 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:20,000 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:21,002 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:22,004 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:23,006 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:23,008 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 01:26:24,015 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:24,019 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:24,019 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:25,025 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:25,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:25,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:26,027 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:26,029 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:26,030 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:27,029 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:27,031 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:27,032 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:28,034 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:28,036 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:29,020 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:26:29,036 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:29,037 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:29,039 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:30,021 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:26:30,039 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:31,023 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:26:31,041 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:31,042 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:31,043 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:32,024 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:26:32,045 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:32,046 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:32,047 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:33,025 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:26:33,050 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:33,051 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:34,026 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11007 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:26:34,049 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:34,052 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:35,028 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12009 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:26:35,052 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:36,029 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 13010 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:26:36,053 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:26:36,056 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 01:27:36,059 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 01:27:37,062 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:38,070 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:39,073 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:40,075 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:41,077 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:42,080 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:43,082 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:44,084 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:45,089 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:46,110 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:46,113 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 01:27:47,118 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:47,119 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:47,120 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:48,126 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:48,127 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:49,122 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:49,128 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:49,129 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:50,125 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:50,130 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:50,131 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:51,127 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:51,132 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:51,133 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:52,118 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:27:52,130 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:52,135 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:52,136 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:53,120 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:27:53,133 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:53,138 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:53,139 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:54,122 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:27:54,135 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:54,140 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:54,141 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:55,123 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9007 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:27:55,137 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:55,143 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:55,145 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:56,125 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10008 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:27:56,139 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:56,145 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:56,146 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:57,127 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11010 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:27:57,141 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:27:57,143 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 01:28:57,146 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 01:28:58,148 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:28:59,150 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:00,152 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:01,155 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:02,158 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:03,160 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:04,163 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:05,165 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:06,167 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:07,170 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:07,171 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 01:29:08,175 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:08,176 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:08,177 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:09,179 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:09,181 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:09,181 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:10,185 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:10,186 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:10,187 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:11,189 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:11,190 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:11,191 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:12,193 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:12,194 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:12,194 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:13,177 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:29:13,196 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:13,197 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:13,197 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:14,179 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:29:14,199 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:14,200 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:14,201 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:15,180 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:29:15,203 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:15,204 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:15,204 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:16,181 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:29:16,206 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:16,207 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:16,208 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:17,183 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:29:17,209 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:17,210 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:17,211 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:29:17,216 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 01:30:17,218 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 01:30:18,222 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:19,224 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:20,226 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:21,228 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:22,231 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:24,234 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:25,236 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:26,238 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:27,240 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:28,242 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:28,245 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 01:30:29,249 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:29,252 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:29,254 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:30,253 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:30,254 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:30,256 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:31,254 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:31,256 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:31,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:32,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:32,259 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:32,261 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:33,261 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:33,263 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:33,263 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:34,256 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:30:34,263 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:34,265 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:34,266 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:35,258 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:30:35,265 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:35,268 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:35,268 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:36,260 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:30:36,267 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:36,270 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:36,270 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:37,261 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9007 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:30:37,269 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:37,272 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:37,274 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:38,262 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10008 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:30:38,271 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:38,276 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:39,264 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11010 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:30:39,275 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:30:39,278 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 01:31:39,281 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 01:31:40,284 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:41,286 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:42,288 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:43,290 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:44,292 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:45,295 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:46,297 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:47,300 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:48,302 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:49,304 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:49,307 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 01:31:50,313 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:50,314 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:50,316 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:51,316 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:51,317 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:51,318 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:52,320 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:52,321 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:52,323 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:53,323 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:53,324 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:53,325 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:54,327 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:54,328 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:54,329 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:55,318 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:31:55,332 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:55,333 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:55,334 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:56,319 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:31:56,336 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:56,337 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:56,338 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:57,320 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:31:57,340 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:57,341 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:57,342 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:58,321 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:31:58,345 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:58,347 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:58,348 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:59,322 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:31:59,349 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:31:59,350 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:32:00,323 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11006 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:32:00,351 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:32:00,355 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 01:33:00,373 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 01:33:02,377 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:03,380 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:04,383 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:05,385 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:06,387 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:07,389 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:08,392 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:09,395 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:10,410 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:11,413 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:11,415 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
java.net.NoRouteToHostException: No Route to Host from  master100/192.168.1.100 to slave101:8020 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor12.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:756)
	at org.apache.hadoop.ipc.Client.call(Client.java:1415)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
Caused by: java.net.NoRouteToHostException: 没有到主机的路由
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:744)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 11 more
2017-12-30 01:33:12,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:13,421 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:13,426 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:13,428 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:14,424 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:14,433 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:15,426 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:15,431 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:15,435 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:16,428 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:16,433 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:16,441 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:17,428 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:33:17,430 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:17,435 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:17,444 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:18,429 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:33:18,432 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:18,437 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:18,446 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:19,430 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:33:19,434 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:19,449 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:20,433 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:33:20,436 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:20,440 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:20,452 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:21,434 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10007 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:33:21,438 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:21,442 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:22,435 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11008 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 01:33:22,440 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:22,444 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:22,455 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:23,436 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12009 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:33:23,446 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:24,438 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 13011 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost, 192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost]
2017-12-30 01:33:24,448 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 01:33:24,454 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.101:8485: No Route to Host from  master100/192.168.1.100 to slave101:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.102:8485: No Route to Host from  master100/192.168.1.100 to slave102:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
192.168.1.103:8485: No Route to Host from  master100/192.168.1.100 to slave103:8485 failed on socket timeout exception: java.net.NoRouteToHostException: 没有到主机的路由; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 01:34:23,598 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2017-12-30 01:34:23,603 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at master100/192.168.1.100
************************************************************/
2017-12-30 02:38:31,517 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = master100/192.168.1.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.1
STARTUP_MSG:   classpath = /home/tools/hadoop-2.5.1/etc/hadoop:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jsch-0.1.42.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-el-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/xz-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/asm-3.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/junit-4.11.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/hadoop-auth-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/hadoop-annotations-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jettison-1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/activation-1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/hadoop-nfs-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/hadoop-common-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/hadoop-common-2.5.1-tests.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-2.5.1-tests.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jline-0.9.94.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-client-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-api-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-common-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-common-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.1-tests.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-10-20T05:53Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2017-12-30 02:38:31,619 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-12-30 02:38:31,675 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2017-12-30 02:38:33,209 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-12-30 02:38:34,938 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-12-30 02:38:34,939 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2017-12-30 02:38:34,952 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://aaaaa
2017-12-30 02:38:34,955 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use aaaaa to access this namenode/service.
2017-12-30 02:38:38,167 INFO org.apache.hadoop.hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
2017-12-30 02:38:38,168 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://master100:50070
2017-12-30 02:38:39,592 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-12-30 02:38:39,600 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2017-12-30 02:38:39,630 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-12-30 02:38:39,640 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-12-30 02:38:39,641 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-12-30 02:38:39,641 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-12-30 02:38:40,782 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-12-30 02:38:40,926 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-12-30 02:38:43,245 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2017-12-30 02:38:43,245 INFO org.mortbay.log: jetty-6.1.26
2017-12-30 02:38:48,363 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: 'signature.secret' configuration not set, using a random value as secret
2017-12-30 02:38:50,378 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@master100:50070
2017-12-30 02:38:51,530 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-12-30 02:38:53,064 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2017-12-30 02:38:53,862 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2017-12-30 02:38:53,862 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2017-12-30 02:38:53,871 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-12-30 02:38:53,876 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2017 十二月 30 02:38:53
2017-12-30 02:38:53,884 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2017-12-30 02:38:53,884 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-12-30 02:38:54,206 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2017-12-30 02:38:54,206 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2017-12-30 02:38:54,274 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2017-12-30 02:38:54,274 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2017-12-30 02:38:54,274 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2017-12-30 02:38:54,274 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2017-12-30 02:38:54,275 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2017-12-30 02:38:54,275 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2017-12-30 02:38:54,275 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2017-12-30 02:38:54,275 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2017-12-30 02:38:54,275 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2017-12-30 02:38:54,283 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2017-12-30 02:38:54,283 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2017-12-30 02:38:54,284 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2017-12-30 02:38:54,284 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Determined nameservice ID: aaaaa
2017-12-30 02:38:54,284 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: true
2017-12-30 02:38:54,287 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2017-12-30 02:39:03,217 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2017-12-30 02:39:03,217 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-12-30 02:39:03,218 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2017-12-30 02:39:03,218 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2017-12-30 02:39:03,224 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2017-12-30 02:39:03,248 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2017-12-30 02:39:03,248 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-12-30 02:39:03,248 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2017-12-30 02:39:03,248 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2017-12-30 02:39:03,251 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-12-30 02:39:03,251 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2017-12-30 02:39:03,251 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2017-12-30 02:39:03,253 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2017-12-30 02:39:03,257 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-12-30 02:39:03,264 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2017-12-30 02:39:03,265 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-12-30 02:39:03,265 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 966.7 MB = 297.0 KB
2017-12-30 02:39:03,265 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2017-12-30 02:39:03,281 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2017-12-30 02:39:03,282 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2017-12-30 02:39:03,282 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2017-12-30 02:39:04,648 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop2/dfs/name/in_use.lock acquired by nodename 2605@master100
2017-12-30 02:39:13,184 WARN org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory: The property 'ssl.client.truststore.location' has not been set, no TrustStore will be loaded
2017-12-30 02:39:22,227 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 02:39:22,542 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:22,543 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:22,543 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:23,229 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7003 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 02:39:23,545 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:23,546 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:23,547 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:24,230 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 02:39:24,549 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:24,550 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:24,550 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:25,231 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 02:39:25,552 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:25,552 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:25,553 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:26,232 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 02:39:26,554 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:26,555 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:26,555 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:27,233 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11007 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 02:39:27,556 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:27,557 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:27,557 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:28,234 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 12008 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 02:39:28,558 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:28,580 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:28,582 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:29,235 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 13009 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 02:39:29,560 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:29,582 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:29,584 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:30,236 WARN org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 14010 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 02:39:30,562 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:30,584 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:30,585 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:31,242 WARN org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 15016 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 02:39:31,564 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:31,587 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:31,588 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:31,591 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.102:8485: Call From master100/192.168.1.100 to slave102:8485 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
192.168.1.103:8485: Call From master100/192.168.1.100 to slave103:8485 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
192.168.1.101:8485: Call From master100/192.168.1.100 to slave101:8485 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:636)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:279)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:955)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:700)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:529)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:751)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:735)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1473)
2017-12-30 02:39:31,594 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2017-12-30 02:39:32,005 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 4 INodes.
2017-12-30 02:39:34,522 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 2 seconds.
2017-12-30 02:39:34,522 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 199 from /opt/hadoop2/dfs/name/current/fsimage_0000000000000000199
2017-12-30 02:39:34,536 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=true, haEnabled=true, isRollingUpgrade=false)
2017-12-30 02:39:34,537 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2017-12-30 02:39:34,537 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 31255 msecs
2017-12-30 02:39:43,679 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to master100:8020
2017-12-30 02:39:43,689 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-12-30 02:39:43,728 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2017-12-30 02:39:44,139 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2017-12-30 02:39:44,357 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2017-12-30 02:39:44,357 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2017-12-30 02:39:44,359 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 2.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-12-30 02:39:44,557 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-12-30 02:39:44,568 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2017-12-30 02:39:44,586 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: master100/192.168.1.100:8020
2017-12-30 02:39:44,587 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2017-12-30 02:39:44,602 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node at slave101/192.168.1.101:8020 every 120 seconds.
2017-12-30 02:39:44,631 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN at http://slave101:50070
Serving checkpoints at http://master100:50070
2017-12-30 02:39:45,636 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:45,639 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:45,640 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:46,639 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:46,640 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:46,641 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:47,641 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:47,642 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:47,643 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:48,647 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:48,647 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:48,648 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:49,649 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:49,650 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:49,652 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:50,636 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 02:39:50,655 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:50,655 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:50,656 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:51,638 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 02:39:51,658 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:51,659 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:51,660 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:52,639 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 02:39:52,663 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:52,664 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:53,641 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9007 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 02:39:53,666 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:53,669 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:54,642 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10008 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 02:39:54,669 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:54,672 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:39:55,644 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11010 ms (timeout=20000 ms) for a response for selectInputStreams. Exceptions so far: [192.168.1.102:8485: Call From master100/192.168.1.100 to slave102:8485 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, 192.168.1.103:8485: Call From master100/192.168.1.100 to slave103:8485 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused]
2017-12-30 02:39:56,416 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 1 successful responses:
192.168.1.101:8485: [[200,201], [202,203], [204,205], [206,207], [208,209], [210,211], [212,213], [214,215], [216,217], [218,219], [220,221], [222,223], [224,225], [226,227], [228,229], [230,231], [232,233], [234,235], [236,237], [238,239], [240,241], [242,243], [244,245]]
2 exceptions thrown:
192.168.1.102:8485: Call From master100/192.168.1.100 to slave102:8485 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
192.168.1.103:8485: Call From master100/192.168.1.100 to slave103:8485 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:212)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:324)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 02:40:04,054 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(192.168.1.101, datanodeUuid=c1a65381-b373-45ea-8031-47c9f6c4e577, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-291bf135-e81a-466b-8cca-005142eed37a;nsid=18366549;c=0) storage c1a65381-b373-45ea-8031-47c9f6c4e577
2017-12-30 02:40:04,068 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/192.168.1.101:50010
2017-12-30 02:40:06,245 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-fa575c26-9138-4923-adfe-224bf6e42868 for DN 192.168.1.101:50010
2017-12-30 02:40:06,599 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 1 has reached the threshold 0.9990 of total blocks 2. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2017-12-30 02:40:06,613 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from DatanodeStorage[DS-fa575c26-9138-4923-adfe-224bf6e42868,DISK,NORMAL] after starting up or becoming active. Its block contents are no longer considered stale
2017-12-30 02:40:06,613 INFO BlockStateChange: BLOCK* processReport: from storage DS-fa575c26-9138-4923-adfe-224bf6e42868 node DatanodeRegistration(192.168.1.101, datanodeUuid=c1a65381-b373-45ea-8031-47c9f6c4e577, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-291bf135-e81a-466b-8cca-005142eed37a;nsid=18366549;c=0), blocks: 2, hasStaleStorages: false, processing time: 41 msecs
2017-12-30 02:40:07,793 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(192.168.1.102, datanodeUuid=39baae53-80c7-4807-a492-8cd1ad4291cf, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-291bf135-e81a-466b-8cca-005142eed37a;nsid=18366549;c=0) storage 39baae53-80c7-4807-a492-8cd1ad4291cf
2017-12-30 02:40:07,794 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/192.168.1.102:50010
2017-12-30 02:40:08,201 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-7cdd7c35-81c1-401d-ac3b-cde27a144a3d for DN 192.168.1.102:50010
2017-12-30 02:40:08,373 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from DatanodeStorage[DS-7cdd7c35-81c1-401d-ac3b-cde27a144a3d,DISK,NORMAL] after starting up or becoming active. Its block contents are no longer considered stale
2017-12-30 02:40:08,374 INFO BlockStateChange: BLOCK* processReport: from storage DS-7cdd7c35-81c1-401d-ac3b-cde27a144a3d node DatanodeRegistration(192.168.1.102, datanodeUuid=39baae53-80c7-4807-a492-8cd1ad4291cf, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-291bf135-e81a-466b-8cca-005142eed37a;nsid=18366549;c=0), blocks: 2, hasStaleStorages: false, processing time: 1 msecs
2017-12-30 02:40:08,904 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(192.168.1.103, datanodeUuid=f82ecc71-3014-4c25-9c75-013de0470b2c, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-291bf135-e81a-466b-8cca-005142eed37a;nsid=18366549;c=0) storage f82ecc71-3014-4c25-9c75-013de0470b2c
2017-12-30 02:40:08,905 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/192.168.1.103:50010
2017-12-30 02:40:09,091 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-b50a7f4e-71dd-4065-a0c8-0dde4734ec7d for DN 192.168.1.103:50010
2017-12-30 02:40:09,142 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from DatanodeStorage[DS-b50a7f4e-71dd-4065-a0c8-0dde4734ec7d,DISK,NORMAL] after starting up or becoming active. Its block contents are no longer considered stale
2017-12-30 02:40:09,142 INFO BlockStateChange: BLOCK* processReport: from storage DS-b50a7f4e-71dd-4065-a0c8-0dde4734ec7d node DatanodeRegistration(192.168.1.103, datanodeUuid=f82ecc71-3014-4c25-9c75-013de0470b2c, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-291bf135-e81a-466b-8cca-005142eed37a;nsid=18366549;c=0), blocks: 2, hasStaleStorages: false, processing time: 1 msecs
2017-12-30 02:40:26,628 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 2 has reached the threshold 0.9990 of total blocks 2. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2017-12-30 02:40:36,638 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 103 secs
2017-12-30 02:40:36,638 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2017-12-30 02:40:36,638 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 3 datanodes
2017-12-30 02:40:36,639 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2017-12-30 02:40:56,504 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@40124467 expecting start txid #200
2017-12-30 02:40:56,504 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=200&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:40:56,508 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=200&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:56,508 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=200&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:56,802 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=200&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:40:56,802 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@6f48e70d expecting start txid #202
2017-12-30 02:40:56,802 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=202&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:40:56,803 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=202&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:56,803 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=202&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:56,833 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=202&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:40:56,833 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1b393f8f expecting start txid #204
2017-12-30 02:40:56,833 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=204&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:40:56,833 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=204&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:56,833 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=204&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:56,856 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=204&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:40:56,856 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@4b7bd33f expecting start txid #206
2017-12-30 02:40:56,856 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=206&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:40:56,856 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=206&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:56,856 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=206&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:56,873 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=206&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:40:56,873 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2e69f3d0 expecting start txid #208
2017-12-30 02:40:56,873 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=208&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:40:56,873 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=208&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:56,874 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=208&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:56,883 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=208&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:40:56,883 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2e05f47e expecting start txid #210
2017-12-30 02:40:56,883 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=210&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:40:56,883 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=210&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:56,884 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=210&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:56,914 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=210&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:40:56,914 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@8f693cd expecting start txid #212
2017-12-30 02:40:56,914 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=212&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:40:56,914 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=212&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:56,914 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=212&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:56,934 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=212&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:40:56,935 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@74617c53 expecting start txid #214
2017-12-30 02:40:56,935 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=214&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:40:56,935 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=214&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:56,935 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=214&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:56,947 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=214&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:40:56,948 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2c2968d6 expecting start txid #216
2017-12-30 02:40:56,948 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=216&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:40:56,948 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=216&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:56,948 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=216&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:56,964 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=216&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:40:56,964 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@52a1d040 expecting start txid #218
2017-12-30 02:40:56,965 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=218&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:40:56,965 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=218&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:56,965 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=218&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:56,971 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=218&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:40:56,971 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@7d6f4421 expecting start txid #220
2017-12-30 02:40:56,971 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=220&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:40:56,972 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=220&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:56,972 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=220&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:56,977 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=220&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:40:56,977 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@13e212dd expecting start txid #222
2017-12-30 02:40:56,978 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=222&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:40:56,978 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=222&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:56,978 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=222&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:57,013 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=222&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:40:57,014 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@5f44755d expecting start txid #224
2017-12-30 02:40:57,014 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=224&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:40:57,014 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=224&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:57,014 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=224&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:57,026 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=224&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:40:57,026 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@7755d88 expecting start txid #226
2017-12-30 02:40:57,026 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=226&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:40:57,026 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=226&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:57,026 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=226&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:57,073 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=226&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:40:57,073 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2a4f8f8b expecting start txid #228
2017-12-30 02:40:57,073 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=228&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:40:57,073 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=228&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:57,073 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=228&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:57,081 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=228&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:40:57,081 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@4d590460 expecting start txid #230
2017-12-30 02:40:57,081 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=230&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:40:57,082 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=230&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:57,082 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=230&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:57,089 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=230&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:40:57,090 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@f2e624c expecting start txid #232
2017-12-30 02:40:57,090 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=232&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:40:57,090 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=232&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:57,090 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=232&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:57,131 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=232&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:40:57,131 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2e37735d expecting start txid #234
2017-12-30 02:40:57,132 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=234&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:40:57,132 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=234&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:57,132 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=234&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:57,396 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=234&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:40:57,396 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3a76f65f expecting start txid #236
2017-12-30 02:40:57,396 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=236&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:40:57,396 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=236&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:57,397 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=236&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:57,409 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=236&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:40:57,409 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@5828f4f5 expecting start txid #238
2017-12-30 02:40:57,409 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=238&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:40:57,409 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=238&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:57,409 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=238&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:57,415 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=238&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:40:57,416 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@68ea2e0a expecting start txid #240
2017-12-30 02:40:57,416 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=240&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:40:57,416 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=240&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:57,416 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=240&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:57,421 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=240&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:40:57,422 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@6674c855 expecting start txid #242
2017-12-30 02:40:57,422 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=242&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:40:57,422 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=242&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:57,422 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=242&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:57,433 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=242&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:40:57,433 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@7d0c78ff expecting start txid #244
2017-12-30 02:40:57,433 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=244&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:40:57,433 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=244&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:57,433 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=244&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:40:57,447 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave101:8480/getJournal?jid=aaaaa&segmentTxId=244&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:40:57,447 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Loaded 46 edits starting from txid 199 
2017-12-30 02:41:39,117 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Get corrupt file blocks returned error: Operation category READ is not supported in state standby
2017-12-30 02:42:04,195 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Get corrupt file blocks returned error: Operation category READ is not supported in state standby
2017-12-30 02:42:14,909 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 8020, call org.apache.hadoop.hdfs.server.protocol.NamenodeProtocol.rollEditLog from 192.168.1.101:49875 Call#9 Retry#0: org.apache.hadoop.ipc.StandbyException: Operation category JOURNAL is not supported in state standby
2017-12-30 02:42:36,364 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Get corrupt file blocks returned error: Operation category READ is not supported in state standby
2017-12-30 02:42:57,492 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Triggering log roll on remote NameNode slave101/192.168.1.101:8020
2017-12-30 02:42:57,697 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Unable to trigger a roll of the active NN
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category JOURNAL is not supported in state standby
	at org.apache.hadoop.hdfs.server.namenode.ha.StandbyState.checkOperation(StandbyState.java:87)
	at org.apache.hadoop.hdfs.server.namenode.NameNode$NameNodeHAContext.checkOperation(NameNode.java:1688)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkOperation(FSNamesystem.java:1258)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:5765)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:886)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:11214)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at org.apache.hadoop.ipc.Client.call(Client.java:1411)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy14.rollEditLog(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.rollEditLog(NamenodeProtocolTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.triggerActiveLogRoll(EditLogTailer.java:271)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$600(EditLogTailer.java:61)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:313)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 02:42:57,768 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2017-12-30 02:42:57,772 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at master100/192.168.1.100
************************************************************/
2017-12-30 02:46:55,270 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = master100/192.168.1.100
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.1
STARTUP_MSG:   classpath = /home/tools/hadoop-2.5.1/etc/hadoop:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jsch-0.1.42.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-el-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/xz-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/asm-3.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/junit-4.11.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/hadoop-auth-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/hadoop-annotations-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jettison-1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/activation-1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/hadoop-nfs-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/hadoop-common-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/common/hadoop-common-2.5.1-tests.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-2.5.1-tests.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jline-0.9.94.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-client-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-api-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-common-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-common-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.1-tests.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/tools/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.1.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'root' on 2014-10-20T05:53Z
STARTUP_MSG:   java = 1.7.0_80
************************************************************/
2017-12-30 02:46:55,285 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
2017-12-30 02:46:55,296 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
2017-12-30 02:46:56,084 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2017-12-30 02:46:56,352 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2017-12-30 02:46:56,352 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
2017-12-30 02:46:56,357 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://aaaaa
2017-12-30 02:46:56,358 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use aaaaa to access this namenode/service.
2017-12-30 02:46:57,708 INFO org.apache.hadoop.hdfs.DFSUtil: Starting web server as: ${dfs.web.authentication.kerberos.principal}
2017-12-30 02:46:57,709 INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://master100:50070
2017-12-30 02:46:57,958 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-12-30 02:46:57,976 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
2017-12-30 02:46:58,050 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-12-30 02:46:58,073 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-12-30 02:46:58,074 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-12-30 02:46:58,074 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-12-30 02:46:58,408 INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-12-30 02:46:58,426 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-12-30 02:46:58,710 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50070
2017-12-30 02:46:58,710 INFO org.mortbay.log: jetty-6.1.26
2017-12-30 02:47:00,894 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter: 'signature.secret' configuration not set, using a random value as secret
2017-12-30 02:47:01,393 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@master100:50070
2017-12-30 02:47:01,672 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-12-30 02:47:01,847 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
2017-12-30 02:47:01,985 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
2017-12-30 02:47:01,985 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
2017-12-30 02:47:01,992 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-12-30 02:47:01,996 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2017 十二月 30 02:47:01
2017-12-30 02:47:02,004 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
2017-12-30 02:47:02,004 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-12-30 02:47:02,011 INFO org.apache.hadoop.util.GSet: 2.0% max memory 966.7 MB = 19.3 MB
2017-12-30 02:47:02,012 INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
2017-12-30 02:47:02,133 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
2017-12-30 02:47:02,134 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 3
2017-12-30 02:47:02,134 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
2017-12-30 02:47:02,134 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
2017-12-30 02:47:02,134 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
2017-12-30 02:47:02,135 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
2017-12-30 02:47:02,135 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
2017-12-30 02:47:02,135 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
2017-12-30 02:47:02,135 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
2017-12-30 02:47:02,153 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
2017-12-30 02:47:02,153 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
2017-12-30 02:47:02,153 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
2017-12-30 02:47:02,155 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Determined nameservice ID: aaaaa
2017-12-30 02:47:02,155 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: true
2017-12-30 02:47:02,161 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Append Enabled: true
2017-12-30 02:47:03,004 INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
2017-12-30 02:47:03,004 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-12-30 02:47:03,005 INFO org.apache.hadoop.util.GSet: 1.0% max memory 966.7 MB = 9.7 MB
2017-12-30 02:47:03,005 INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
2017-12-30 02:47:03,020 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
2017-12-30 02:47:03,110 INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
2017-12-30 02:47:03,110 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-12-30 02:47:03,115 INFO org.apache.hadoop.util.GSet: 0.25% max memory 966.7 MB = 2.4 MB
2017-12-30 02:47:03,115 INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
2017-12-30 02:47:03,122 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-12-30 02:47:03,123 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
2017-12-30 02:47:03,123 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
2017-12-30 02:47:03,142 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
2017-12-30 02:47:03,143 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-12-30 02:47:03,175 INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
2017-12-30 02:47:03,175 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2017-12-30 02:47:03,176 INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 966.7 MB = 297.0 KB
2017-12-30 02:47:03,180 INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
2017-12-30 02:47:03,221 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: ACLs enabled? false
2017-12-30 02:47:03,226 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: XAttrs enabled? true
2017-12-30 02:47:03,226 INFO org.apache.hadoop.hdfs.server.namenode.NNConf: Maximum size of an xattr: 16384
2017-12-30 02:47:03,333 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /opt/hadoop2/dfs/name/in_use.lock acquired by nodename 3404@master100
2017-12-30 02:47:07,878 WARN org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory: The property 'ssl.client.truststore.location' has not been set, no TrustStore will be loaded
2017-12-30 02:47:11,406 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:11,406 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:11,407 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:12,409 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:12,409 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:12,410 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:13,412 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:13,413 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:13,414 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:14,416 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:14,417 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:14,417 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:15,374 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6002 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 02:47:15,418 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:15,419 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:15,419 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:16,375 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7004 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 02:47:16,421 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:16,421 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:16,421 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:17,376 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8005 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 02:47:17,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:17,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:17,424 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:18,377 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9006 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 02:47:18,426 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:18,427 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:18,428 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:19,378 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 10007 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 02:47:19,429 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:19,430 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:19,430 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:20,379 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 11008 ms (timeout=20000 ms) for a response for selectInputStreams. No responses yet.
2017-12-30 02:47:20,434 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:20,434 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:20,435 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:20,448 WARN org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input streams from QJM to [192.168.1.101:8485, 192.168.1.102:8485, 192.168.1.103:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.1.102:8485: Call From master100/192.168.1.100 to slave102:8485 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
192.168.1.103:8485: Call From master100/192.168.1.100 to slave103:8485 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
192.168.1.101:8485: Call From master100/192.168.1.100 to slave101:8485 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:223)
	at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:142)
	at org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:471)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.selectInputStreams(JournalSet.java:260)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1430)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1450)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:636)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:279)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:955)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:700)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:529)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:751)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:735)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1407)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.main(NameNode.java:1473)
2017-12-30 02:47:20,455 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
2017-12-30 02:47:20,569 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 4 INodes.
2017-12-30 02:47:21,069 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
2017-12-30 02:47:21,070 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 199 from /opt/hadoop2/dfs/name/current/fsimage_0000000000000000199
2017-12-30 02:47:21,156 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=true, haEnabled=true, isRollingUpgrade=false)
2017-12-30 02:47:21,159 INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
2017-12-30 02:47:21,160 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 17933 msecs
2017-12-30 02:47:23,402 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to master100:8020
2017-12-30 02:47:23,449 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-12-30 02:47:23,603 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 8020
2017-12-30 02:47:23,955 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
2017-12-30 02:47:24,034 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2017-12-30 02:47:24,034 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Number of blocks under construction: 0
2017-12-30 02:47:24,036 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
The reported blocks 0 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 2.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-12-30 02:47:24,870 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-12-30 02:47:24,876 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 8020: starting
2017-12-30 02:47:24,933 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: master100/192.168.1.100:8020
2017-12-30 02:47:24,934 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for standby state
2017-12-30 02:47:24,989 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Will roll logs on active node at slave101/192.168.1.101:8020 every 120 seconds.
2017-12-30 02:47:25,098 INFO org.apache.hadoop.hdfs.server.namenode.ha.StandbyCheckpointer: Starting standby checkpoint thread...
Checkpointing active NN at http://slave101:50070
Serving checkpoints at http://master100:50070
2017-12-30 02:47:26,114 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:26,118 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:26,121 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:27,118 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:27,121 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:27,123 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:28,121 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave103/192.168.1.103:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:28,123 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave102/192.168.1.102:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:28,127 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:29,307 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: slave101/192.168.1.101:8485. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2017-12-30 02:47:30,136 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2dad3d89 expecting start txid #200
2017-12-30 02:47:30,139 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=200&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:47:30,180 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=200&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:30,180 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=200&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:34,536 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader: replaying edit log: 1/2 transactions completed. (50%)
2017-12-30 02:47:34,538 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=200&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 4 seconds
2017-12-30 02:47:34,538 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@48a304cc expecting start txid #202
2017-12-30 02:47:34,543 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=202&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:47:34,544 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=202&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:34,544 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=202&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:34,622 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=202&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:47:34,623 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@46901255 expecting start txid #204
2017-12-30 02:47:34,623 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=204&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:47:34,628 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=204&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:34,628 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=204&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:34,692 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=204&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:47:34,692 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1ca3aea4 expecting start txid #206
2017-12-30 02:47:34,692 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=206&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:47:34,693 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=206&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:34,693 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=206&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:34,751 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=206&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:47:34,752 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3e1e9fac expecting start txid #208
2017-12-30 02:47:34,752 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=208&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:47:34,752 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=208&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:34,752 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=208&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:34,881 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=208&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:47:34,881 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@4c84f510 expecting start txid #210
2017-12-30 02:47:34,882 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=210&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:47:34,882 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=210&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:34,882 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=210&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:34,951 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=210&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:47:34,951 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2cf514af expecting start txid #212
2017-12-30 02:47:34,952 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=212&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:47:34,952 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=212&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:34,952 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=212&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:35,048 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=212&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:47:35,048 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@e210438 expecting start txid #214
2017-12-30 02:47:35,049 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=214&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:47:35,049 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=214&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:35,049 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=214&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:35,128 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=214&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:47:35,128 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@199bffc7 expecting start txid #216
2017-12-30 02:47:35,129 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=216&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:47:35,129 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=216&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:35,129 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=216&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:35,235 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=216&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:47:35,238 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@50b56ef3 expecting start txid #218
2017-12-30 02:47:35,239 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=218&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:47:35,239 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=218&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:35,239 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=218&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:35,315 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=218&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:47:35,316 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@37873cea expecting start txid #220
2017-12-30 02:47:35,320 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=220&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:47:35,320 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=220&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:35,320 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=220&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:35,381 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=220&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:47:35,382 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@fb04321 expecting start txid #222
2017-12-30 02:47:35,382 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=222&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:47:35,382 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=222&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:35,382 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=222&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:35,461 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=222&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:47:35,461 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@7d073392 expecting start txid #224
2017-12-30 02:47:35,462 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=224&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:47:35,462 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=224&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:35,465 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=224&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:35,496 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=224&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:47:35,497 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@63caf65e expecting start txid #226
2017-12-30 02:47:35,497 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=226&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:47:35,508 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=226&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:35,508 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=226&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:35,529 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=226&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:47:35,530 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@21f4c881 expecting start txid #228
2017-12-30 02:47:35,530 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=228&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:47:35,537 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=228&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:35,537 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=228&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:35,560 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=228&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:47:35,561 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@4d979e91 expecting start txid #230
2017-12-30 02:47:35,561 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=230&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:47:35,564 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=230&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:35,564 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=230&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:35,621 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=230&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:47:35,621 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1d2b6963 expecting start txid #232
2017-12-30 02:47:35,621 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=232&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:47:35,621 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=232&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:35,621 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=232&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:35,651 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=232&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:47:35,652 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@d13f18b expecting start txid #234
2017-12-30 02:47:35,652 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=234&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:47:35,652 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=234&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:35,652 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=234&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:35,676 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=234&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:47:35,676 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1856e362 expecting start txid #236
2017-12-30 02:47:35,676 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=236&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:47:35,677 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=236&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:35,677 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=236&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:35,715 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=236&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:47:35,715 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@706a4369 expecting start txid #238
2017-12-30 02:47:35,715 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=238&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:47:35,716 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=238&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:35,716 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=238&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:35,756 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=238&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:47:35,756 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@506fdc27 expecting start txid #240
2017-12-30 02:47:35,756 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=240&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:47:35,756 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=240&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:35,757 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=240&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:35,784 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=240&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:47:35,784 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@5fdeadb2 expecting start txid #242
2017-12-30 02:47:35,785 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=242&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:47:35,785 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=242&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:35,785 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=242&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:35,811 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=242&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:47:35,811 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@145db24a expecting start txid #244
2017-12-30 02:47:35,811 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=244&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a
2017-12-30 02:47:35,811 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=244&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:35,812 INFO org.apache.hadoop.hdfs.server.namenode.EditLogInputStream: Fast-forwarding stream 'http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=244&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a' to transaction ID 200
2017-12-30 02:47:35,831 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file http://slave102:8480/getJournal?jid=aaaaa&segmentTxId=244&storageInfo=-57%3A18366549%3A0%3ACID-291bf135-e81a-466b-8cca-005142eed37a of size 42 edits # 2 loaded in 0 seconds
2017-12-30 02:47:35,832 INFO org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Loaded 46 edits starting from txid 199 
2017-12-30 02:47:40,209 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(192.168.1.102, datanodeUuid=39baae53-80c7-4807-a492-8cd1ad4291cf, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-291bf135-e81a-466b-8cca-005142eed37a;nsid=18366549;c=0) storage 39baae53-80c7-4807-a492-8cd1ad4291cf
2017-12-30 02:47:40,307 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/192.168.1.102:50010
2017-12-30 02:47:41,376 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(192.168.1.103, datanodeUuid=f82ecc71-3014-4c25-9c75-013de0470b2c, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-291bf135-e81a-466b-8cca-005142eed37a;nsid=18366549;c=0) storage f82ecc71-3014-4c25-9c75-013de0470b2c
2017-12-30 02:47:41,379 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/192.168.1.103:50010
2017-12-30 02:47:42,283 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-b50a7f4e-71dd-4065-a0c8-0dde4734ec7d for DN 192.168.1.103:50010
2017-12-30 02:47:42,286 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-7cdd7c35-81c1-401d-ac3b-cde27a144a3d for DN 192.168.1.102:50010
2017-12-30 02:47:42,837 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
The reported blocks 1 has reached the threshold 0.9990 of total blocks 2. The number of live datanodes 2 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2017-12-30 02:47:42,838 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from DatanodeStorage[DS-7cdd7c35-81c1-401d-ac3b-cde27a144a3d,DISK,NORMAL] after starting up or becoming active. Its block contents are no longer considered stale
2017-12-30 02:47:42,842 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from DatanodeStorage[DS-b50a7f4e-71dd-4065-a0c8-0dde4734ec7d,DISK,NORMAL] after starting up or becoming active. Its block contents are no longer considered stale
2017-12-30 02:47:42,843 INFO BlockStateChange: BLOCK* processReport: from storage DS-b50a7f4e-71dd-4065-a0c8-0dde4734ec7d node DatanodeRegistration(192.168.1.103, datanodeUuid=f82ecc71-3014-4c25-9c75-013de0470b2c, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-291bf135-e81a-466b-8cca-005142eed37a;nsid=18366549;c=0), blocks: 2, hasStaleStorages: false, processing time: 1 msecs
2017-12-30 02:47:42,847 INFO BlockStateChange: BLOCK* processReport: from storage DS-7cdd7c35-81c1-401d-ac3b-cde27a144a3d node DatanodeRegistration(192.168.1.102, datanodeUuid=39baae53-80c7-4807-a492-8cd1ad4291cf, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-291bf135-e81a-466b-8cca-005142eed37a;nsid=18366549;c=0), blocks: 2, hasStaleStorages: false, processing time: 184 msecs
2017-12-30 02:47:45,247 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(192.168.1.101, datanodeUuid=c1a65381-b373-45ea-8031-47c9f6c4e577, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-291bf135-e81a-466b-8cca-005142eed37a;nsid=18366549;c=0) storage c1a65381-b373-45ea-8031-47c9f6c4e577
2017-12-30 02:47:45,248 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/192.168.1.101:50010
2017-12-30 02:47:45,785 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Stopping services started for standby state
2017-12-30 02:47:45,786 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:337)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:282)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:299)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:411)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:295)
2017-12-30 02:47:45,887 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2017-12-30 02:47:45,892 WARN org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory: The property 'ssl.client.truststore.location' has not been set, no TrustStore will be loaded
2017-12-30 02:47:45,918 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Starting recovery process for unclosed journal segments...
2017-12-30 02:47:46,812 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Successfully started new epoch 3
2017-12-30 02:47:46,813 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Beginning recovery of unclosed segment starting at txid 244
2017-12-30 02:47:47,049 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Recovery prepare phase complete. Responses:
192.168.1.103:8485: lastWriterEpoch: 1 lastCommittedTxId: 19
192.168.1.102:8485: segmentState { startTxId: 244 endTxId: 245 isInProgress: false } lastWriterEpoch: 2 lastCommittedTxId: 245
2017-12-30 02:47:47,073 INFO org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Using longest log: 192.168.1.102:8485=segmentState {
  startTxId: 244
  endTxId: 245
  isInProgress: false
}
lastWriterEpoch: 2
lastCommittedTxId: 245

2017-12-30 02:47:48,594 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /opt/hadoop2/dfs/name/current
2017-12-30 02:47:48,649 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Catching up to latest edits from old active before taking over writer role in edits logs
2017-12-30 02:47:48,817 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: Marking all datandoes as stale
2017-12-30 02:47:48,820 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Will take over writing edit logs at txnid 246
2017-12-30 02:47:49,020 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 246
2017-12-30 02:47:50,331 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-fa575c26-9138-4923-adfe-224bf6e42868 for DN 192.168.1.101:50010
2017-12-30 02:47:50,339 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-12-30 02:47:50,339 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning because of pending operations
2017-12-30 02:47:50,380 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: BLOCK* processReport: Received first block report from DatanodeStorage[DS-fa575c26-9138-4923-adfe-224bf6e42868,DISK,NORMAL] after starting up or becoming active. Its block contents are no longer considered stale
2017-12-30 02:47:50,380 INFO BlockStateChange: BLOCK* processReport: from storage DS-fa575c26-9138-4923-adfe-224bf6e42868 node DatanodeRegistration(192.168.1.101, datanodeUuid=c1a65381-b373-45ea-8031-47c9f6c4e577, infoPort=50075, ipcPort=50020, storageInfo=lv=-55;cid=CID-291bf135-e81a-466b-8cca-005142eed37a;nsid=18366549;c=0), blocks: 2, hasStaleStorages: false, processing time: 1 msecs
2017-12-30 02:47:50,383 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 44 millisecond(s).
2017-12-30 02:48:03,348 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
The reported blocks 2 has reached the threshold 0.9990 of total blocks 2. The number of live datanodes 3 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2017-12-30 02:48:13,357 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: initializing replication queues
2017-12-30 02:48:13,360 INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 71 secs
2017-12-30 02:48:13,360 INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
2017-12-30 02:48:13,360 INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 3 datanodes
2017-12-30 02:48:13,360 INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
2017-12-30 02:48:13,390 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 2
2017-12-30 02:48:13,390 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
2017-12-30 02:48:13,390 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
2017-12-30 02:48:13,391 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
2017-12-30 02:48:13,391 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
2017-12-30 02:48:13,391 INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 28 msec
2017-12-30 02:48:20,340 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-30 02:48:20,340 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-30 02:48:50,341 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-30 02:48:50,342 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-30 02:49:20,343 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-30 02:49:20,343 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-30 02:49:36,013 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-30 02:49:36,013 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-30 02:49:36,014 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 246
2017-12-30 02:49:36,016 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 35 12 
2017-12-30 02:49:36,048 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 66 13 
2017-12-30 02:49:36,095 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000246 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000246-0000000000000000247
2017-12-30 02:49:36,164 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 248
2017-12-30 02:49:50,344 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-30 02:49:50,345 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-30 02:50:20,345 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-30 02:50:20,345 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-30 02:50:50,346 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-30 02:50:50,347 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-30 02:51:20,347 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-30 02:51:20,348 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-30 02:51:29,209 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: there are no corrupt file blocks.
2017-12-30 02:51:37,441 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-30 02:51:37,442 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-30 02:51:37,442 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 248
2017-12-30 02:51:37,442 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 18 12 
2017-12-30 02:51:37,463 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 37 14 
2017-12-30 02:51:37,482 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000248 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000248-0000000000000000249
2017-12-30 02:51:37,482 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 250
2017-12-30 02:51:50,347 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-30 02:51:50,348 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-30 02:52:20,349 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-30 02:52:20,350 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-30 02:52:50,351 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-30 02:52:50,352 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-30 02:53:20,354 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-30 02:53:20,355 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-30 02:53:37,681 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-30 02:53:37,682 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-30 02:53:37,682 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 250
2017-12-30 02:53:37,682 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 7 27 
2017-12-30 02:53:37,706 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 29 28 
2017-12-30 02:53:37,718 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000250 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000250-0000000000000000251
2017-12-30 02:53:37,719 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 252
2017-12-30 02:53:50,354 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-30 02:53:50,355 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-30 02:54:20,355 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-30 02:54:20,356 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-30 02:54:50,355 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-30 02:54:50,356 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-30 02:55:20,357 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-30 02:55:20,358 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-30 02:55:37,885 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-30 02:55:37,886 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-30 02:55:37,886 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 252
2017-12-30 02:55:37,887 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 6 11 
2017-12-30 02:55:37,914 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 31 13 
2017-12-30 02:55:37,928 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000252 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000252-0000000000000000253
2017-12-30 02:55:37,928 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 254
2017-12-30 02:55:50,357 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-30 02:55:50,358 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-30 02:56:20,358 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-30 02:56:20,359 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-30 02:56:50,359 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-30 02:56:50,360 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2017-12-30 02:57:20,360 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-30 02:57:20,361 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-30 02:57:38,138 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-30 02:57:38,138 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-30 02:57:38,138 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 254
2017-12-30 02:57:38,139 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 9 15 
2017-12-30 02:57:38,165 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 32 17 
2017-12-30 02:57:38,176 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000254 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000254-0000000000000000255
2017-12-30 02:57:38,177 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 256
2017-12-30 02:57:50,361 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-30 02:57:50,362 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-30 02:58:20,362 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-30 02:58:20,362 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-30 02:58:50,362 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-30 02:58:50,362 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-30 02:59:20,363 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-30 02:59:20,364 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-30 02:59:38,308 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-30 02:59:38,309 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-30 02:59:38,309 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 256
2017-12-30 02:59:38,309 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 8 11 
2017-12-30 02:59:38,332 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 29 12 
2017-12-30 02:59:38,344 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000256 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000256-0000000000000000257
2017-12-30 02:59:38,345 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 258
2017-12-30 02:59:50,364 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-30 02:59:50,364 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-30 03:00:20,365 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-30 03:00:20,366 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-30 03:00:50,365 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-30 03:00:50,366 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-30 03:01:20,366 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-30 03:01:20,367 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-30 03:01:38,504 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-30 03:01:38,505 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-30 03:01:38,505 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 258
2017-12-30 03:01:38,505 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 6 12 
2017-12-30 03:01:38,528 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 25 16 
2017-12-30 03:01:38,541 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000258 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000258-0000000000000000259
2017-12-30 03:01:38,541 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 260
2017-12-30 03:01:50,367 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-30 03:01:50,368 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-30 03:02:20,369 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-30 03:02:20,370 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-30 03:02:50,371 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-30 03:02:50,372 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-30 03:03:20,371 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-30 03:03:20,372 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-30 03:03:38,698 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-30 03:03:38,698 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-30 03:03:38,698 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 260
2017-12-30 03:03:38,699 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 9 13 
2017-12-30 03:03:38,717 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 26 14 
2017-12-30 03:03:38,728 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000260 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000260-0000000000000000261
2017-12-30 03:03:38,729 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 262
2017-12-30 03:03:50,372 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-30 03:03:50,373 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-30 03:04:20,373 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-30 03:04:20,374 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-30 03:04:50,373 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30000 milliseconds
2017-12-30 03:04:50,374 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-30 03:05:20,374 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-30 03:05:20,376 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2017-12-30 03:05:32,833 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1146ms
No GCs detected
2017-12-30 03:05:38,882 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-30 03:05:38,882 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-30 03:05:38,882 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 262
2017-12-30 03:05:38,883 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 29 15 
2017-12-30 03:05:38,902 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 47 16 
2017-12-30 03:05:38,911 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000262 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000262-0000000000000000263
2017-12-30 03:05:38,915 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 264
2017-12-30 03:05:50,375 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-30 03:05:50,376 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-30 03:06:20,376 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-30 03:06:20,377 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-30 03:06:50,377 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-30 03:06:50,377 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-30 03:07:20,378 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-30 03:07:20,379 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-30 03:07:39,051 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-30 03:07:39,052 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-30 03:07:39,052 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 264
2017-12-30 03:07:39,053 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 10 10 
2017-12-30 03:07:39,082 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 35 14 
2017-12-30 03:07:39,096 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000264 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000264-0000000000000000265
2017-12-30 03:07:39,096 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 266
2017-12-30 03:07:50,379 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-30 03:07:50,380 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-30 03:08:20,380 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-30 03:08:20,381 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 2 millisecond(s).
2017-12-30 03:08:50,381 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-30 03:08:50,381 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-30 03:09:20,382 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-30 03:09:20,382 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-30 03:09:39,279 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-30 03:09:39,279 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-30 03:09:39,279 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 266
2017-12-30 03:09:39,280 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 8 36 
2017-12-30 03:09:39,311 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 38 37 
2017-12-30 03:09:39,321 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000266 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000266-0000000000000000267
2017-12-30 03:09:39,322 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 268
2017-12-30 03:09:50,383 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-30 03:09:50,384 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-30 03:10:20,385 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-30 03:10:20,386 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-30 03:10:50,386 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-30 03:10:50,387 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-30 03:11:20,388 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-30 03:11:20,389 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-30 03:11:39,469 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 192.168.1.101
2017-12-30 03:11:39,469 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
2017-12-30 03:11:39,469 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 268
2017-12-30 03:11:39,470 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 1 SyncTimes(ms): 5 10 
2017-12-30 03:11:40,742 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 631 656 
2017-12-30 03:11:40,752 WARN org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Took 1281ms to send a batch of 1 edits (17 bytes) to remote journal 192.168.1.101:8485
2017-12-30 03:11:40,770 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /opt/hadoop2/dfs/name/current/edits_inprogress_0000000000000000268 -> /opt/hadoop2/dfs/name/current/edits_0000000000000000268-0000000000000000269
2017-12-30 03:11:40,771 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 270
2017-12-30 03:11:50,390 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30002 milliseconds
2017-12-30 03:11:50,391 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 0 millisecond(s).
2017-12-30 03:12:20,392 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Rescanning after 30001 milliseconds
2017-12-30 03:12:20,393 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Scanned 0 directive(s) and 0 block(s) in 1 millisecond(s).
2017-12-30 03:12:36,978 ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
2017-12-30 03:12:36,989 INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at master100/192.168.1.100
************************************************************/
